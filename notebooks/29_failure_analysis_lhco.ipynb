{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "import energyflow as ef\n",
    "import h5py\n",
    "import hydra\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "from sklearn.neighbors import KernelDensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots and metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.data.components import (\n",
    "    calculate_all_wasserstein_metrics,\n",
    "    inverse_normalize_tensor,\n",
    "    normalize_tensor,\n",
    ")\n",
    "from src.data.components.utils import (\n",
    "    get_jet_data,\n",
    "    get_mjj,\n",
    "    get_nonrel_consts,\n",
    "    sort_consts,\n",
    "    sort_jets,\n",
    ")\n",
    "from src.utils.data_generation import generate_data\n",
    "from src.utils.plotting import apply_mpl_styles, plot_data, prepare_data_for_plotting\n",
    "\n",
    "apply_mpl_styles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetnet.evaluation import w1efp, w1m, w1p\n",
    "\n",
    "from src.data.components.metrics import wasserstein_distance_batched\n",
    "from src.utils.jet_substructure import dump_hlvs\n",
    "from src.utils.plotting import plot_full_substructure, plot_substructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set env variable DATA_DIR again because of hydra\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"DATA_DIR\"] = os.environ.get(\"DATA_DIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.environ.get(\"DATA_DIR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_preds = \"/beegfs/desy/user/ewencedr/data/lhco/preds.h5\"\n",
    "with h5py.File(path_preds, \"r\") as f:\n",
    "    pred = f[\"preds\"][:]\n",
    "    semi_labels = f[\"semi_labels\"][:]\n",
    "    sample_mjj = f[\"mjj\"][:]\n",
    "    sample_j = f[\"sample_j\"][:]\n",
    "    sample_p = f[\"sample_p\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revert pre-processing\n",
    "def LoadJson(file_name):\n",
    "    import json\n",
    "\n",
    "    import yaml\n",
    "\n",
    "    JSONPATH = os.path.join(file_name)\n",
    "    return yaml.safe_load(open(JSONPATH))\n",
    "\n",
    "\n",
    "data_dict = LoadJson(\"/home/ewencedr/LHCO_diffusion/scripts/preprocessing_279.json\")\n",
    "batch_size = sample_p.shape[0]\n",
    "num_part = sample_p.shape[2]\n",
    "sample_p = sample_p.reshape(-1, sample_p.shape[-1])\n",
    "mask = np.expand_dims(sample_p[:, 0] != 0, -1)\n",
    "sample_p = sample_p * data_dict[\"std_particle\"] + data_dict[\"mean_particle\"]\n",
    "\n",
    "sample_p[:, 0] = 1.0 - np.exp(sample_p[:, 0])\n",
    "sample_p[:, 0] = np.clip(sample_p[:, 0], 2.5349376295699686e-05, 1.0)  # apply min pt cut\n",
    "sample_p = (sample_p * mask).reshape(batch_size, 2, num_part, -1)\n",
    "print(sample_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revert jet data preprocessing\n",
    "sample_j = sample_j.reshape(-1, sample_j.shape[-1])\n",
    "mjj_tile = np.expand_dims(sample_mjj, 1)\n",
    "mjj_tile = np.reshape(np.tile(mjj_tile, (1, 2)), (-1))\n",
    "sample_j = sample_j * data_dict[\"std_jet\"] + data_dict[\"mean_jet\"]\n",
    "sample_j[:, 0] = np.exp(sample_j[:, 0]) * mjj_tile\n",
    "sample_j[:, 4] = np.round(sample_j[:, 4])\n",
    "sample_j[:, 4] = np.clip(sample_j[:, 4], 1, 279)\n",
    "# 1 particle jets have 0 mass\n",
    "mask_mass = sample_j[:, 4] > 1.0\n",
    "sample_j[:, 3] = np.exp(sample_j[:, 3]) * mask_mass * mjj_tile\n",
    "sample_j = sample_j.reshape(batch_size, 2, -1)\n",
    "print(sample_j.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bool = pred > 0.5\n",
    "pred_bool = pred_bool.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = pred_bool == semi_labels\n",
    "accuracy = np.sum(correct) / len(correct)\n",
    "print(f\"ACC: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(correct))\n",
    "print(np.sum(~correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_pt(array):\n",
    "\n",
    "    pt = array[..., 0]\n",
    "    # print(pt[0,0,:10])\n",
    "    eta = array[..., 1]\n",
    "    phi = array[..., 2]\n",
    "    args = np.argsort(pt, axis=-1)[..., ::-1]\n",
    "    # print(pt.shape)\n",
    "    # print(args.shape)\n",
    "\n",
    "    pt2 = np.take_along_axis(pt, args, axis=-1)\n",
    "    # print(pt2[0,0,:10])\n",
    "    eta2 = np.take_along_axis(eta, args, axis=-1)\n",
    "    phi2 = np.take_along_axis(phi, args, axis=-1)\n",
    "    return np.stack([pt2, eta2, phi2], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_p = sort_pt(sample_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_j = sample_j[correct]\n",
    "false_j = sample_j[~correct]\n",
    "correct_mjj = sample_mjj[correct]\n",
    "false_mjj = sample_mjj[~correct]\n",
    "correct_p = sample_p[correct]\n",
    "false_p = sample_p[~correct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(correct_j.shape)\n",
    "print(correct_p.shape)\n",
    "print(false_j.shape)\n",
    "print(false_p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## look at dijet features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(correct_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particles_correct_nonrel = get_nonrel_consts(correct_j, correct_p)\n",
    "particles_false_nonrel = get_nonrel_consts(false_j, false_p)\n",
    "print(particles_correct_nonrel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "plt.hist(\n",
    "    particles_correct_nonrel[..., i].flatten()[particles_correct_nonrel[..., i].flatten() != 0],\n",
    "    bins=100,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_correctly_classified = get_jet_data(particles_correct_nonrel)\n",
    "jet_false_classified = get_jet_data(particles_false_nonrel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jet_correctly_classified.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(correct_j.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mjj_correctly_classified = get_mjj(jet_correctly_classified[:,0], jet_correctly_classified[:,1])\n",
    "# mjj_false_classified = get_mjj(jet_false_classified[:,0], jet_false_classified[:,1])\n",
    "mjj_correctly_classified = get_mjj(correct_j[:, 0, :4], correct_j[:, 1, :4])\n",
    "mjj_false_classified = get_mjj(false_j[:, 0, :4], false_j[:, 1, :4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_bin, max_bin = min(np.min(mjj_correctly_classified), np.min(mjj_false_classified)), max(\n",
    "    np.max(mjj_correctly_classified), np.max(mjj_false_classified)\n",
    ")\n",
    "hist = plt.hist(\n",
    "    mjj_correctly_classified,\n",
    "    bins=100,\n",
    "    alpha=0.5,\n",
    "    label=\"correct\",\n",
    "    density=True,\n",
    "    range=(min_bin, max_bin),\n",
    ")\n",
    "plt.hist(mjj_false_classified, bins=100, label=\"false\", density=True, histtype=\"step\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(jet_features_id.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p4_jets_x = ef.p4s_from_ptyphims(jet_features_id[:, 0, :4])\n",
    "# p4_jets_y = ef.p4s_from_ptyphims(jet_features_id[:, 1, :4])\n",
    "# sum_p4 = p4_jets_x + p4_jets_y\n",
    "# mjj = ef.ms_from_p4s(sum_p4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(mjj, bins=100, alpha=0.5, label=\"correct\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at substructure of correctly vs incorrectly classified events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "path_true_data = \"/beegfs/desy/user/ewencedr/data/lhco/generated/idealized_LHCO_shuffled.h5\"\n",
    "# path_true_data = \"/beegfs/desy/user/ewencedr/data/lhco/generated/SB_idealized_120k.h5\"\n",
    "with h5py.File(path_true_data, \"r\") as f:\n",
    "    jet_features_id = f[\"jet_features\"][:]\n",
    "    particle_data_id = f[\"particle_features\"][:]\n",
    "    mjj_id = f[\"mjj\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "path_true_datav = \"/beegfs/desy/user/ewencedr/data/lhco/generated/FPCD_LHCO_SR_shuffled.h5\"\n",
    "with h5py.File(path_true_datav, \"r\") as f:\n",
    "    jet_features_v = f[\"jet_features\"][:]\n",
    "    particle_data_v = f[\"particle_features\"][:]\n",
    "    mjj_v = f[\"mjj\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "# path_true_datac = \"/beegfs/desy/user/ewencedr/data/lhco/generated/lhco-xy-10layer-256latent-logpt-new2m_sr-midpoint-300_shuffled.h5\"\n",
    "# path_true_datac = \"/beegfs/desy/user/ewencedr/data/lhco/generated/both_jets2_nnew2_sr-midpoint-300.h5\"\n",
    "# path_true_datac = \"/beegfs/desy/user/ewencedr/data/lhco/generated/both_jets-100p-not-nnew_sr-midpoint-300.h5\"\n",
    "# path_true_datac = \"/beegfs/desy/user/ewencedr/data/lhco/generated/lhco-xy-10layer-256latent-logpt-new2_sr-euler-500.h5\"\n",
    "# path_true_datac = \"/beegfs/desy/user/ewencedr/data/lhco/generated/vhighconfig-mass-ordered-2-midpoint-250.h5\"\n",
    "# path_true_datac = \"/beegfs/desy/user/ewencedr/data/lhco/generated/lhco-xy-13layer_sr-midpoint-300.h5\"\n",
    "# path_true_datac = \"/beegfs/desy/user/ewencedr/data/lhco/generated/lhco-xy-setup2_sr-midpoint-300.h5\"\n",
    "\n",
    "# path_true_datac = \"/beegfs/desy/user/ewencedr/data/lhco/generated/lhco-xy-256-logpt-sbtest_sb-midpoint-300.h5\"\n",
    "\n",
    "\n",
    "path_true_datac = \"/beegfs/desy/user/ewencedr/data/lhco/generated/lhco-xy-10layer-256latent-logpt-noseed_sr-midpoint-250.h5\"\n",
    "\n",
    "\n",
    "with h5py.File(path_true_datac, \"r\") as f:\n",
    "    jet_features_c = f[\"jet_features\"][:]\n",
    "    particle_data_c = f[\"particle_features\"][:]\n",
    "    # particle_features_nonrel_c = f[\"particle_features_nonrel\"][:]\n",
    "    mjj_c = f[\"mjj\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jet_features_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort jets by pt\n",
    "jet_features_id, particle_data_id = sort_jets(jet_features_id, particle_data_id, sort_by=\"pt\")\n",
    "jet_features_c, particle_data_c = sort_jets(jet_features_c, particle_data_c, sort_by=\"pt\")\n",
    "jet_features_v, particle_data_v = sort_jets(jet_features_v, particle_data_v, sort_by=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort constituents by pt\n",
    "particle_data_id = sort_consts(particle_data_id, sort_by=\"pt\")\n",
    "particle_data_c = sort_consts(particle_data_c, sort_by=\"pt\")\n",
    "particle_data_v = sort_consts(particle_data_v, sort_by=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(particle_data_id.shape)\n",
    "print(particle_data_v.shape)\n",
    "print(particle_data_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particle_data_v = particle_data_v[: len(particle_data_id)]\n",
    "jet_features_v = jet_features_v[: len(jet_features_id)]\n",
    "mjj_v = mjj_v[: len(mjj_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### look at high level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonrel_data_id = get_nonrel_consts(jet_features_id, particle_data_id)\n",
    "nonrel_data_v = get_nonrel_consts(jet_features_v, particle_data_v)\n",
    "nonrel_data_c = get_nonrel_consts(jet_features_c, particle_data_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_jet_features_id = get_jet_data(nonrel_data_id)\n",
    "calc_jet_features_v = get_jet_data(nonrel_data_v)\n",
    "calc_jet_features_c = get_jet_data(nonrel_data_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_particle_data_id = particle_data_id[..., 0] != 0\n",
    "particle_multiplicity_id = np.sum(mask_particle_data_id, axis=-1)\n",
    "calc_jet_features_id = np.concatenate(\n",
    "    [calc_jet_features_id, np.expand_dims(particle_multiplicity_id, axis=-1)], axis=-1\n",
    ")\n",
    "mask_particle_data_c = particle_data_c[..., 0] != 0\n",
    "particle_multiplicity_c = np.sum(mask_particle_data_c, axis=-1)\n",
    "calc_jet_features_c = np.concatenate(\n",
    "    [calc_jet_features_c, np.expand_dims(particle_multiplicity_c, axis=-1)], axis=-1\n",
    ")\n",
    "mask_particle_data_v = particle_data_v[..., 0] != 0\n",
    "particle_multiplicity_v = np.sum(mask_particle_data_v, axis=-1)\n",
    "calc_jet_features_v = np.concatenate(\n",
    "    [calc_jet_features_v, np.expand_dims(particle_multiplicity_v, axis=-1)], axis=-1\n",
    ")\n",
    "print(calc_jet_features_id.shape)\n",
    "print(calc_jet_features_v.shape)\n",
    "print(calc_jet_features_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "for i, ax in enumerate(axs):\n",
    "    # min_bin, max_bin = min(np.min(calc_jet_features_id[:,i]), np.min(calc_jet_features_v[:,i])), max(np.max(calc_jet_features_id[:,i]), np.max(calc_jet_features_v[:,i]))\n",
    "    min_bin, max_bin = min(\n",
    "        np.min(jet_features_c[..., i]), np.min(calc_jet_features_c[..., i])\n",
    "    ), max(np.max(jet_features_c[..., i]), np.max(calc_jet_features_c[..., i]))\n",
    "    ax.hist(\n",
    "        jet_features_c[..., i].flatten(),\n",
    "        bins=100,\n",
    "        alpha=0.5,\n",
    "        label=\"conditioning\",\n",
    "        range=(min_bin, max_bin),\n",
    "    )\n",
    "    ax.hist(\n",
    "        calc_jet_features_c[..., i].flatten(), bins=100, label=\"generate_data\", histtype=\"step\"\n",
    "    )\n",
    "    ax.legend()\n",
    "    ax.set_yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first jet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 5, figsize=(20, 5))\n",
    "for i, ax in enumerate(axs):\n",
    "    # min_bin, max_bin = min(np.min(calc_jet_features_id[:,i]), np.min(calc_jet_features_v[:,i])), max(np.max(calc_jet_features_id[:,i]), np.max(calc_jet_features_v[:,i]))\n",
    "    min_bin, max_bin = min(\n",
    "        np.min(jet_features_c[..., i][:, 0]), np.min(calc_jet_features_c[..., i][:, 0])\n",
    "    ), max(np.max(jet_features_c[..., i][:, 0]), np.max(calc_jet_features_c[..., i][:, 0]))\n",
    "    ax.hist(\n",
    "        jet_features_c[..., i][:, 0].flatten(),\n",
    "        bins=100,\n",
    "        alpha=0.5,\n",
    "        label=\"conditioning\",\n",
    "        range=(min_bin, max_bin),\n",
    "    )\n",
    "    ax.hist(\n",
    "        calc_jet_features_c[..., i][:, 0].flatten(),\n",
    "        bins=100,\n",
    "        label=\"generate_data\",\n",
    "        histtype=\"step\",\n",
    "    )\n",
    "    ax.hist(\n",
    "        calc_jet_features_v[..., i][:, 0].flatten(),\n",
    "        bins=100,\n",
    "        label=\"generate_data_v\",\n",
    "        histtype=\"step\",\n",
    "    )\n",
    "    ax.legend()\n",
    "    ax.set_yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_mjj_id = get_mjj(calc_jet_features_id[:, 0, :4], calc_jet_features_id[:, 1, :4])\n",
    "calc_mjj_v = get_mjj(calc_jet_features_v[:, 0, :4], calc_jet_features_v[:, 1, :4])\n",
    "calc_mjj_c = get_mjj(calc_jet_features_c[:, 0, :4], calc_jet_features_c[:, 1, :4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_bin, max_bin = min(np.min(calc_mjj_id), np.min(calc_mjj_v), np.min(calc_mjj_c)), max(\n",
    "    np.max(calc_mjj_id), np.max(calc_mjj_v), np.max(calc_mjj_c)\n",
    ")\n",
    "plt.hist(calc_mjj_id, bins=100, alpha=0.5, label=\"ideal\", range=(min_bin, max_bin))\n",
    "plt.hist(calc_mjj_v, bins=100, label=\"vinicius\", histtype=\"step\", range=(min_bin, max_bin))\n",
    "plt.hist(calc_mjj_c, bins=100, label=\"FM\", histtype=\"step\", range=(min_bin, max_bin))\n",
    "plt.legend()\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"mjj\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### delta R between jets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deltaR(jet_features: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Calculate deltaR between two jets\n",
    "\n",
    "    Args:\n",
    "        jet_features (np.ndarray): jet features (pt, eta, phi, mass)\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: delta R between two jets\n",
    "    \"\"\"\n",
    "    eta1 = jet_features[:, 0, 1]\n",
    "    phi1 = jet_features[:, 0, 2]\n",
    "    eta2 = jet_features[:, 1, 1]\n",
    "    phi2 = jet_features[:, 1, 2]\n",
    "    return np.sqrt((eta1 - eta2) ** 2 + (phi1 - phi2) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaR_id = get_deltaR(calc_jet_features_id)\n",
    "deltaR_v = get_deltaR(calc_jet_features_v)\n",
    "deltaR_c = get_deltaR(calc_jet_features_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_bin, max_bin = min(np.min(deltaR_id), np.min(deltaR_v), np.min(deltaR_c)), max(\n",
    "    np.max(deltaR_id), np.max(deltaR_v), np.max(deltaR_c)\n",
    ")\n",
    "plt.hist(deltaR_id, bins=100, alpha=0.5, label=\"ideal\", range=(min_bin, max_bin))\n",
    "plt.hist(deltaR_v, bins=100, label=\"vinicius\", histtype=\"step\", range=(min_bin, max_bin))\n",
    "plt.hist(deltaR_c, bins=100, label=\"FM\", histtype=\"step\", range=(min_bin, max_bin))\n",
    "plt.legend()\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(r\"$\\Delta R$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_pt_jet_id = abs(calc_jet_features_id[:, 0, 0] - calc_jet_features_id[:, 1, 0])\n",
    "delta_pt_jet_v = abs(calc_jet_features_v[:, 0, 0] - calc_jet_features_v[:, 1, 0])\n",
    "delta_pt_jet_c = abs(calc_jet_features_c[:, 0, 0] - calc_jet_features_c[:, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_bin, max_bin = min(\n",
    "    np.min(delta_pt_jet_id), np.min(delta_pt_jet_v), np.min(delta_pt_jet_c)\n",
    "), max(np.max(delta_pt_jet_id), np.max(delta_pt_jet_v), np.max(delta_pt_jet_c))\n",
    "plt.hist(delta_pt_jet_id, bins=100, alpha=0.5, label=\"ideal\", range=(min_bin, max_bin))\n",
    "plt.hist(delta_pt_jet_v, bins=100, label=\"vinicius\", histtype=\"step\", range=(min_bin, max_bin))\n",
    "plt.hist(delta_pt_jet_c, bins=100, label=\"FM\", histtype=\"step\", range=(min_bin, max_bin))\n",
    "plt.legend()\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(r\"$\\Delta p_T$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## substructure for each jet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((particle_data_id[..., [1, 2, 0]][:10000, 0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_hlvs(\n",
    "    particle_data_id[..., [1, 2, 0]][:10000, 0],\n",
    "    \"/beegfs/desy/user/ewencedr/data/lhco/substructure/notebook_jet1_id_pto\",\n",
    "    plot=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_hlvs(\n",
    "    particle_data_id[..., [1, 2, 0]][:10000, 1],\n",
    "    \"/beegfs/desy/user/ewencedr/data/lhco/substructure/notebook_jet2_id_pto\",\n",
    "    plot=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_hlvs(\n",
    "    particle_data_c[..., [1, 2, 0]][:10000, 0],\n",
    "    \"/beegfs/desy/user/ewencedr/data/lhco/substructure/notebook_jet1_c_both_jets2_pto\",\n",
    "    plot=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_hlvs(\n",
    "    particle_data_c[..., [1, 2, 0]][:10000, 1],\n",
    "    \"/beegfs/desy/user/ewencedr/data/lhco/substructure/notebook_jet2_c_both_jets2_pto\",\n",
    "    plot=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_hlvs(\n",
    "    particle_data_v[..., [1, 2, 0]][:10000, 0],\n",
    "    \"/beegfs/desy/user/ewencedr/data/lhco/substructure/notebook_jet1_pto\",\n",
    "    plot=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_hlvs(\n",
    "    particle_data_v[..., [1, 2, 0]][:10000, 1],\n",
    "    \"/beegfs/desy/user/ewencedr/data/lhco/substructure/notebook_jet2_pto\",\n",
    "    plot=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load substructure for id data\n",
    "data_substructure_id1 = []\n",
    "with h5py.File(\n",
    "    \"/beegfs/desy/user/ewencedr/data/lhco/substructure/notebook_jet1_id_pto\" + \".h5\", \"r\"\n",
    ") as f:\n",
    "    tau21_id1 = np.nan_to_num(np.array(f[\"tau21\"]))\n",
    "    tau32_id1 = np.nan_to_num(np.array(f[\"tau32\"]))\n",
    "    d2_id1 = np.nan_to_num(np.array(f[\"d2\"]))\n",
    "    for key in f.keys():\n",
    "        data_substructure_id1.append(np.array(f[key]))\n",
    "data_substructure_id1 = np.array(data_substructure_id1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load substructure for id data\n",
    "data_substructure_id2 = []\n",
    "with h5py.File(\n",
    "    \"/beegfs/desy/user/ewencedr/data/lhco/substructure/notebook_jet2_id_pto\" + \".h5\", \"r\"\n",
    ") as f:\n",
    "    tau21_id2 = np.nan_to_num(np.array(f[\"tau21\"]))\n",
    "    tau32_id2 = np.nan_to_num(np.array(f[\"tau32\"]))\n",
    "    d2_id2 = np.nan_to_num(np.array(f[\"d2\"]))\n",
    "    for key in f.keys():\n",
    "        data_substructure_id2.append(np.array(f[key]))\n",
    "data_substructure_id2 = np.array(data_substructure_id2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load substructure for id data\n",
    "data_substructure_c1 = []\n",
    "with h5py.File(\n",
    "    \"/beegfs/desy/user/ewencedr/data/lhco/substructure/notebook_jet1_c_both_jets2_pto\" + \".h5\", \"r\"\n",
    ") as f:\n",
    "    tau21_c1 = np.nan_to_num(np.array(f[\"tau21\"]))\n",
    "    tau32_c1 = np.nan_to_num(np.array(f[\"tau32\"]))\n",
    "    d2_c1 = np.nan_to_num(np.array(f[\"d2\"]))\n",
    "    for key in f.keys():\n",
    "        data_substructure_c1.append(np.array(f[key]))\n",
    "data_substructure_c1 = np.array(data_substructure_c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load substructure for id data\n",
    "data_substructure_c2 = []\n",
    "with h5py.File(\n",
    "    \"/beegfs/desy/user/ewencedr/data/lhco/substructure/notebook_jet2_c_both_jets2_pto\" + \".h5\", \"r\"\n",
    ") as f:\n",
    "    tau21_c2 = np.nan_to_num(np.array(f[\"tau21\"]))\n",
    "    tau32_c2 = np.nan_to_num(np.array(f[\"tau32\"]))\n",
    "    d2_c2 = np.nan_to_num(np.array(f[\"d2\"]))\n",
    "    for key in f.keys():\n",
    "        data_substructure_c2.append(np.array(f[key]))\n",
    "data_substructure_c2 = np.array(data_substructure_c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load substructure for id data\n",
    "data_substructure_v1 = []\n",
    "with h5py.File(\n",
    "    \"/beegfs/desy/user/ewencedr/data/lhco/substructure/notebook_jet1_pto\" + \".h5\", \"r\"\n",
    ") as f:\n",
    "    tau21_v1 = np.nan_to_num(np.array(f[\"tau21\"]))\n",
    "    tau32_v1 = np.nan_to_num(np.array(f[\"tau32\"]))\n",
    "    d2_v1 = np.nan_to_num(np.array(f[\"d2\"]))\n",
    "    for key in f.keys():\n",
    "        data_substructure_v1.append(np.array(f[key]))\n",
    "data_substructure_v1 = np.array(data_substructure_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load substructure for id data\n",
    "data_substructure_v2 = []\n",
    "with h5py.File(\n",
    "    \"/beegfs/desy/user/ewencedr/data/lhco/substructure/notebook_jet2_pto\" + \".h5\", \"r\"\n",
    ") as f:\n",
    "    tau21_v2 = np.nan_to_num(np.array(f[\"tau21\"]))\n",
    "    tau32_v2 = np.nan_to_num(np.array(f[\"tau32\"]))\n",
    "    d2_v2 = np.nan_to_num(np.array(f[\"d2\"]))\n",
    "    for key in f.keys():\n",
    "        data_substructure_v2.append(np.array(f[key]))\n",
    "data_substructure_v2 = np.array(data_substructure_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_tau21_id = abs(tau21_id1 - tau21_id2)\n",
    "delta_tau21_c = abs(tau21_c1 - tau21_c2)\n",
    "delta_tau21_v = abs(tau21_v1 - tau21_v2)\n",
    "delta_tau32_id = abs(tau32_id1 - tau32_id2)\n",
    "delta_tau32_c = abs(tau32_c1 - tau32_c2)\n",
    "delta_tau32_v = abs(tau32_v1 - tau32_v2)\n",
    "delta_d2_id = abs(d2_id1 - d2_id2)\n",
    "delta_d2_c = abs(d2_c1 - d2_c2)\n",
    "delta_d2_v = abs(d2_v1 - d2_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(delta_tau21_id), np.max(delta_tau21_id))\n",
    "print(np.min(delta_tau21_c), np.max(delta_tau21_c))\n",
    "print(np.min(delta_tau21_v), np.max(delta_tau21_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_bin, max_bin = min(np.min(delta_tau21_id), np.min(delta_tau21_c), np.min(delta_tau21_v)), max(\n",
    "    np.max(delta_tau21_id), np.max(delta_tau21_c), np.max(delta_tau21_v)\n",
    ")\n",
    "plt.hist(delta_tau21_id, bins=100, alpha=0.5, label=\"ideal\", range=(min_bin, max_bin))\n",
    "plt.hist(delta_tau21_c, bins=100, label=\"FM\", histtype=\"step\", range=(min_bin, max_bin))\n",
    "plt.hist(delta_tau21_v, bins=100, label=\"vinicius\", histtype=\"step\", range=(min_bin, max_bin))\n",
    "plt.legend()\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(r\"$\\Delta \\tau_{21}$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_bin, max_bin = min(np.min(delta_tau32_id), np.min(delta_tau32_c), np.min(delta_tau32_v)), max(\n",
    "    np.max(delta_tau32_id), np.max(delta_tau32_c), np.max(delta_tau32_v)\n",
    ")\n",
    "plt.hist(delta_tau32_id, bins=100, alpha=0.5, label=\"ideal\", range=(min_bin, max_bin))\n",
    "plt.hist(delta_tau32_c, bins=100, label=\"FM\", histtype=\"step\", range=(min_bin, max_bin))\n",
    "plt.hist(delta_tau32_v, bins=100, label=\"vinicius\", histtype=\"step\", range=(min_bin, max_bin))\n",
    "plt.legend()\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(r\"$\\Delta \\tau_{32}$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_bin, max_bin = min(np.min(delta_d2_id), np.min(delta_d2_c), np.min(delta_d2_v)), max(\n",
    "    np.max(delta_d2_id), np.max(delta_d2_c), np.max(delta_d2_v)\n",
    ")\n",
    "plt.hist(delta_d2_id, bins=100, alpha=0.5, label=\"ideal\", range=(min_bin, max_bin))\n",
    "plt.hist(delta_d2_c, bins=100, label=\"FM\", histtype=\"step\", range=(min_bin, max_bin))\n",
    "plt.hist(delta_d2_v, bins=100, label=\"vinicius\", histtype=\"step\", range=(min_bin, max_bin))\n",
    "plt.legend()\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(r\"$\\Delta d_2$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## correlations plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_pt_jet_id_plot = delta_pt_jet_id[: len(delta_tau21_id)]\n",
    "delta_pt_jet_c_plot = delta_pt_jet_c[: len(delta_tau21_c)]\n",
    "delta_pt_jet_v_plot = delta_pt_jet_v[: len(delta_tau21_v)]\n",
    "\n",
    "deltaR_id_plot = deltaR_id[: len(delta_tau21_id)]\n",
    "deltaR_c_plot = deltaR_c[: len(delta_tau21_c)]\n",
    "deltaR_v_plot = deltaR_v[: len(delta_tau21_v)]\n",
    "\n",
    "calc_mjj_id_plot = calc_mjj_id[: len(delta_tau21_id)]\n",
    "calc_mjj_c_plot = calc_mjj_c[: len(delta_tau21_c)]\n",
    "calc_mjj_v_plot = calc_mjj_v[: len(delta_tau21_v)]\n",
    "\n",
    "calc_jet_features_id_plot = calc_jet_features_id[: len(delta_tau21_id)]\n",
    "calc_jet_features_c_plot = calc_jet_features_c[: len(delta_tau21_c)]\n",
    "calc_jet_features_v_plot = calc_jet_features_v[: len(delta_tau21_v)]\n",
    "jet_features_id_plot = jet_features_id[: len(delta_tau21_id)]\n",
    "jet_features_c_plot = jet_features_c[: len(delta_tau21_c)]\n",
    "jet_features_v_plot = jet_features_v[: len(delta_tau21_v)]\n",
    "\n",
    "mass_1_id_plot = calc_jet_features_id_plot[:, 0, 3]\n",
    "mass_1_c_plot = calc_jet_features_c_plot[:, 0, 3]\n",
    "mass_1_v_plot = calc_jet_features_v_plot[:, 0, 3]\n",
    "mass_1_id_plot_cond = jet_features_id_plot[:, 0, 3]\n",
    "mass_1_c_plot_cond = jet_features_c_plot[:, 0, 3]\n",
    "mass_1_v_plot_cond = jet_features_v_plot[:, 0, 3]\n",
    "\n",
    "mass_2_id_plot = calc_jet_features_id_plot[:, 1, 3]\n",
    "mass_2_c_plot = calc_jet_features_c_plot[:, 1, 3]\n",
    "mass_2_v_plot = calc_jet_features_v_plot[:, 1, 3]\n",
    "mass_2_id_plot_cond = jet_features_id_plot[:, 1, 3]\n",
    "mass_2_c_plot_cond = jet_features_c_plot[:, 1, 3]\n",
    "mass_2_v_plot_cond = jet_features_v_plot[:, 1, 3]\n",
    "\n",
    "pt_1_id_plot = calc_jet_features_id_plot[:, 0, 0]\n",
    "pt_1_c_plot = calc_jet_features_c_plot[:, 0, 0]\n",
    "pt_1_v_plot = calc_jet_features_v_plot[:, 0, 0]\n",
    "pt_1_id_plot_cond = jet_features_id_plot[:, 0, 0]\n",
    "pt_1_c_plot_cond = jet_features_c_plot[:, 0, 0]\n",
    "pt_1_v_plot_cond = jet_features_v_plot[:, 0, 0]\n",
    "\n",
    "pt_2_id_plot = calc_jet_features_id_plot[:, 1, 0]\n",
    "pt_2_c_plot = calc_jet_features_c_plot[:, 1, 0]\n",
    "pt_2_v_plot = calc_jet_features_v_plot[:, 1, 0]\n",
    "pt_2_id_plot_cond = jet_features_id_plot[:, 1, 0]\n",
    "pt_2_c_plot_cond = jet_features_c_plot[:, 1, 0]\n",
    "pt_2_v_plot_cond = jet_features_v_plot[:, 1, 0]\n",
    "\n",
    "eta_1_id_plot = calc_jet_features_id_plot[:, 0, 1]\n",
    "eta_1_c_plot = calc_jet_features_c_plot[:, 0, 1]\n",
    "eta_1_v_plot = calc_jet_features_v_plot[:, 0, 1]\n",
    "eta_1_id_plot_cond = jet_features_id_plot[:, 0, 1]\n",
    "eta_1_c_plot_cond = jet_features_c_plot[:, 0, 1]\n",
    "eta_1_v_plot_cond = jet_features_v_plot[:, 0, 1]\n",
    "\n",
    "eta_2_id_plot = calc_jet_features_id_plot[:, 1, 1]\n",
    "eta_2_c_plot = calc_jet_features_c_plot[:, 1, 1]\n",
    "eta_2_v_plot = calc_jet_features_v_plot[:, 1, 1]\n",
    "eta_2_id_plot_cond = jet_features_id_plot[:, 1, 1]\n",
    "eta_2_c_plot_cond = jet_features_c_plot[:, 1, 1]\n",
    "eta_2_v_plot_cond = jet_features_v_plot[:, 1, 1]\n",
    "\n",
    "phi_1_id_plot = calc_jet_features_id_plot[:, 0, 2]\n",
    "phi_1_c_plot = calc_jet_features_c_plot[:, 0, 2]\n",
    "phi_1_v_plot = calc_jet_features_v_plot[:, 0, 2]\n",
    "phi_1_id_plot_cond = jet_features_id_plot[:, 0, 2]\n",
    "phi_1_c_plot_cond = jet_features_c_plot[:, 0, 2]\n",
    "phi_1_v_plot_cond = jet_features_v_plot[:, 0, 2]\n",
    "\n",
    "phi_2_id_plot = calc_jet_features_id_plot[:, 1, 2]\n",
    "phi_2_c_plot = calc_jet_features_c_plot[:, 1, 2]\n",
    "phi_2_v_plot = calc_jet_features_v_plot[:, 1, 2]\n",
    "phi_2_id_plot_cond = jet_features_id_plot[:, 1, 2]\n",
    "phi_2_c_plot_cond = jet_features_c_plot[:, 1, 2]\n",
    "phi_2_v_plot_cond = jet_features_v_plot[:, 1, 2]\n",
    "\n",
    "multiplicity_1_id_plot = calc_jet_features_id_plot[:, 0, 4]\n",
    "multiplicity_1_c_plot = calc_jet_features_c_plot[:, 0, 4]\n",
    "multiplicity_1_v_plot = calc_jet_features_v_plot[:, 0, 4]\n",
    "multiplicity_1_id_plot_cond = jet_features_id_plot[:, 0, 4]\n",
    "multiplicity_1_c_plot_cond = jet_features_c_plot[:, 0, 4]\n",
    "multiplicity_1_v_plot_cond = jet_features_v_plot[:, 0, 4]\n",
    "\n",
    "multiplicity_2_id_plot = calc_jet_features_id_plot[:, 1, 4]\n",
    "multiplicity_2_c_plot = calc_jet_features_c_plot[:, 1, 4]\n",
    "multiplicity_2_v_plot = calc_jet_features_v_plot[:, 1, 4]\n",
    "multiplicity_2_id_plot_cond = jet_features_id_plot[:, 1, 4]\n",
    "multiplicity_2_c_plot_cond = jet_features_c_plot[:, 1, 4]\n",
    "multiplicity_2_v_plot_cond = jet_features_v_plot[:, 1, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(multiplicity_1_c_plot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_pt_2_id = pt_2_id_plot != 0\n",
    "print(mask_pt_2_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analysis of the most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = [tau21_id1, tau21_c1, tau21_v1]\n",
    "data_y = [tau21_id2, tau21_c2, tau21_v2]\n",
    "label = [\"ideal\", \"FM\", \"vinicius\"]\n",
    "quantity1 = r\"$\\tau_{21}$ jet1\"\n",
    "quantity2 = r\"$\\tau_{21}$ jet2\"\n",
    "min_bin_x, max_bin_x = min(np.min(data_x[0]), np.min(data_x[1]), np.min(data_x[2])), max(\n",
    "    np.max(data_x[0]), np.max(data_x[1]), np.max(data_x[2])\n",
    ")\n",
    "min_bin_y, max_bin_y = min(np.min(data_y[0]), np.min(data_y[1]), np.min(data_y[2])), max(\n",
    "    np.max(data_y[0]), np.max(data_y[1]), np.max(data_y[2])\n",
    ")\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 5))\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.hist2d(\n",
    "        data_x[i],\n",
    "        data_y[i],\n",
    "        bins=25,\n",
    "        cmap=\"jet\",\n",
    "        range=[[min_bin_x, max_bin_x], [min_bin_y, max_bin_y]],\n",
    "    )\n",
    "    ax.set_xlabel(f\"{quantity1}\")\n",
    "    ax.set_ylabel(f\"{quantity2}\")\n",
    "    ax.set_title(f\"{quantity1} vs {quantity2} {label[i]}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_bin, max_bin = min(np.min(tau21_id1), np.min(tau21_c1), np.min(tau21_v1)), max(\n",
    "    np.max(tau21_id1), np.max(tau21_c1), np.max(tau21_v1)\n",
    ")\n",
    "min_bin1, max_bin2 = min(np.min(tau21_id2), np.min(tau21_c2), np.min(tau21_v2)), max(\n",
    "    np.max(tau21_id2), np.max(tau21_c2), np.max(tau21_v2)\n",
    ")\n",
    "\n",
    "bins = 30\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].hist(tau21_id1, bins=bins, alpha=0.5, label=\"Ideal\", range=(min_bin, max_bin))\n",
    "axs[0].hist(tau21_c1, bins=bins, label=\"FM\", histtype=\"step\", range=(min_bin, max_bin))\n",
    "axs[0].hist(tau21_v1, bins=bins, label=\"Vinicius\", histtype=\"step\", range=(min_bin, max_bin))\n",
    "axs[0].legend(frameon=False)\n",
    "axs[0].set_xlabel(r\"$\\tau_{21}$ jet1\")\n",
    "\n",
    "axs[1].hist(tau21_id2, bins=bins, alpha=0.5, label=\"Ideal\", range=(min_bin, max_bin))\n",
    "axs[1].hist(tau21_c2, bins=bins, label=\"FM\", histtype=\"step\", range=(min_bin, max_bin))\n",
    "axs[1].hist(tau21_v2, bins=bins, label=\"Vinicius\", histtype=\"step\", range=(min_bin, max_bin))\n",
    "axs[1].legend(frameon=False)\n",
    "axs[1].set_xlabel(r\"$\\tau_{21}$ jet2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = [tau32_id1, tau32_c1, tau32_v1]\n",
    "data_y = [tau32_id2, tau32_c2, tau32_v2]\n",
    "label = [\"ideal\", \"FM\", \"vinicius\"]\n",
    "quantity1 = r\"$\\tau_{32}$ jet1\"\n",
    "quantity2 = r\"$\\tau_{32}$ jet2\"\n",
    "min_bin_x, max_bin_x = min(np.min(data_x[0]), np.min(data_x[1]), np.min(data_x[2])), max(\n",
    "    np.max(data_x[0]), np.max(data_x[1]), np.max(data_x[2])\n",
    ")\n",
    "min_bin_y, max_bin_y = min(np.min(data_y[0]), np.min(data_y[1]), np.min(data_y[2])), max(\n",
    "    np.max(data_y[0]), np.max(data_y[1]), np.max(data_y[2])\n",
    ")\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 5))\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.hist2d(\n",
    "        data_x[i],\n",
    "        data_y[i],\n",
    "        bins=25,\n",
    "        cmap=\"jet\",\n",
    "        range=[[min_bin_x, max_bin_x], [min_bin_y, max_bin_y]],\n",
    "    )\n",
    "    ax.set_xlabel(f\"{quantity1}\")\n",
    "    ax.set_ylabel(f\"{quantity2}\")\n",
    "    ax.set_title(f\"{quantity1} vs {quantity2} {label[i]}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_bin, max_bin = min(np.min(tau32_id1), np.min(tau32_c1), np.min(tau32_v1)), max(\n",
    "    np.max(tau32_id1), np.max(tau32_c1), np.max(tau32_v1)\n",
    ")\n",
    "min_bin1, max_bin2 = min(np.min(tau32_id2), np.min(tau32_c2), np.min(tau32_v2)), max(\n",
    "    np.max(tau32_id2), np.max(tau32_c2), np.max(tau32_v2)\n",
    ")\n",
    "\n",
    "bins = 30\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].hist(tau32_id1, bins=bins, alpha=0.5, label=\"Ideal\", range=(min_bin, max_bin))\n",
    "axs[0].hist(tau32_c1, bins=bins, label=\"FM\", histtype=\"step\", range=(min_bin, max_bin))\n",
    "axs[0].hist(tau32_v1, bins=bins, label=\"Vinicius\", histtype=\"step\", range=(min_bin, max_bin))\n",
    "axs[0].legend(frameon=False)\n",
    "axs[0].set_xlabel(r\"$\\tau_{32}$ jet1\")\n",
    "\n",
    "axs[1].hist(tau32_id2, bins=bins, alpha=0.5, label=\"Ideal\", range=(min_bin, max_bin))\n",
    "axs[1].hist(tau32_c2, bins=bins, label=\"FM\", histtype=\"step\", range=(min_bin, max_bin))\n",
    "axs[1].hist(tau32_v2, bins=bins, label=\"Vinicius\", histtype=\"step\", range=(min_bin, max_bin))\n",
    "axs[1].legend(frameon=False)\n",
    "axs[1].set_xlabel(r\"$\\tau_{32}$ jet2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = [tau21_id1, tau21_c1, tau21_v1]\n",
    "data_y = [d2_id2, d2_c2, d2_v2]\n",
    "label = [\"ideal\", \"FM\", \"vinicius\"]\n",
    "quantity1 = r\"$\\tau_{21}$ jet1\"\n",
    "quantity2 = r\"$d2$ jet2\"\n",
    "min_bin_x, max_bin_x = min(np.min(data_x[0]), np.min(data_x[1]), np.min(data_x[2])), max(\n",
    "    np.max(data_x[0]), np.max(data_x[1]), np.max(data_x[2])\n",
    ")\n",
    "min_bin_y, max_bin_y = min(np.min(data_y[0]), np.min(data_y[1]), np.min(data_y[2])), max(\n",
    "    np.max(data_y[0]), np.max(data_y[1]), np.max(data_y[2])\n",
    ")\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 5))\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.hist2d(\n",
    "        data_x[i],\n",
    "        data_y[i],\n",
    "        bins=25,\n",
    "        cmap=\"jet\",\n",
    "        range=[[min_bin_x, max_bin_x], [min_bin_y, max_bin_y]],\n",
    "    )\n",
    "    ax.set_xlabel(f\"{quantity1}\")\n",
    "    ax.set_ylabel(f\"{quantity2}\")\n",
    "    ax.set_title(f\"{quantity1} vs {quantity2} {label[i]}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_bin, max_bin = min(np.min(d2_id1), np.min(d2_c1), np.min(d2_v1)), max(\n",
    "    np.max(d2_id1), np.max(d2_c1), np.max(d2_v1)\n",
    ")\n",
    "min_bin1, max_bin2 = min(np.min(d2_id2), np.min(d2_c2), np.min(d2_v2)), max(\n",
    "    np.max(d2_id2), np.max(d2_c2), np.max(d2_v2)\n",
    ")\n",
    "\n",
    "bins = 30\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].hist(d2_id1, bins=bins, alpha=0.5, label=\"Ideal\", range=(min_bin, max_bin))\n",
    "axs[0].hist(d2_c1, bins=bins, label=\"FM\", histtype=\"step\", range=(min_bin, max_bin))\n",
    "axs[0].hist(d2_v1, bins=bins, label=\"Vinicius\", histtype=\"step\", range=(min_bin, max_bin))\n",
    "axs[0].legend(frameon=False)\n",
    "axs[0].set_xlabel(r\"$d2$ jet1\")\n",
    "\n",
    "axs[1].hist(d2_id2, bins=bins, alpha=0.5, label=\"Ideal\", range=(min_bin, max_bin))\n",
    "axs[1].hist(d2_c2, bins=bins, label=\"FM\", histtype=\"step\", range=(min_bin, max_bin))\n",
    "axs[1].hist(d2_v2, bins=bins, label=\"Vinicius\", histtype=\"step\", range=(min_bin, max_bin))\n",
    "axs[1].legend(frameon=False)\n",
    "axs[1].set_xlabel(r\"$d2$ jet2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = [deltaR_id_plot, deltaR_c_plot, deltaR_v_plot]\n",
    "data_y = [pt_1_id_plot, pt_1_c_plot, pt_1_v_plot]\n",
    "label = [\"ideal\", \"FM\", \"vinicius\"]\n",
    "quantity1 = r\"$\\Delta R$\"\n",
    "quantity2 = r\"$p_T$ jet2\"\n",
    "min_bin_x, max_bin_x = min(np.min(data_x[0]), np.min(data_x[1]), np.min(data_x[2])), max(\n",
    "    np.max(data_x[0]), np.max(data_x[1]), np.max(data_x[2])\n",
    ")\n",
    "min_bin_y, max_bin_y = min(np.min(data_y[0]), np.min(data_y[1]), np.min(data_y[2])), max(\n",
    "    np.max(data_y[0]), np.max(data_y[1]), np.max(data_y[2])\n",
    ")\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 5))\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.hist2d(\n",
    "        data_x[i],\n",
    "        data_y[i],\n",
    "        bins=25,\n",
    "        cmap=\"jet\",\n",
    "        range=[[min_bin_x, max_bin_x], [min_bin_y, max_bin_y]],\n",
    "    )\n",
    "    ax.set_xlabel(f\"{quantity1}\")\n",
    "    ax.set_ylabel(f\"{quantity2}\")\n",
    "    ax.set_title(f\"{quantity1} vs {quantity2} {label[i]}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = [delta_tau21_id, delta_tau21_c, delta_tau21_v]\n",
    "data_y = [mass_1_id_plot, mass_1_c_plot, mass_1_v_plot]\n",
    "label = [\"ideal\", \"FM\", \"vinicius\"]\n",
    "quantity1 = r\"$\\Delta \\tau_{21}$\"\n",
    "quantity2 = r\"$p_T$ jet1\"\n",
    "min_bin_x, max_bin_x = min(np.min(data_x[0]), np.min(data_x[1]), np.min(data_x[2])), max(\n",
    "    np.max(data_x[0]), np.max(data_x[1]), np.max(data_x[2])\n",
    ")\n",
    "min_bin_y, max_bin_y = min(np.min(data_y[0]), np.min(data_y[1]), np.min(data_y[2])), max(\n",
    "    np.max(data_y[0]), np.max(data_y[1]), np.max(data_y[2])\n",
    ")\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 5))\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.hist2d(\n",
    "        data_x[i],\n",
    "        data_y[i],\n",
    "        bins=25,\n",
    "        cmap=\"jet\",\n",
    "        range=[[min_bin_x, max_bin_x], [min_bin_y, max_bin_y]],\n",
    "    )\n",
    "    ax.set_xlabel(f\"{quantity1}\")\n",
    "    ax.set_ylabel(f\"{quantity2}\")\n",
    "    ax.set_title(f\"{quantity1} vs {quantity2} {label[i]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## correlation plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tau21_c1.shape)\n",
    "print(tau21_c2.shape)\n",
    "print(delta_pt_jet_c_plot.shape)\n",
    "print(deltaR_c_plot.shape)\n",
    "print(calc_mjj_c_plot.shape)\n",
    "print(calc_jet_features_c_plot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names_list = [\"tau21_1\", \"tau21_2\", \"tau32_1\", \"tau32_2\", \"d2_1\", \"d2_2\", \"delta_tau21\", \"delta_tau32\", \"delta_d2\", \"delta_pt_jet\", \"deltaR\", \"mjj\", \"mass_1\", \"mass_2\", \"pt_1\", \"pt_2\", \"eta_1\", \"eta_2\", \"phi_1\", \"phi_2\"]\n",
    "names_list = [\n",
    "    r\"$\\tau_{21,1}$\",\n",
    "    r\"$\\tau_{21,2}$\",\n",
    "    r\"$\\tau_{32,1}$\",\n",
    "    r\"$\\tau_{32,2}$\",\n",
    "    r\"$d_{2,1}$\",\n",
    "    r\"$d_{2,2}$\",\n",
    "    r\"$\\Delta \\tau_{21}$\",\n",
    "    r\"$\\Delta \\tau_{32}$\",\n",
    "    r\"$\\Delta d_2$\",\n",
    "    r\"$\\Delta p_T$\",\n",
    "    r\"$\\Delta R$\",\n",
    "    r\"$m_{jj}$\",\n",
    "    r\"$m_1$\",\n",
    "    r\"$m_2$\",\n",
    "    r\"$p_{T,1}$\",\n",
    "    r\"$p_{T,2}$\",\n",
    "    r\"$\\eta_1$\",\n",
    "    r\"$\\eta_2$\",\n",
    "    r\"$\\phi_1$\",\n",
    "    r\"$\\phi_2$\",\n",
    "    r\"$N_1$\",\n",
    "    r\"$N_2$\",\n",
    "]\n",
    "data_list_id = [\n",
    "    tau21_id1,\n",
    "    tau21_id2,\n",
    "    tau32_id1,\n",
    "    tau32_id2,\n",
    "    d2_id1,\n",
    "    d2_id2,\n",
    "    delta_tau21_id,\n",
    "    delta_tau32_id,\n",
    "    delta_d2_id,\n",
    "    delta_pt_jet_id_plot,\n",
    "    deltaR_id_plot,\n",
    "    calc_mjj_id_plot,\n",
    "    mass_1_id_plot,\n",
    "    mass_2_id_plot,\n",
    "    pt_1_id_plot,\n",
    "    pt_2_id_plot,\n",
    "    eta_1_id_plot,\n",
    "    eta_2_id_plot,\n",
    "    phi_1_id_plot,\n",
    "    phi_2_id_plot,\n",
    "    multiplicity_1_id_plot,\n",
    "    multiplicity_2_id_plot,\n",
    "]\n",
    "data_list_c = [\n",
    "    tau21_c1,\n",
    "    tau21_c2,\n",
    "    tau32_c1,\n",
    "    tau32_c2,\n",
    "    d2_c1,\n",
    "    d2_c2,\n",
    "    delta_tau21_c,\n",
    "    delta_tau32_c,\n",
    "    delta_d2_c,\n",
    "    delta_pt_jet_c_plot,\n",
    "    deltaR_c_plot,\n",
    "    calc_mjj_c_plot,\n",
    "    mass_1_c_plot,\n",
    "    mass_2_c_plot,\n",
    "    pt_1_c_plot,\n",
    "    pt_2_c_plot,\n",
    "    eta_1_c_plot,\n",
    "    eta_2_c_plot,\n",
    "    phi_1_c_plot,\n",
    "    phi_2_c_plot,\n",
    "    multiplicity_1_c_plot,\n",
    "    multiplicity_2_c_plot,\n",
    "]\n",
    "data_list_v = [\n",
    "    tau21_v1,\n",
    "    tau21_v2,\n",
    "    tau32_v1,\n",
    "    tau32_v2,\n",
    "    d2_v1,\n",
    "    d2_v2,\n",
    "    delta_tau21_v,\n",
    "    delta_tau32_v,\n",
    "    delta_d2_v,\n",
    "    delta_pt_jet_v_plot,\n",
    "    deltaR_v_plot,\n",
    "    calc_mjj_v_plot,\n",
    "    mass_1_v_plot,\n",
    "    mass_2_v_plot,\n",
    "    pt_1_v_plot,\n",
    "    pt_2_v_plot,\n",
    "    eta_1_v_plot,\n",
    "    eta_2_v_plot,\n",
    "    phi_1_v_plot,\n",
    "    phi_2_v_plot,\n",
    "    multiplicity_1_v_plot,\n",
    "    multiplicity_2_v_plot,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_list = [\n",
    "    r\"$\\tau_{21,1}$\",\n",
    "    r\"$\\tau_{21,2}$\",\n",
    "    r\"$m_1^{gen}$\",\n",
    "    r\"$m_2^{gen}$\",\n",
    "    r\"$p_{T,1}^{gen}$\",\n",
    "    r\"$p_{T,2}^{gen}$\",\n",
    "    r\"$\\eta_1^{gen}$\",\n",
    "    r\"$\\eta_2^{gen}$\",\n",
    "    r\"$\\phi_1^{gen}$\",\n",
    "    r\"$\\phi_2^{gen}$\",\n",
    "    r\"$N_1^{gen}$\",\n",
    "    r\"$N_2^{gen}$\",\n",
    "    r\"$m_1^{cond}$\",\n",
    "    r\"$m_2^{cond}$\",\n",
    "    r\"$p_{T,1}^{cond}$\",\n",
    "    r\"$p_{T,2}^{cond}$\",\n",
    "    r\"$\\eta_1^{cond}$\",\n",
    "    r\"$\\eta_2^{cond}$\",\n",
    "    r\"$\\phi_1^{cond}$\",\n",
    "    r\"$\\phi_2^{cond}$\",\n",
    "    r\"$N_1^{cond}$\",\n",
    "    r\"$N_2^{cond}$\",\n",
    "]\n",
    "data_list_id = [\n",
    "    tau21_id1,\n",
    "    tau21_id2,\n",
    "    mass_1_id_plot,\n",
    "    mass_2_id_plot,\n",
    "    pt_1_id_plot,\n",
    "    pt_2_id_plot,\n",
    "    eta_1_id_plot,\n",
    "    eta_2_id_plot,\n",
    "    phi_1_id_plot,\n",
    "    phi_2_id_plot,\n",
    "    multiplicity_1_id_plot,\n",
    "    multiplicity_2_id_plot,\n",
    "    mass_1_id_plot_cond,\n",
    "    mass_2_id_plot_cond,\n",
    "    pt_1_id_plot_cond,\n",
    "    pt_2_id_plot_cond,\n",
    "    eta_1_id_plot_cond,\n",
    "    eta_2_id_plot_cond,\n",
    "    phi_1_id_plot_cond,\n",
    "    phi_2_id_plot_cond,\n",
    "    multiplicity_1_id_plot_cond,\n",
    "    multiplicity_2_id_plot_cond,\n",
    "]\n",
    "data_list_c = [\n",
    "    tau21_c1,\n",
    "    tau21_c2,\n",
    "    mass_1_c_plot,\n",
    "    mass_2_c_plot,\n",
    "    pt_1_c_plot,\n",
    "    pt_2_c_plot,\n",
    "    eta_1_c_plot,\n",
    "    eta_2_c_plot,\n",
    "    phi_1_c_plot,\n",
    "    phi_2_c_plot,\n",
    "    multiplicity_1_c_plot,\n",
    "    multiplicity_2_c_plot,\n",
    "    mass_1_c_plot_cond,\n",
    "    mass_2_c_plot_cond,\n",
    "    pt_1_c_plot_cond,\n",
    "    pt_2_c_plot_cond,\n",
    "    eta_1_c_plot_cond,\n",
    "    eta_2_c_plot_cond,\n",
    "    phi_1_c_plot_cond,\n",
    "    phi_2_c_plot_cond,\n",
    "    multiplicity_1_c_plot_cond,\n",
    "    multiplicity_2_c_plot_cond,\n",
    "]\n",
    "data_list_v = [\n",
    "    tau21_v1,\n",
    "    tau21_v2,\n",
    "    mass_1_v_plot,\n",
    "    mass_2_v_plot,\n",
    "    pt_1_v_plot,\n",
    "    pt_2_v_plot,\n",
    "    eta_1_v_plot,\n",
    "    eta_2_v_plot,\n",
    "    phi_1_v_plot,\n",
    "    phi_2_v_plot,\n",
    "    multiplicity_1_v_plot,\n",
    "    multiplicity_2_v_plot,\n",
    "    mass_1_v_plot_cond,\n",
    "    mass_2_v_plot_cond,\n",
    "    pt_1_v_plot_cond,\n",
    "    pt_2_v_plot_cond,\n",
    "    eta_1_v_plot_cond,\n",
    "    eta_2_v_plot_cond,\n",
    "    phi_1_v_plot_cond,\n",
    "    phi_2_v_plot_cond,\n",
    "    multiplicity_1_v_plot_cond,\n",
    "    multiplicity_2_v_plot_cond,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.DataFrame(data=np.vstack(data_list_id).transpose(), columns=names_list)\n",
    "correlations_full = df_data.corr()\n",
    "upper_triangle = np.ones((len(names_list), len(names_list)))\n",
    "upper_triangle[np.triu_indices(len(names_list), 1)] = 0.0\n",
    "correlations = correlations_full.mask(upper_triangle == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_cor = plt.figure(figsize=(20, 20))\n",
    "ax_cor = fig_cor.add_subplot(1, 1, 1)\n",
    "g = sns_plot = sns.heatmap(\n",
    "    (correlations),\n",
    "    xticklabels=correlations.columns,\n",
    "    yticklabels=correlations.index,\n",
    "    cmap=sns.diverging_palette(5, 250, as_cmap=True),\n",
    "    annot=True,\n",
    "    ax=ax_cor,\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    annot_kws={\"size\": 14},\n",
    "    fmt=\".2f\",\n",
    "    square=True,\n",
    "    cbar=False,\n",
    "    linewidths=0,\n",
    "    linecolor=\"black\",\n",
    ")\n",
    "plt.title(\"Ideal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_c = pd.DataFrame(data=np.vstack(data_list_c).transpose(), columns=names_list)\n",
    "correlations_full_c = df_data_c.corr()\n",
    "upper_triangle_c = np.ones((len(names_list), len(names_list)))\n",
    "upper_triangle_c[np.triu_indices(len(names_list), 1)] = 0.0\n",
    "correlations_c = correlations_full_c.mask(upper_triangle_c == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_cor_c = plt.figure(figsize=(20, 20))\n",
    "ax_cor_c = fig_cor_c.add_subplot(1, 1, 1)\n",
    "g_c = sns_plot_c = sns.heatmap(\n",
    "    (correlations_c),\n",
    "    xticklabels=correlations_c.columns,\n",
    "    yticklabels=correlations_c.index,\n",
    "    cmap=sns.diverging_palette(5, 250, as_cmap=True),\n",
    "    annot=True,\n",
    "    ax=ax_cor_c,\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    annot_kws={\"size\": 14},\n",
    "    fmt=\".2f\",\n",
    "    square=True,\n",
    "    cbar=False,\n",
    "    linewidths=0,\n",
    "    linecolor=\"black\",\n",
    ")\n",
    "plt.title(\"FM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_v = pd.DataFrame(data=np.vstack(data_list_v).transpose(), columns=names_list)\n",
    "correlations_full_v = df_data_v.corr()\n",
    "upper_triangle_v = np.ones((len(names_list), len(names_list)))\n",
    "upper_triangle_v[np.triu_indices(len(names_list), 1)] = 0.0\n",
    "correlations_v = correlations_full_v.mask(upper_triangle_v == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_cor_v = plt.figure(figsize=(20, 20))\n",
    "ax_cor_v = fig_cor_v.add_subplot(1, 1, 1)\n",
    "g_v = sns_plot_v = sns.heatmap(\n",
    "    (correlations_v),\n",
    "    xticklabels=correlations_v.columns,\n",
    "    yticklabels=correlations_v.index,\n",
    "    cmap=sns.diverging_palette(5, 250, as_cmap=True),\n",
    "    annot=True,\n",
    "    ax=ax_cor_v,\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    annot_kws={\"size\": 14},\n",
    "    fmt=\".2f\",\n",
    "    square=True,\n",
    "    cbar=False,\n",
    "    linewidths=0,\n",
    "    linecolor=\"black\",\n",
    ")\n",
    "plt.title(\"Vinicius\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations_diff = correlations - correlations_c\n",
    "fig_cor_diff = plt.figure(figsize=(20, 20))\n",
    "ax_cor_diff = fig_cor_diff.add_subplot(1, 1, 1)\n",
    "g_diff = sns_plot_diff = sns.heatmap(\n",
    "    (correlations_diff),\n",
    "    xticklabels=correlations_diff.columns,\n",
    "    yticklabels=correlations_diff.index,\n",
    "    cmap=sns.diverging_palette(5, 250, as_cmap=True),\n",
    "    annot=True,\n",
    "    ax=ax_cor_diff,\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    annot_kws={\"size\": 14},\n",
    "    fmt=\".2f\",\n",
    "    square=True,\n",
    "    cbar=False,\n",
    "    linewidths=0,\n",
    "    linecolor=\"black\",\n",
    ")\n",
    "plt.title(\"Correlation difference between ideal and FM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations_diff_v = correlations - correlations_v\n",
    "fig_cor_diff_v = plt.figure(figsize=(20, 20))\n",
    "ax_cor_diff_v = fig_cor_diff_v.add_subplot(1, 1, 1)\n",
    "g_diff_v = sns_plot_diff_v = sns.heatmap(\n",
    "    (correlations_diff_v),\n",
    "    xticklabels=correlations_diff_v.columns,\n",
    "    yticklabels=correlations_diff_v.index,\n",
    "    cmap=sns.diverging_palette(5, 250, as_cmap=True),\n",
    "    annot=True,\n",
    "    ax=ax_cor_diff_v,\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    annot_kws={\"size\": 14},\n",
    "    fmt=\".2f\",\n",
    "    square=True,\n",
    "    cbar=False,\n",
    "    linewidths=0,\n",
    "    linecolor=\"black\",\n",
    ")\n",
    "plt.title(\"Correlation difference between ideal and Vincius\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## substructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "\n",
    "def plot_single_jets(\n",
    "    data: np.ndarray,\n",
    "    color: str = \"#E2001A\",\n",
    "    save_folder: str = \"logs/\",\n",
    "    save_name: str = \"sim_jets\",\n",
    "    title: str = \"Simulated Jets\",\n",
    ") -> plt.figure:\n",
    "    \"\"\"Create a plot with 16 randomly selected jets from the data.\n",
    "\n",
    "    Args:\n",
    "        data (_type_): Data to plot.\n",
    "        color (str, optional): Color of plotted point cloud. Defaults to \"#E2001A\".\n",
    "        save_folder (str, optional): Path to folder where the plot is saved. Defaults to \"logs/\".\n",
    "        save_name (str, optional): File_name for saving the plot. Defaults to \"sim_jets\".\n",
    "    \"\"\"\n",
    "    mask_data = np.ma.masked_where(\n",
    "        data[:, :, 0] == 0,\n",
    "        data[:, :, 0],\n",
    "    )\n",
    "    mask = np.expand_dims(mask_data, axis=-1)\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    gs = GridSpec(1, 1)\n",
    "    ax = fig.add_subplot(gs[0])\n",
    "    for i in range(10):\n",
    "\n",
    "        idx = np.random.randint(len(data))\n",
    "        x_plot = data[idx, :, :2]  # .cpu()\n",
    "        s_plot = np.abs(data[idx, :, 2])  # .cpu())\n",
    "        # s_plot[mask[idx, :, 0] < 0.0] = 0.0\n",
    "\n",
    "        ax.scatter(*x_plot.T, s=5000 * s_plot, color=color, alpha=0.5)\n",
    "\n",
    "    ax.set_xlabel(r\"$\\eta$\")\n",
    "    ax.set_ylabel(r\"$\\phi$\")\n",
    "\n",
    "    ax.set_xlim(-1, 1)\n",
    "    ax.set_ylim(-1, 1)\n",
    "    ax.set_title(title)\n",
    "\n",
    "    # plt.show()\n",
    "    # plt.tight_layout()\n",
    "\n",
    "    # plt.savefig(f\"{save_folder}{save_name}.png\", bbox_inches=\"tight\")\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "\n",
    "def plot_single_jets2(\n",
    "    data: np.ndarray,\n",
    "    color: str = \"#E2001A\",\n",
    "    save_folder: str = \"logs/\",\n",
    "    save_name: str = \"sim_jets\",\n",
    "    title: str = \"Simulated Jets\",\n",
    ") -> plt.figure:\n",
    "    \"\"\"Create a plot with 16 randomly selected jets from the data.\n",
    "\n",
    "    Args:\n",
    "        data (_type_): Data to plot.\n",
    "        color (str, optional): Color of plotted point cloud. Defaults to \"#E2001A\".\n",
    "        save_folder (str, optional): Path to folder where the plot is saved. Defaults to \"logs/\".\n",
    "        save_name (str, optional): File_name for saving the plot. Defaults to \"sim_jets\".\n",
    "    \"\"\"\n",
    "    mask_data = np.ma.masked_where(\n",
    "        data[:, :, 0] == 0,\n",
    "        data[:, :, 0],\n",
    "    )\n",
    "    mask = np.expand_dims(mask_data, axis=-1)\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    gs = GridSpec(1, 1)\n",
    "    ax = fig.add_subplot(gs[0])\n",
    "    # for i in range(10):\n",
    "\n",
    "    # idx = np.random.randint(len(data))\n",
    "    x_plot = data[:, :, :2]  # .cpu()\n",
    "    s_plot = np.abs(data[:, :, 2])  # .cpu())\n",
    "    # s_plot[mask[idx, :, 0] < 0.0] = 0.0\n",
    "\n",
    "    ax.hist2d(\n",
    "        x_plot[:, :, 0].flatten(),\n",
    "        x_plot[:, :, 1].flatten(),\n",
    "        weights=s_plot.flatten(),\n",
    "        bins=100,\n",
    "        norm=LogNorm(),\n",
    "    )\n",
    "    # ax.scatter(*x_plot.T, s=5000 * s_plot, color=color, alpha=0.5)\n",
    "    # ax.loglog()\n",
    "    ax.set_xlabel(r\"$\\eta$\")\n",
    "    ax.set_ylabel(r\"$\\phi$\")\n",
    "\n",
    "    ax.set_xlim(-0.3, 0.3)\n",
    "    ax.set_ylim(-0.3, 0.3)\n",
    "    ax.set_title(title)\n",
    "\n",
    "    # plt.show()\n",
    "    # plt.tight_layout()\n",
    "\n",
    "    # plt.savefig(f\"{save_folder}{save_name}.png\", bbox_inches=\"tight\")\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = plot_single_jets(particle_data_id[:, 0][..., [1, 2, 0]], color=\"blue\", title=\"Idealized Jets\")\n",
    "t = plot_single_jets2(particle_data_id[:, 0][..., [1, 2, 0]], color=\"blue\", title=\"Idealized Jets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = plot_single_jets(false_p[:, 0][..., [1, 2, 0]], color=\"red\", title=\"False predictions\")\n",
    "t = plot_single_jets2(false_p[:, 0][..., [1, 2, 0]], color=\"red\", title=\"False predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = plot_single_jets(\n",
    "    correct_p[:, 0][..., [1, 2, 0]], color=\"green\", title=\"Correct predictions (no fooling)\"\n",
    ")\n",
    "t = plot_single_jets2(\n",
    "    correct_p[:, 0][..., [1, 2, 0]], color=\"green\", title=\"Correct predictions (no fooling)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## substructure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_hlvs(\n",
    "    np.reshape(\n",
    "        correct_p[..., [1, 2, 0]], (-1, correct_p.shape[-2], correct_p.shape[-1]), order=\"F\"\n",
    "    )[:10000],\n",
    "    \"/beegfs/desy/user/ewencedr/data/lhco/substructure/notebook_correct\",\n",
    "    plot=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_hlvs(\n",
    "    np.reshape(false_p[..., [1, 2, 0]], (-1, false_p.shape[-2], false_p.shape[-1]), order=\"F\")[\n",
    "        :10000\n",
    "    ],\n",
    "    \"/beegfs/desy/user/ewencedr/data/lhco/substructure/notebook_false\",\n",
    "    plot=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_hlvs(\n",
    "    np.reshape(\n",
    "        particle_data_id[..., [1, 2, 0]],\n",
    "        (-1, particle_data_id.shape[-2], particle_data_id.shape[-1]),\n",
    "        order=\"F\",\n",
    "    )[:10000],\n",
    "    \"/beegfs/desy/user/ewencedr/data/lhco/substructure/notebook_id2\",\n",
    "    plot=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load substructure for id data\n",
    "data_substructure_id = []\n",
    "with h5py.File(\"/beegfs/desy/user/ewencedr/data/lhco/substructure/notebook_id2\" + \".h5\", \"r\") as f:\n",
    "    tau21_jetnet = np.array(f[\"tau21\"])\n",
    "    tau32_jetnet = np.array(f[\"tau32\"])\n",
    "    d2_jetnet = np.array(f[\"d2\"])\n",
    "    for key in f.keys():\n",
    "        data_substructure_id.append(np.array(f[key]))\n",
    "data_substructure_jetnet = np.array(data_substructure_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load substructure for model generated data\n",
    "keys = []\n",
    "data_substructure_c = []\n",
    "with h5py.File(\n",
    "    \"/beegfs/desy/user/ewencedr/data/lhco/substructure/notebook_correct\" + \".h5\", \"r\"\n",
    ") as f:\n",
    "    tau21_c = np.array(f[\"tau21\"])\n",
    "    tau32_c = np.array(f[\"tau32\"])\n",
    "    d2_c = np.array(f[\"d2\"])\n",
    "    for key in f.keys():\n",
    "        keys.append(key)\n",
    "        data_substructure_c.append(np.array(f[key]))\n",
    "keys = np.array(keys)\n",
    "data_substructure_c = np.array(data_substructure_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load substructure for model generated data\n",
    "keys = []\n",
    "data_substructure_f = []\n",
    "with h5py.File(\n",
    "    \"/beegfs/desy/user/ewencedr/data/lhco/substructure/notebook_false\" + \".h5\", \"r\"\n",
    ") as f:\n",
    "    tau21_f = np.array(f[\"tau21\"])\n",
    "    tau32_f = np.array(f[\"tau32\"])\n",
    "    d2_f = np.array(f[\"d2\"])\n",
    "    for key in f.keys():\n",
    "        keys.append(key)\n",
    "        data_substructure_f.append(np.array(f[key]))\n",
    "keys = np.array(keys)\n",
    "data_substructure_f = np.array(data_substructure_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate wasserstein distances\n",
    "w_dist_tau21_mean, w_dist_tau21_std = wasserstein_distance_batched(\n",
    "    tau21_jetnet, tau21_jetnet, num_eval_samples=50_000, num_batches=40\n",
    ")\n",
    "w_dist_tau32_mean, w_dist_tau32_std = wasserstein_distance_batched(\n",
    "    tau32_jetnet, tau32_jetnet, num_eval_samples=50_000, num_batches=40\n",
    ")\n",
    "w_dist_d2_mean, w_dist_d2_std = wasserstein_distance_batched(\n",
    "    d2_jetnet, d2_jetnet, num_eval_samples=50_000, num_batches=40\n",
    ")\n",
    "print(f\"Wasserstein distance tau21: {w_dist_tau21_mean} +- {w_dist_tau21_std}\")\n",
    "print(f\"Wasserstein distance tau32: {w_dist_tau32_mean} +- {w_dist_tau32_std}\")\n",
    "print(f\"Wasserstein distance d2: {w_dist_d2_mean} +- {w_dist_d2_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate wasserstein distances\n",
    "w_dist_tau21_mean_c, w_dist_tau21_std_c = wasserstein_distance_batched(\n",
    "    tau21_jetnet, tau21_c, num_eval_samples=50_000, num_batches=40\n",
    ")\n",
    "w_dist_tau32_mean_c, w_dist_tau32_std_c = wasserstein_distance_batched(\n",
    "    tau32_jetnet, tau32_c, num_eval_samples=50_000, num_batches=40\n",
    ")\n",
    "w_dist_d2_mean_c, w_dist_d2_std_c = wasserstein_distance_batched(\n",
    "    d2_jetnet, d2_c, num_eval_samples=50_000, num_batches=40\n",
    ")\n",
    "print(f\"Wasserstein distance tau21: {w_dist_tau21_mean_c} +- {w_dist_tau21_std_c}\")\n",
    "print(f\"Wasserstein distance tau32: {w_dist_tau32_mean_c} +- {w_dist_tau32_std_c}\")\n",
    "print(f\"Wasserstein distance d2: {w_dist_d2_mean_c} +- {w_dist_d2_std_c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate wasserstein distances\n",
    "w_dist_tau21_mean_f, w_dist_tau21_std_f = wasserstein_distance_batched(\n",
    "    tau21_jetnet, tau21_f, num_eval_samples=50_000, num_batches=40\n",
    ")\n",
    "w_dist_tau32_mean_f, w_dist_tau32_std_f = wasserstein_distance_batched(\n",
    "    tau32_jetnet, tau32_f, num_eval_samples=50_000, num_batches=40\n",
    ")\n",
    "w_dist_d2_mean_f, w_dist_d2_std_f = wasserstein_distance_batched(\n",
    "    d2_jetnet, d2_f, num_eval_samples=50_000, num_batches=40\n",
    ")\n",
    "print(f\"Wasserstein distance tau21: {w_dist_tau21_mean_f} +- {w_dist_tau21_std_f}\")\n",
    "print(f\"Wasserstein distance tau32: {w_dist_tau32_mean_f} +- {w_dist_tau32_std_f}\")\n",
    "print(f\"Wasserstein distance d2: {w_dist_d2_mean_f} +- {w_dist_d2_std_f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_substructure(\n",
    "    tau21=tau21_c,\n",
    "    tau32=tau32_c,\n",
    "    d2=d2_c,\n",
    "    tau21_jetnet=tau21_jetnet,\n",
    "    tau32_jetnet=tau32_jetnet,\n",
    "    d2_jetnet=d2_jetnet,\n",
    "    save_fig=False,\n",
    "    save_folder=None,\n",
    "    save_name=None,\n",
    "    close_fig=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_substructure(\n",
    "    tau21=tau21_f,\n",
    "    tau32=tau32_f,\n",
    "    d2=d2_f,\n",
    "    tau21_jetnet=tau21_jetnet,\n",
    "    tau32_jetnet=tau32_jetnet,\n",
    "    d2_jetnet=d2_jetnet,\n",
    "    save_fig=False,\n",
    "    save_folder=None,\n",
    "    save_name=None,\n",
    "    close_fig=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_tau21_id = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_falseclassified = \"/beegfs/desy/user/ewencedr/data/lhco/generated/falseclassified.h5\"\n",
    "# with h5py.File(path_falseclassified, \"w\") as f:\n",
    "#    f.create_dataset(\"jet_features\", data=false_j)\n",
    "#    f.create_dataset(\"particle_features\", data=false_p)\n",
    "#    f.create_dataset(\"mjj\", data=false_mjj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for i, ax in enumerate(axs):\n",
    "    # min_bin, max_bin = min(np.min(false_p[..., i]), np.min(correct_p[...,i])), max(np.max(false_p[..., i]), np.max(correct_p[...,i]))\n",
    "    # bins = np.linspace(int(min_bin), int(max_bin), 100)\n",
    "    bins = 25\n",
    "    hist = ax.hist(\n",
    "        correct_p[..., i].flatten()[correct_p[..., i].flatten() != 0],\n",
    "        bins=bins,\n",
    "        label=\"correct\",\n",
    "        alpha=0.5,\n",
    "        density=True,\n",
    "    )\n",
    "    hist2 = ax.hist(\n",
    "        false_p[..., i].flatten()[false_p[..., i].flatten() != 0],\n",
    "        bins=hist[1],\n",
    "        label=\"false\",\n",
    "        histtype=\"step\",\n",
    "        color=\"red\",\n",
    "        density=True,\n",
    "    )\n",
    "    ax.legend()\n",
    "    ax.set_yscale(\"log\")\n",
    "    # ax.step(bins[:-1], hist / np.sum(hist), where=\"post\", label=\"correct\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"pt\", \"eta\", \"phi\", \"mass\", \"multiplicity\"]\n",
    "fig, axs = plt.subplots(1, 5, figsize=(25, 5))\n",
    "for i, ax in enumerate(axs):\n",
    "    # min_bin, max_bin = min(np.min(false_j[..., i]), np.min(correct_j[...,i])), max(np.max(false_j[..., i]), np.max(correct_j[...,i]))\n",
    "    # bins = np.linspace(int(min_bin), int(max_bin), 100)\n",
    "    if i == 4:\n",
    "        bins = range(0, 279)\n",
    "        ax.set_yscale(\"log\")\n",
    "    else:\n",
    "        bins = 50\n",
    "    hist = ax.hist(\n",
    "        correct_j[..., i].flatten()[correct_j[..., i].flatten() != 0],\n",
    "        bins=bins,\n",
    "        label=\"correct\",\n",
    "        alpha=0.5,\n",
    "        density=True,\n",
    "    )\n",
    "    hist2 = ax.hist(\n",
    "        false_j[..., i].flatten()[false_j[..., i].flatten() != 0],\n",
    "        bins=hist[1],\n",
    "        label=\"false\",\n",
    "        histtype=\"step\",\n",
    "        color=\"red\",\n",
    "        density=True,\n",
    "    )\n",
    "    ax.legend()\n",
    "    if i == 2:\n",
    "        ax.set_ylim(\n",
    "            0.001,\n",
    "        )\n",
    "    # ax.set_yscale(\"log\")\n",
    "    ax.set_xlabel(labels[i])\n",
    "    # ax.step(bins[:-1], hist / np.sum(hist), where=\"post\", label=\"correct\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(correct_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_p = correct_p[:len(false_p)]\n",
    "c_p = correct_p\n",
    "correct_p_flat = c_p.reshape(c_p.shape[0] * c_p.shape[1], -1)\n",
    "false_p_flat = false_p.reshape(false_p.shape[0] * false_p.shape[1], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(correct_p_flat.shape)\n",
    "print(false_p_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(93, 9, figsize=(45, 465))\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    min_bin, max_bin = min(np.min(false_p_flat[..., i]), np.min(correct_p_flat[..., i])), max(\n",
    "        np.max(false_p_flat[..., i]), np.max(correct_p_flat[..., i])\n",
    "    )\n",
    "    # bins = np.linspace(int(min_bin), int(max_bin), 100)\n",
    "    bins = 25\n",
    "    hist = ax.hist(\n",
    "        correct_p_flat[..., i].flatten()[correct_p_flat[..., i].flatten() != 0],\n",
    "        bins=bins,\n",
    "        alpha=0.5,\n",
    "        label=\"nofool\",\n",
    "        histtype=\"stepfilled\",\n",
    "        density=True,\n",
    "        range=(min_bin, max_bin),\n",
    "    )\n",
    "    ax.hist(\n",
    "        false_p_flat[..., i].flatten()[false_p_flat[..., i].flatten() != 0],\n",
    "        bins=hist[1],\n",
    "        label=\"fool\",\n",
    "        histtype=\"step\",\n",
    "        density=True,\n",
    "    )\n",
    "    # ax.hist(flat_data_v[...,i].flatten()[flat_data_v[..., i].flatten() != 0], bins=hist[1], label=\"Vini\", histtype=\"step\")\n",
    "\n",
    "    # [false_p_flat[..., i].flatten() != 0]\n",
    "    label = \"\"\n",
    "    if (i + 1) % 3 == 1:\n",
    "        label += \" pt\"\n",
    "        ax.set_yscale(\"log\")\n",
    "        # print(min_bin, max_bin)\n",
    "    if (i + 1) % 3 == 2:\n",
    "        label += \" eta\"\n",
    "        # ax.set_yscale(\"log\")\n",
    "    if (i + 1) % 3 == 0:\n",
    "        label += \" phi\"\n",
    "        # ax.set_yscale(\"log\")\n",
    "    # if i < flat_data_id.shape[-1]//2:\n",
    "    #    label += \" first jet\"\n",
    "    # else:\n",
    "    #    label += \" second jet\"\n",
    "    # ax.set_yscale(\"log\")\n",
    "    label += f\"{(i//3)}\"\n",
    "    # for j in range(particle_data_id.shape[-2]):\n",
    "    #    if (i+1) % ((j+1)*3) < 0:\n",
    "    #        label += f\" particle {i}\"\n",
    "    ax.set_xlabel(label)\n",
    "    ax.legend()\n",
    "plt.savefig(\"comparison_correctly_falsly_classified.pdf\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(93, 9, figsize=(45, 465))\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    # min_bin, max_bin = min(np.min(false_p_flat[..., i]), np.min(correct_p_flat[...,i])), max(np.max(false_p_flat[..., i]), np.max(correct_p_flat[...,i]))\n",
    "    # bins = np.linspace(int(min_bin), int(max_bin), 100)\n",
    "    bins = 100\n",
    "    hist = ax.hist(\n",
    "        correct_p_flat[..., i].flatten()[np.allclose(correct_p_flat[..., i].flatten(), 0)],\n",
    "        bins=bins,\n",
    "        alpha=0.5,\n",
    "        label=\"nofool\",\n",
    "        histtype=\"stepfilled\",\n",
    "        density=True,\n",
    "    )\n",
    "    ax.hist(\n",
    "        false_p_flat[..., i].flatten()[np.allclose(false_p_flat[..., i].flatten(), 0)],\n",
    "        bins=hist[1],\n",
    "        label=\"fool\",\n",
    "        histtype=\"step\",\n",
    "        density=True,\n",
    "    )\n",
    "    # ax.hist(flat_data_v[...,i].flatten()[flat_data_v[..., i].flatten() != 0], bins=hist[1], label=\"Vini\", histtype=\"step\")\n",
    "\n",
    "    # [false_p_flat[..., i].flatten() != 0]\n",
    "    label = \"\"\n",
    "    if (i + 1) % 3 == 1:\n",
    "        label += \" pt\"\n",
    "        ax.set_yscale(\"log\")\n",
    "        # print(min_bin, max_bin)\n",
    "    if (i + 1) % 3 == 2:\n",
    "        label += \" eta\"\n",
    "        # ax.set_yscale(\"log\")\n",
    "    if (i + 1) % 3 == 0:\n",
    "        label += \" phi\"\n",
    "        # ax.set_yscale(\"log\")\n",
    "    # if i < flat_data_id.shape[-1]//2:\n",
    "    #    label += \" first jet\"\n",
    "    # else:\n",
    "    #    label += \" second jet\"\n",
    "    # ax.set_yscale(\"log\")\n",
    "    label += f\"{(i//3)}\"\n",
    "    # for j in range(particle_data_id.shape[-2]):\n",
    "    #    if (i+1) % ((j+1)*3) < 0:\n",
    "    #        label += f\" particle {i}\"\n",
    "    ax.set_xlabel(label)\n",
    "    ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_gen = \"/beegfs/desy/user/ewencedr/data//lhco/generated/idealized_LHCO.h5\"\n",
    "with h5py.File(path_gen, \"r\") as f:\n",
    "    jet_data_gen = f[\"jet_features\"][:]\n",
    "    particle_data_gen = f[\"particle_features\"][:]\n",
    "\n",
    "jet_data_gen = jet_data_gen[..., :4]\n",
    "# particle_data_gen = particle_data_gen[..., [1, 2, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_gen = np.expand_dims(np.array(particle_data_gen[..., 0] != 0), axis=-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mask_gen.flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(particle_data_gen[..., 2].flatten(), bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_bckg = \"/beegfs/desy/user/ewencedr/data/lhco/final_data/processed_data_background_rel.h5\"\n",
    "\n",
    "with h5py.File(path_bckg, \"r\") as f:\n",
    "    jet_data_bckg = f[\"jet_data\"][:]\n",
    "    particle_data_bckg = f[\"constituents\"][:]\n",
    "    mask_bckg = f[\"mask\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut mjj window\n",
    "p4_jets_bckg = ef.p4s_from_ptyphims(jet_data_bckg)\n",
    "# get mjj from p4_jets\n",
    "sum_p4_bckg = p4_jets_bckg[:, 0] + p4_jets_bckg[:, 1]\n",
    "mjj_bckg = ef.ms_from_p4s(sum_p4_bckg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_to_keep_bckg = (mjj_bckg > 3300) & (mjj_bckg < 3700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_data_bckg = jet_data_bckg[args_to_keep_bckg]\n",
    "particle_data_bckg = particle_data_bckg[args_to_keep_bckg]\n",
    "mask_bckg = mask_bckg[args_to_keep_bckg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(jet_data_bckg))\n",
    "print(len(particle_data_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = plt.hist(particle_data_bckg[..., 2].flatten(), bins=100, histtype=\"step\", label=\"true\")\n",
    "plt.hist(particle_data_gen[..., 2].flatten(), bins=100, histtype=\"step\", label=\"gen\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare idealized vs fm data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_id = \"/beegfs/desy/user/ewencedr/data/lhco/generated/idealized_LHCO.h5\"\n",
    "with h5py.File(path_id, \"r\") as f:\n",
    "    jet_data_id = f[\"jet_features\"][:]\n",
    "    particle_data_id = f[\"particle_features\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_c = \"/beegfs/desy/user/ewencedr/data/lhco/generated/lhco-xy-10layer-256latent-logpt-nnew_sr-midpoint-300.h5\"\n",
    "with h5py.File(path_c, \"r\") as f:\n",
    "    jet_data_c = f[\"jet_features\"][:]\n",
    "    particle_data_c = f[\"particle_features\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_v = \"/beegfs/desy/user/ewencedr/data/lhco/generated/FPCD_LHCO_SR.h5\"\n",
    "with h5py.File(path_v, \"r\") as f:\n",
    "    jet_data_v = f[\"jet_features\"][:]\n",
    "    particle_data_v = f[\"particle_features\"][:]\n",
    "jet_data_v = jet_data_v[: len(jet_data_id)]\n",
    "particle_data_v = particle_data_v[: len(particle_data_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jet_data_id.shape)\n",
    "print(jet_data_c.shape)\n",
    "print(jet_data_v.shape)\n",
    "print(particle_data_id.shape)\n",
    "print(particle_data_c.shape)\n",
    "print(particle_data_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_calc = np.expand_dims(np.sum(particle_data_c[..., 0] != 0, axis=-1), axis=-1)\n",
    "bins = range(0, 279)\n",
    "plt.hist(pm_calc.flatten(), bins=bins)\n",
    "plt.hist(jet_data_id[..., 4].flatten(), bins=bins, histtype=\"step\")\n",
    "plt.hist(jet_data_v[..., 4].flatten(), bins=bins, histtype=\"step\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"pt\", \"eta\", \"phi\", \"mass\", \"multiplicity\"]\n",
    "fig, axs = plt.subplots(1, 5, figsize=(50, 10))\n",
    "for i, ax in enumerate(axs):\n",
    "    min_bin, max_bin = min(np.min(jet_data_id[..., i]), np.min(jet_data_c[..., i])), max(\n",
    "        np.max(jet_data_id[..., i]), np.max(jet_data_c[..., i])\n",
    "    )\n",
    "    if i == 4:\n",
    "        bins = range(0, 279)\n",
    "        ax.set_yscale(\"log\")\n",
    "    else:\n",
    "        bins = 100\n",
    "    hist = ax.hist(\n",
    "        jet_data_id[..., i].flatten(),\n",
    "        bins=bins,\n",
    "        alpha=0.5,\n",
    "        label=\"idealized\",\n",
    "        histtype=\"stepfilled\",\n",
    "        range=(min_bin, max_bin),\n",
    "    )\n",
    "    cycler = ax._get_lines.prop_cycler\n",
    "    next(cycler)\n",
    "    ax.hist(jet_data_c[..., i].flatten(), bins=hist[1], label=\"FM\", histtype=\"step\")\n",
    "    ax.hist(jet_data_v[..., i].flatten(), bins=hist[1], label=\"Vini\", histtype=\"step\")\n",
    "    ax.set_xlabel(labels[i])\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_pt(array):\n",
    "\n",
    "    pt = array[..., 0]\n",
    "    # print(pt[0,0,:10])\n",
    "    eta = array[..., 1]\n",
    "    phi = array[..., 2]\n",
    "    args = np.argsort(pt, axis=-1)[..., ::-1]\n",
    "    # print(pt.shape)\n",
    "    # print(args.shape)\n",
    "\n",
    "    pt2 = np.take_along_axis(pt, args, axis=-1)\n",
    "    # print(pt2[0,0,:10])\n",
    "    eta2 = np.take_along_axis(eta, args, axis=-1)\n",
    "    phi2 = np.take_along_axis(phi, args, axis=-1)\n",
    "    return np.stack([pt2, eta2, phi2], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particle_data_id = sort_pt(particle_data_id)\n",
    "particle_data_c = sort_pt(particle_data_c)\n",
    "particle_data_v = sort_pt(particle_data_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadJson(file_name):\n",
    "    import json\n",
    "\n",
    "    import yaml\n",
    "\n",
    "    JSONPATH = os.path.join(file_name)\n",
    "    return yaml.safe_load(open(JSONPATH))\n",
    "\n",
    "\n",
    "def preprocess(particle):\n",
    "    new_p = np.copy(particle).reshape((-1, particle.shape[-1]))\n",
    "\n",
    "    mask = new_p[:, 0] != 0\n",
    "    new_p[:, 0] = np.ma.log(1.0 - new_p[:, 0]).filled(0)\n",
    "    data_dict = LoadJson(\"/home/ewencedr/LHCO_diffusion/scripts/preprocessing_279.json\")\n",
    "    new_p = np.ma.divide(new_p - data_dict[\"mean_particle\"], data_dict[\"std_particle\"]).filled(0)\n",
    "    new_p *= np.expand_dims(mask, -1)\n",
    "    new_p = np.reshape(new_p, particle.shape)\n",
    "    return new_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particle_data_id = preprocess(particle_data_id)\n",
    "particle_data_c = preprocess(particle_data_c)\n",
    "particle_data_v = preprocess(particle_data_v)\n",
    "print(particle_data_id.shape)\n",
    "print(particle_data_c.shape)\n",
    "print(particle_data_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for i, ax in enumerate(axs):\n",
    "    # min_bin, max_bin = min(np.min(false_p[..., i]), np.min(correct_p[...,i])), max(np.max(false_p[..., i]), np.max(correct_p[...,i]))\n",
    "    # bins = np.linspace(int(min_bin), int(max_bin), 100)\n",
    "    bins = 25\n",
    "    hist = ax.hist(\n",
    "        particle_data_id[..., i].flatten()[particle_data_id[..., i].flatten() != 0],\n",
    "        bins=bins,\n",
    "        label=\"Truth\",\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    cycler = ax._get_lines.prop_cycler\n",
    "    next(cycler)\n",
    "    hist2 = ax.hist(\n",
    "        particle_data_c[..., i].flatten()[particle_data_c[..., i].flatten() != 0],\n",
    "        bins=hist[1],\n",
    "        label=\"FM\",\n",
    "        histtype=\"step\",\n",
    "    )\n",
    "    hist3 = ax.hist(\n",
    "        particle_data_v[..., i].flatten()[particle_data_v[..., i].flatten() != 0],\n",
    "        bins=hist[1],\n",
    "        label=\"Vinicius\",\n",
    "        histtype=\"step\",\n",
    "    )\n",
    "\n",
    "    ax.legend()\n",
    "    ax.set_yscale(\"log\")\n",
    "    # ax.step(bins[:-1], hist / np.sum(hist), where=\"post\", label=\"correct\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particle_data_c_full = particle_data_c.reshape(\n",
    "    particle_data_c.shape[0] * particle_data_c.shape[1], -1\n",
    ")\n",
    "particle_data_id_full = particle_data_id.reshape(\n",
    "    particle_data_id.shape[0] * particle_data_id.shape[1], -1\n",
    ")\n",
    "particle_data_v_full = particle_data_v.reshape(\n",
    "    particle_data_v.shape[0] * particle_data_v.shape[1], -1\n",
    ")\n",
    "\n",
    "print(particle_data_c_full.shape)\n",
    "print(particle_data_id_full.shape)\n",
    "print(particle_data_v_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(93, 9, figsize=(45, 465))\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    # min_bin, max_bin = min(np.min(particle_data_id_full[..., i]), np.min(particle_data_c_full[...,i])), max(np.max(particle_data_id_full[..., i]), np.max(particle_data_c_full[...,i]))\n",
    "    # bins = np.linspace(int(min_bin), int(max_bin), 100)\n",
    "    bins = 100\n",
    "    hist = ax.hist(\n",
    "        particle_data_id_full[..., i].flatten()[particle_data_id_full[..., i].flatten() != 0],\n",
    "        bins=bins,\n",
    "        alpha=0.5,\n",
    "        label=\"Truth\",\n",
    "        histtype=\"stepfilled\",\n",
    "    )\n",
    "    cycler = ax._get_lines.prop_cycler\n",
    "    next(cycler)\n",
    "    ax.hist(\n",
    "        particle_data_c_full[..., i].flatten()[particle_data_c_full[..., i].flatten() != 0],\n",
    "        bins=bins,\n",
    "        label=\"FM\",\n",
    "        histtype=\"step\",\n",
    "    )\n",
    "    ax.hist(\n",
    "        particle_data_v_full[..., i].flatten()[particle_data_v_full[..., i].flatten() != 0],\n",
    "        bins=bins,\n",
    "        label=\"Vini\",\n",
    "        histtype=\"step\",\n",
    "    )\n",
    "\n",
    "    # ax.hist(flat_data_v[...,i].flatten()[flat_data_v[..., i].flatten() != 0], bins=hist[1], label=\"Vini\", histtype=\"step\")\n",
    "\n",
    "    # [false_p_flat[..., i].flatten() != 0]\n",
    "    label = \"\"\n",
    "    if (i + 1) % 3 == 1:\n",
    "        label += \" pt\"\n",
    "        ax.set_yscale(\"log\")\n",
    "        # print(min_bin, max_bin)\n",
    "    if (i + 1) % 3 == 2:\n",
    "        label += \" eta\"\n",
    "        # ax.set_yscale(\"log\")\n",
    "    if (i + 1) % 3 == 0:\n",
    "        label += \" phi\"\n",
    "        # ax.set_yscale(\"log\")\n",
    "    # if i < flat_data_id.shape[-1]//2:\n",
    "    #    label += \" first jet\"\n",
    "    # else:\n",
    "    #    label += \" second jet\"\n",
    "    # ax.set_yscale(\"log\")\n",
    "    label += f\"{(i//3)}\"\n",
    "    # for j in range(particle_data_id.shape[-2]):\n",
    "    #    if (i+1) % ((j+1)*3) < 0:\n",
    "    #        label += f\" particle {i}\"\n",
    "    ax.set_xlabel(label)\n",
    "    ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(93, 9, figsize=(45, 465))\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    min_bin, max_bin = min(\n",
    "        np.min(particle_data_id_full[..., i]), np.min(particle_data_c_full[..., i])\n",
    "    ), max(np.max(particle_data_id_full[..., i]), np.max(particle_data_c_full[..., i]))\n",
    "    # bins = np.linspace(int(min_bin), int(max_bin), 100)\n",
    "    bins = 25\n",
    "    hist = ax.hist(\n",
    "        particle_data_id_full[..., i].flatten()[particle_data_id_full[..., i].flatten() != 0],\n",
    "        bins=bins,\n",
    "        alpha=0.5,\n",
    "        label=\"Truth\",\n",
    "        histtype=\"stepfilled\",\n",
    "        range=(min_bin, max_bin),\n",
    "    )\n",
    "    cycler = ax._get_lines.prop_cycler\n",
    "    next(cycler)\n",
    "    ax.hist(\n",
    "        particle_data_c_full[..., i].flatten()[particle_data_c_full[..., i].flatten() != 0],\n",
    "        bins=hist[1],\n",
    "        label=\"FM\",\n",
    "        histtype=\"step\",\n",
    "    )\n",
    "    ax.hist(\n",
    "        particle_data_v_full[..., i].flatten()[particle_data_v_full[..., i].flatten() != 0],\n",
    "        bins=hist[1],\n",
    "        label=\"Vini\",\n",
    "        histtype=\"step\",\n",
    "    )\n",
    "\n",
    "    # ax.hist(flat_data_v[...,i].flatten()[flat_data_v[..., i].flatten() != 0], bins=hist[1], label=\"Vini\", histtype=\"step\")\n",
    "\n",
    "    # [false_p_flat[..., i].flatten() != 0]\n",
    "    label = \"\"\n",
    "    if (i + 1) % 3 == 1:\n",
    "        label += \" pt\"\n",
    "        ax.set_yscale(\"log\")\n",
    "        # print(min_bin, max_bin)\n",
    "    if (i + 1) % 3 == 2:\n",
    "        label += \" eta\"\n",
    "        # ax.set_yscale(\"log\")\n",
    "    if (i + 1) % 3 == 0:\n",
    "        label += \" phi\"\n",
    "        # ax.set_yscale(\"log\")\n",
    "    # if i < flat_data_id.shape[-1]//2:\n",
    "    #    label += \" first jet\"\n",
    "    # else:\n",
    "    #    label += \" second jet\"\n",
    "    # ax.set_yscale(\"log\")\n",
    "    label += f\"{(i//3)}\"\n",
    "    # for j in range(particle_data_id.shape[-2]):\n",
    "    #    if (i+1) % ((j+1)*3) < 0:\n",
    "    #        label += f\" particle {i}\"\n",
    "    ax.set_xlabel(label)\n",
    "    ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"particle_distributions.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particle_data_id_f = particle_data_id[..., [1, 2, 0]]\n",
    "particle_data_c_f = particle_data_c[..., [1, 2, 0]]\n",
    "particle_data_v_f = particle_data_v[..., [1, 2, 0]]\n",
    "particle_data_id_f = particle_data_id_f.reshape(\n",
    "    -1, particle_data_id.shape[-2], particle_data_id.shape[-1]\n",
    ")\n",
    "particle_data_c_f = particle_data_c_f.reshape(\n",
    "    -1, particle_data_c.shape[-2], particle_data_c.shape[-1]\n",
    ")\n",
    "particle_data_v_f = particle_data_v_f.reshape(\n",
    "    -1, particle_data_v.shape[-2], particle_data_v.shape[-1]\n",
    ")\n",
    "\n",
    "print(particle_data_c_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_config_x = {\n",
    "    \"num_samples\": len(particle_data_id_f),\n",
    "    \"plot_jet_features\": True,\n",
    "    \"plot_w_dists\": False,\n",
    "    \"plot_efps\": False,\n",
    "    \"plot_selected_multiplicities\": True,\n",
    "    \"selected_multiplicities\": [10, 20, 30, 40, 50, 100],\n",
    "    \"selected_particles\": [1, 5, 20],\n",
    "    \"plottype\": \"sim_data\",\n",
    "    \"save_fig\": False,\n",
    "    \"variable_jet_sizes_plotting\": True,\n",
    "    \"bins\": 100,\n",
    "    \"close_fig\": False,\n",
    "    \"labels\": [\"FM\", \"FPCD\"],\n",
    "}\n",
    "plot_prep_config_x = {\n",
    "    \"calculate_efps\" if key == \"plot_efps\" else key: value\n",
    "    for key, value in plot_config_x.items()\n",
    "    if key in [\"plot_efps\", \"selected_particles\", \"selected_multiplicities\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    jet_data_x,\n",
    "    efps_values_x,\n",
    "    pt_selected_particles_x,\n",
    "    pt_selected_multiplicities_x,\n",
    ") = prepare_data_for_plotting(\n",
    "    np.array([particle_data_c_f, particle_data_v_f]),\n",
    "    **plot_prep_config_x,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    jet_data_sim_x,\n",
    "    efps_sim_x,\n",
    "    pt_selected_particles_sim_x,\n",
    "    pt_selected_multiplicities_sim_x,\n",
    ") = prepare_data_for_plotting(\n",
    "    [particle_data_id_f],\n",
    "    **plot_prep_config_x,\n",
    ")\n",
    "jet_data_sim_x, efps_sim_x, pt_selected_particles_sim_x = (\n",
    "    jet_data_sim_x[0],\n",
    "    efps_sim_x[0],\n",
    "    pt_selected_particles_sim_x[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_x = plot_data(\n",
    "    particle_data=np.array([particle_data_c_f, particle_data_v_f]),\n",
    "    sim_data=particle_data_id_f,\n",
    "    jet_data_sim=jet_data_sim_x,\n",
    "    jet_data=jet_data_x,\n",
    "    efps_sim=efps_sim_x,\n",
    "    efps_values=efps_values_x,\n",
    "    pt_selected_particles=pt_selected_particles_x,\n",
    "    pt_selected_multiplicities=pt_selected_multiplicities_x,\n",
    "    pt_selected_particles_sim=pt_selected_particles_sim_x,\n",
    "    pt_selected_multiplicities_sim=pt_selected_multiplicities_sim_x,\n",
    "    **plot_config_x,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check jet feature stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_jet_features = f\"{data_folder}/lhco/generated/jet_features.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(path_jet_features, \"r\") as f:\n",
    "    data_jet_feature = f[\"jet_features\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"{data_folder}/lhco/final_data/processed_data_background_rel.h5\"\n",
    "with h5py.File(path, \"r\") as f:\n",
    "    jet_data = f[\"jet_data\"][:]\n",
    "    mask = f[\"mask\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get particle multilicities\n",
    "n_particles = np.sum(mask, axis=-2)\n",
    "\n",
    "p4_jets = ef.p4s_from_ptyphims(jet_data)\n",
    "\n",
    "# get mjj from p4_jets\n",
    "sum_p4 = p4_jets[:, 0] + p4_jets[:, 1]\n",
    "mjj = ef.ms_from_p4s(sum_p4)\n",
    "\n",
    "jet_data2 = jet_data.copy()\n",
    "n_particles2 = n_particles.copy()\n",
    "\n",
    "# cut window\n",
    "args_to_keep = ((mjj < 3300) & (mjj > 2300)) | ((mjj > 3700) & (mjj < 5000))\n",
    "conditioning_cut = mjj[args_to_keep].reshape(-1, 1)\n",
    "\n",
    "args_to_keep_sr = (mjj > 3300) & (mjj < 3700)\n",
    "conditioning_sr = mjj.copy()[args_to_keep_sr].reshape(-1, 1)\n",
    "\n",
    "jet_data_cut = jet_data[args_to_keep]\n",
    "n_particles_cut = n_particles[args_to_keep]\n",
    "jet_data_sr = jet_data2[args_to_keep_sr]\n",
    "n_particles_sr = n_particles2[args_to_keep_sr]\n",
    "\n",
    "jet_data_n_particles_cut = np.concatenate([jet_data_cut, n_particles_cut], axis=-1)\n",
    "jet_data_n_particles_sr = np.concatenate([jet_data_sr, n_particles_sr], axis=-1)\n",
    "\n",
    "data = np.reshape(jet_data_n_particles_cut, (jet_data_n_particles_cut.shape[0], -1))\n",
    "data_sr = np.reshape(jet_data_n_particles_sr, (jet_data_n_particles_sr.shape[0], -1))\n",
    "mjj = mjj[args_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mjj.shape)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the same transformations used during training\n",
    "mjj_tile = mjj  # np.expand_dims(mjj,1)\n",
    "# mjj_tile = np.tile(mjj_tile,(1,2))\n",
    "print(mjj_tile.shape)\n",
    "print(data[:, 0].shape)\n",
    "data[:, 0] = np.log(data[:, 0] / mjj_tile)\n",
    "data[:, 2] = np.clip(data[:, 2] - np.pi, -np.pi, np.pi)  # clip phi\n",
    "data[:, 3] = np.ma.log(data[:, 3] / mjj_tile).filled(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jet_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data[..., 4].flatten(), bins=range(0, 279))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.copy()\n",
    "data2[..., 4] = np.random.normal(data2[..., 4], 0.5)\n",
    "plt.hist(data2[..., 4].flatten(), bins=range(0, 279))\n",
    "plt.show()\n",
    "print(data2[..., 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 5, figsize=(50, 20))\n",
    "\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    if i == 4 or i == 9:\n",
    "        bins = range(0, 279)\n",
    "        ax.set_yscale(\"log\")\n",
    "    else:\n",
    "        bins = 100\n",
    "    hist = ax.hist(data[..., i].flatten(), bins=bins, alpha=0.5, label=\"FM\", histtype=\"stepfilled\")\n",
    "    # ax.set_xlabel(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pllhome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
