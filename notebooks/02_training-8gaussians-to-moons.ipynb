{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd0b73a3",
   "metadata": {},
   "source": [
    "###### based on https://github.com/atong01/conditional-flow-matching/blob/main/notebooks/training-8gaussians-to-moons.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9525284d-82d9-4e71-9825-953fcc43fe9c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Conditional Flow Matching\n",
    "\n",
    "This notebook is a self-contained example of conditional flow matching. We implement a number of different simulation-free methods for learning flow models. They differ based on the interpolant used and the loss function used to train them.\n",
    "\n",
    "In this notebook we implement 5 models that can map from a source distribution $q_0$ to a target distribution $q_1$:\n",
    "* Conditional Flow Matching (CFM)\n",
    "    * This is equivalent to the basic (non-rectified) formulation of \"Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow\" [(Liu et al. 2023)](https://openreview.net/forum?id=XVjTT1nw5z)\n",
    "    * Is similar to \"Stochastic Interpolants\" [(Albergo et al. 2023)](https://openreview.net/forum?id=li7qeBbCR1t) with a non-variance preserving interpolant.\n",
    "    * Is similar to \"Flow Matching\" [(Lipman et al. 2023)](https://openreview.net/forum?id=PqvMRDCJT9t) but conditions on both source and target.\n",
    "* Optimal Transport CFM (OT-CFM), which directly optimizes for dynamic optimal transport\n",
    "* Schrödinger Bridge CFM (SB-CFM), which optimizes for Schrödinger Bridge probability paths\n",
    "* \"Building Normalizing Flows with Stochastic Interpolants\" [(Albergo et al. 2023)](https://openreview.net/forum?id=li7qeBbCR1t) this corresponds to \"VP-CFM\" in our README referring to its variance preserving properties.\n",
    "* \"Action Matching: Learning Stochastic Dynamics From Samples\" [(Neklyudov et al. 2022)](https://arxiv.org/abs/2210.06662)\n",
    "\n",
    "Note that this Flow Matching is different from the Generative Flow Network Flow Matching losses. Here we specifically regress against continuous flows, rather than matching inflows and outflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89efbbe0-6c0a-4b92-873c-0184450e5a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# import ot as pot\n",
    "import torch\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "# import torchdyn\n",
    "from torchdyn.core import NeuralODE\n",
    "from torchdyn.datasets import generate_moons\n",
    "\n",
    "savedir = \"models/8gaussian-moons\"\n",
    "os.makedirs(savedir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a83e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from src.models.components import EPiC_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489aa1a0-5caa-43a9-b813-74fadba4953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement some helper functions\n",
    "\n",
    "\n",
    "def eight_normal_sample(n, dim, scale=1, var=1):\n",
    "    m = torch.distributions.multivariate_normal.MultivariateNormal(\n",
    "        torch.zeros(dim), math.sqrt(var) * torch.eye(dim)\n",
    "    )\n",
    "    centers = [\n",
    "        (1, 0),\n",
    "        (-1, 0),\n",
    "        (0, 1),\n",
    "        (0, -1),\n",
    "        (1.0 / np.sqrt(2), 1.0 / np.sqrt(2)),\n",
    "        (1.0 / np.sqrt(2), -1.0 / np.sqrt(2)),\n",
    "        (-1.0 / np.sqrt(2), 1.0 / np.sqrt(2)),\n",
    "        (-1.0 / np.sqrt(2), -1.0 / np.sqrt(2)),\n",
    "    ]\n",
    "    centers = torch.tensor(centers) * scale\n",
    "    noise = m.sample((n,))\n",
    "    multi = torch.multinomial(torch.ones(8), n, replacement=True)\n",
    "    data = []\n",
    "    for i in range(n):\n",
    "        data.append(centers[multi[i]] + noise[i])\n",
    "    data = torch.stack(data)\n",
    "    return data\n",
    "\n",
    "\n",
    "def sample_moons(n, num_points=30):\n",
    "    # x0, _ = generate_moons(n, noise=0.2)\n",
    "    # return x0 * 3 - 1\n",
    "    data = []\n",
    "    for _ in range(n):\n",
    "        x, _ = make_moons(n_samples=num_points, noise=0.05, shuffle=True)\n",
    "        data.append(x)\n",
    "    return torch.tensor(np.array(data), dtype=torch.float32) * 3 - 1\n",
    "\n",
    "\n",
    "def sample_8gaussians(n, num_points=30):\n",
    "    data = []\n",
    "    for _ in range(n):\n",
    "        x = eight_normal_sample(num_points, 2, scale=5, var=0.1).float()\n",
    "        data.append(np.array(x))\n",
    "    return torch.tensor(np.array(data), dtype=torch.float32)\n",
    "\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, dim, out_dim=None, w=64, time_varying=False):\n",
    "        super().__init__()\n",
    "        self.time_varying = time_varying\n",
    "        if out_dim is None:\n",
    "            out_dim = dim\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(dim + (1 if time_varying else 0), w),\n",
    "            torch.nn.SELU(),\n",
    "            torch.nn.Linear(w, w),\n",
    "            torch.nn.SELU(),\n",
    "            torch.nn.Linear(w, w),\n",
    "            torch.nn.SELU(),\n",
    "            torch.nn.Linear(w, out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class GradModel(torch.nn.Module):\n",
    "    def __init__(self, action):\n",
    "        super().__init__()\n",
    "        self.action = action\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.requires_grad_(True)\n",
    "        grad = torch.autograd.grad(torch.sum(self.action(x)), x, create_graph=True)[0]\n",
    "        return grad[:, :-1]\n",
    "\n",
    "\n",
    "class torch_wrapper(torch.nn.Module):\n",
    "    \"\"\"Wraps model to torchdyn compatible format.\"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        return self.model(torch.cat([x, t.repeat(x.shape[:-1])[..., None]], dim=-1))\n",
    "\n",
    "\n",
    "class torch_wrapper_epic(torch.nn.Module):\n",
    "    \"\"\"Wraps model to torchdyn compatible format.\"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        x_local = torch.cat([x, t.repeat(x.shape[:-1])[..., None]], dim=-1)\n",
    "        x_global = torch.randn_like(torch.ones(x_local.shape[0], 16, device=x_local.device))\n",
    "        return self.model(t, x_global, x_local)\n",
    "\n",
    "\n",
    "def plot_trajectories(traj):\n",
    "    n = 2000\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(traj[0, :n, :, 0], traj[0, :n, :, 1], s=10, alpha=0.8, c=\"black\")\n",
    "    plt.scatter(traj[:, :n, :, 0], traj[:, :n, :, 1], s=0.2, alpha=0.2, c=\"olive\")\n",
    "    plt.scatter(traj[-1, :n, :, 0], traj[-1, :n, :, 1], s=4, alpha=1, c=\"blue\")\n",
    "    plt.legend([\"Prior sample z(S)\", \"Flow\", \"z(0)\"])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c8135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "moons = sample_moons(100)\n",
    "print(moons.shape)\n",
    "gaussians = sample_8gaussians(100)\n",
    "print(gaussians.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ab43d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor(0.0)\n",
    "rep = t.repeat(moons.shape[:-1])[..., None]\n",
    "cat = torch.cat([moons, rep], dim=-1)\n",
    "print(cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1297ade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(moons[:10, :, 0], moons[:10, :, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecdb0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(gaussians[:10, :, 0], gaussians[:10, :, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b87ac5-6349-4dfb-8b17-eaa3940d3935",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Conditional Flow Matching\n",
    "\n",
    "First we implement the basic conditional flow matching. As in the paper, we have\n",
    "$$\n",
    "\\begin{align}\n",
    "z &= (x_0, x_1) \\\\\n",
    "q(z) &= q(x_0)q(x_1) \\\\\n",
    "p_t(x | z) &= \\mathcal{N}(x | t * x_1 + (1 - t) * x_0, \\sigma^2) \\\\\n",
    "u_t(x | z) &= x_1 - x_0\n",
    "\\end{align}\n",
    "$$\n",
    "When $\\sigma = 0$ this is equivalent to zero-steps of rectified flow. We find that small $\\sigma$ helps to regularize the problem ymmv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00283979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213f12bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_set_feats(tensor: torch.Tensor) -> torch.Tensor:\n",
    "    if len(tensor.shape) != 3:\n",
    "        raise ValueError(\"Input tensor must be of shape (batch, set_size, feats)\")\n",
    "    mean_set = torch.mean(tensor, dim=-2)\n",
    "    sum_set = torch.sum(tensor, dim=-2)\n",
    "    mean_feat = torch.mean(tensor, dim=-1)\n",
    "    mean_set_feat = torch.mean(mean_feat, dim=-1).unsqueeze(-1)\n",
    "    sum_set_feat = torch.sum(mean_feat, dim=-1).unsqueeze(-1)\n",
    "    cat = torch.cat([mean_set, sum_set, mean_set_feat, sum_set_feat], dim=-1)\n",
    "    return cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0717857c-e4a2-4dbe-88d1-b2399b4eab37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sigma = 0.1\n",
    "dim = 2\n",
    "batch_size = 256\n",
    "# model = MLP(dim=dim, time_varying=True)\n",
    "model = EPiC_generator(feats=dim, latent_local=dim + 1)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "start = time.time()\n",
    "for k in tqdm(range(500)):\n",
    "    optimizer.zero_grad()\n",
    "    x0 = sample_8gaussians(batch_size)  # (x,y)\n",
    "    # print(f\"x_0: {x0.shape}\")\n",
    "    x1 = sample_moons(batch_size)  # (x,y)\n",
    "    # print(f\"x_1: {x1.shape}\")\n",
    "    t = torch.rand_like(x0[..., 0]).unsqueeze(-1)\n",
    "    # print(f\"t shape: {t.shape}\")\n",
    "    mu_t = t * x1 + (1 - t) * x0  #\n",
    "    # print(f\"mu_t: {mu_t.shape}\")\n",
    "    sigma_t = sigma\n",
    "    x = mu_t + sigma_t * torch.randn_like(x0)\n",
    "    # print(f\"x: {x.shape}\")\n",
    "    ut = x1 - x0\n",
    "    # print(f\"ut: {ut.shape}\")\n",
    "    # vt = model(torch.cat([x, t], dim=-1)) #MLP\n",
    "    x_local = torch.cat([x, t], dim=-1)\n",
    "    x_global = torch.randn_like(torch.ones(x_local.shape[0], 16, device=x_local.device))\n",
    "    vt = model(t, x_global, x_local)\n",
    "    # print(f\"vt: {vt.shape}\")\n",
    "    # print(f\"ut: {ut.shape}\")\n",
    "    loss = torch.mean((calc_set_feats(vt) - calc_set_feats(ut)) ** 2)\n",
    "\n",
    "    # print(f\"loss: {loss}\")\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (k + 1) % 30 == 0:\n",
    "        print(f\"k: {k+1}\")\n",
    "    if (k + 1) % 499 == 0:\n",
    "        end = time.time()\n",
    "        print(f\"{k+1}: loss {loss.item():0.3f} time {(end - start):0.2f}\")\n",
    "        start = end\n",
    "        node = NeuralODE(\n",
    "            torch_wrapper_epic(model), solver=\"dopri5\", sensitivity=\"adjoint\", atol=1e-4, rtol=1e-4\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            traj = node.trajectory(\n",
    "                sample_8gaussians(100),\n",
    "                t_span=torch.linspace(0, 1, 50),\n",
    "            )\n",
    "            plot_trajectories(traj)\n",
    "torch.save(model, f\"{savedir}/cfm_v1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebc10f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sigma = 0.1\n",
    "dim = 2\n",
    "batch_size = 256\n",
    "# model = MLP(dim=dim, time_varying=True)\n",
    "model = EPiC_generator(feats=dim, latent_local=dim + 1)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "start = time.time()\n",
    "for k in tqdm(range(500)):\n",
    "    optimizer.zero_grad()\n",
    "    x0 = sample_8gaussians(batch_size)  # (x,y)\n",
    "    # print(f\"x_0: {x0.shape}\")\n",
    "    x1 = sample_moons(batch_size)  # (x,y)\n",
    "    # print(f\"x_1: {x1.shape}\")\n",
    "    t = torch.rand_like(x0[..., 0]).unsqueeze(-1)\n",
    "    # print(f\"t shape: {t.shape}\")\n",
    "    mu_t = t * x1 + (1 - t) * x0  #\n",
    "    # print(f\"mu_t: {mu_t.shape}\")\n",
    "    sigma_t = sigma\n",
    "    x = mu_t + sigma_t * torch.randn_like(x0)\n",
    "    # print(f\"x: {x.shape}\")\n",
    "    ut = x1 - x0\n",
    "    # print(f\"ut: {ut.shape}\")\n",
    "    # vt = model(torch.cat([x, t], dim=-1)) #MLP\n",
    "    x_local = torch.cat([x, t], dim=-1)\n",
    "    x_global = torch.randn_like(torch.ones(x_local.shape[0], 16, device=x_local.device))\n",
    "    vt = model(t, x_global, x_local)\n",
    "    # print(f\"vt: {vt.shape}\")\n",
    "    # print(f\"ut: {ut.shape}\")\n",
    "    loss = torch.mean((vt - ut) ** 2) + torch.mean((calc_set_feats(vt) - calc_set_feats(ut)) ** 2)\n",
    "\n",
    "    # print(f\"loss: {loss}\")\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (k + 1) % 30 == 0:\n",
    "        print(f\"k: {k+1}\")\n",
    "    if (k + 1) % 499 == 0:\n",
    "        end = time.time()\n",
    "        print(f\"{k+1}: loss {loss.item():0.3f} time {(end - start):0.2f}\")\n",
    "        start = end\n",
    "        node = NeuralODE(\n",
    "            torch_wrapper_epic(model), solver=\"dopri5\", sensitivity=\"adjoint\", atol=1e-4, rtol=1e-4\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            traj = node.trajectory(\n",
    "                sample_8gaussians(100),\n",
    "                t_span=torch.linspace(0, 1, 50),\n",
    "            )\n",
    "            plot_trajectories(traj)\n",
    "torch.save(model, f\"{savedir}/cfm_v1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc27451",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77600a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trajectories1(traj):\n",
    "    n = 1\n",
    "    m = 2\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(traj[0, :n, :, 0], traj[0, :n, :, 1], s=10, alpha=0.8, c=\"black\")\n",
    "    plt.scatter(traj[:, :n, :, 0], traj[:, :n, :, 1], s=0.2, alpha=0.2, c=\"olive\")\n",
    "    plt.scatter(traj[-1, :n, :, 0], traj[-1, :n, :, 1], s=4, alpha=1, c=\"blue\")\n",
    "    plt.scatter(traj[0, m, :, 0], traj[0, m, :, 1], s=10, alpha=0.8, c=\"green\")\n",
    "    plt.scatter(traj[:, m, :, 0], traj[:, m, :, 1], s=0.2, alpha=0.2, c=\"orange\")\n",
    "    plt.scatter(traj[-1, m, :, 0], traj[-1, m, :, 1], s=4, alpha=1, c=\"red\")\n",
    "    plt.legend([\"Prior sample z(S)\", \"Flow\", \"z(0)\"])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580d2996",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectories1(traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa05c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1 = torch.rand_like(torch.ones(10, 5, 3))\n",
    "tensor2 = torch.rand_like(torch.ones(10, 5, 3))\n",
    "print(tensor1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8159bc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_set_feats(tensor: torch.Tensor) -> torch.Tensor:\n",
    "    if len(tensor.shape) != 3:\n",
    "        raise ValueError(\"Input tensor must be of shape (batch, set_size, feats)\")\n",
    "    mean_set = torch.mean(tensor, dim=-2)\n",
    "    sum_set = torch.sum(tensor, dim=-2)\n",
    "    mean_feat = torch.mean(tensor, dim=-1)\n",
    "    mean_set_feat = torch.mean(mean_feat, dim=-1).unsqueeze(-1)\n",
    "    sum_set_feat = torch.sum(mean_feat, dim=-1).unsqueeze(-1)\n",
    "    cat = torch.cat([mean_set, sum_set, mean_set_feat, sum_set_feat], dim=-1)\n",
    "    return cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700ea790",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"function: {calc_set_feats(tensor1).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebf553e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_set = torch.mean(tensor1, dim=-2)\n",
    "sum_set = torch.sum(tensor1, dim=-2)\n",
    "print(mean_set.shape)\n",
    "print(sum_set.shape)\n",
    "print(f\"tensor1: {tensor1.shape}\")\n",
    "mean_feat = torch.mean(tensor1, dim=-1)\n",
    "print(mean_feat.shape)\n",
    "mean_set_feat = torch.mean(mean_feat, dim=-1).unsqueeze(-1)\n",
    "sum_set_feat = torch.sum(mean_feat, dim=-1).unsqueeze(-1)\n",
    "print(mean_set_feat.shape)\n",
    "print(sum_set_feat.shape)\n",
    "cat = torch.cat([mean_set, sum_set, mean_set_feat, sum_set_feat], dim=-1)\n",
    "print(cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72553068",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = tensor1 - tensor2\n",
    "print(diff.shape)\n",
    "sqr = diff**2\n",
    "print(sqr.shape)\n",
    "mn = torch.mean(sqr)\n",
    "print(mn.shape)\n",
    "# loss = torch.mean((vt - ut) ** 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pllhome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
