{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LHCO Cathode Generation Pipeline\n",
    "After the particle level models and the jet feature models have been trained, the final step is to run the whole generation pipeline. This is the purpose of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "import energyflow as ef\n",
    "import h5py\n",
    "import hydra\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "from sklearn.neighbors import KernelDensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots and metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.data.components import calculate_all_wasserstein_metrics, normalize_tensor\n",
    "from src.utils.data_generation import generate_data\n",
    "from src.utils.plotting import apply_mpl_styles, plot_data, prepare_data_for_plotting\n",
    "\n",
    "apply_mpl_styles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set env variable DATA_DIR again because of hydra\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"DATA_DIR\"] = os.environ.get(\"DATA_DIR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate mjj samples\n",
    "We fit a KDE to the mjj distribution of the signal and background samples. We then sample from the KDE to generate new mjj samples in the signal region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/beegfs/desy/user/ewencedr/data/lhco/final_data/processed_data_background_rel.h5\"\n",
    "with h5py.File(path, \"r\") as f:\n",
    "    jets = f[\"jet_data\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p4_jets = ef.p4s_from_ptyphims(jets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_p4 = p4_jets[:, 0] + p4_jets[:, 1]\n",
    "mjj = ef.ms_from_p4s(sum_p4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_to_keep = ((mjj < 3300) & (mjj > 2300)) | ((mjj > 3700) & (mjj < 5000))\n",
    "args_to_keep_sr = (mjj > 3300) & (mjj < 3700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mjj_sb = mjj[args_to_keep]\n",
    "mjj_sr = mjj[args_to_keep_sr]\n",
    "args_to_keep_sb_sr = args_to_keep | args_to_keep_sr\n",
    "mjj_sb_sr = mjj[args_to_keep_sb_sr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = plt.hist(\n",
    "    mjj, bins=np.arange(1e3, 9.5e3, 0.1e3), histtype=\"stepfilled\", label=\"mjj\", alpha=0.5\n",
    ")\n",
    "plt.hist(mjj_sb, bins=hist[1], histtype=\"step\", label=\"mjj SB\")\n",
    "plt.hist(mjj_sr, bins=hist[1], histtype=\"step\", label=\"mjj SR\")\n",
    "\n",
    "plt.legend()\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = plt.hist(\n",
    "    mjj, bins=np.arange(1e3, 9.5e3, 0.1e3), histtype=\"stepfilled\", label=\"mjj\", alpha=0.5\n",
    ")\n",
    "plt.hist(mjj_sb_sr, bins=hist[1], histtype=\"step\", label=\"mjj SB SR\")\n",
    "\n",
    "plt.legend()\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit KDE on SR and SB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_model_sb_sr = KernelDensity(kernel=\"gaussian\", bandwidth=0.001)\n",
    "kde_model_sb_sr.fit(mjj_sb_sr.reshape(-1, 1))\n",
    "\n",
    "samples_sb_sr = kde_model_sb_sr.sample(len(mjj_sb_sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = plt.hist(\n",
    "    mjj_sb_sr,\n",
    "    bins=np.arange(1e3, 9.5e3, 0.05e3),\n",
    "    histtype=\"stepfilled\",\n",
    "    label=\"Truth\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.hist(samples_sb_sr, bins=hist[1], histtype=\"step\", label=\"KDE samples\")\n",
    "plt.xlabel(\"mjj [GeV]\")\n",
    "plt.ylim(1e-1, 1e5)\n",
    "plt.legend(frameon=False)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### only take SR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_to_keep_sr_samples = (samples_sb_sr > 3300) & (samples_sb_sr < 3700)\n",
    "mjj_samples_sr = samples_sb_sr[args_to_keep_sr_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = plt.hist(\n",
    "    mjj_sr,\n",
    "    bins=np.arange(1e3, 9.5e3, 0.1e3),\n",
    "    histtype=\"stepfilled\",\n",
    "    label=\"Truth\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.hist(mjj_samples_sr, bins=hist[1], histtype=\"step\", label=\"KDE samples\")\n",
    "plt.ylim(1e-1, 1e5)\n",
    "plt.xlabel(\"mjj [GeV]\")\n",
    "plt.legend(frameon=False)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate from Jet Feature Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"/lhco/lhco_jet_features.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load everything from experiment config\n",
    "with hydra.initialize(version_base=None, config_path=\"../configs/\"):\n",
    "    cfg = hydra.compose(config_name=\"train.yaml\", overrides=[f\"experiment={experiment}\"])\n",
    "    # print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = hydra.utils.instantiate(cfg.data)\n",
    "model = hydra.utils.instantiate(cfg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_sr = np.array(datamodule.tensor_test_sr)\n",
    "test_cond_sr = np.array(datamodule.tensor_conditioning_test_sr)\n",
    "val_data_sr = np.array(datamodule.tensor_val_sr)\n",
    "val_cond_sr = np.array(datamodule.tensor_conditioning_val_sr)\n",
    "train_data_sr = np.array(datamodule.tensor_train_sr)\n",
    "train_cond_sr = np.array(datamodule.tensor_conditioning_train_sr)\n",
    "means = np.array(datamodule.means)\n",
    "stds = np.array(datamodule.stds)\n",
    "means_cond = np.array(datamodule.cond_means)\n",
    "stds_cond = np.array(datamodule.cond_stds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = (\n",
    "    \"/beegfs/desy/user/ewencedr/deep-learning/logs/lhco jet features with particle\"\n",
    "    \" multiplicity/runs/2023-08-16_14-58-31/checkpoints/last-EMA.ckpt\"\n",
    ")\n",
    "model = model.load_from_checkpoint(ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize conditioning variables\n",
    "normalized_cond = normalize_tensor(\n",
    "    torch.tensor(mjj_samples_sr, dtype=torch.float).clone().unsqueeze(-1),\n",
    "    means_cond,\n",
    "    stds_cond,\n",
    "    datamodule.hparams.normalize_sigma,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(9999)\n",
    "data_jet_feature, generation_time = generate_data(\n",
    "    model,\n",
    "    num_jet_samples=n_samples,\n",
    "    batch_size=2048,\n",
    "    cond=normalized_cond[:n_samples],\n",
    "    normalized_data=datamodule.hparams.normalize,\n",
    "    means=datamodule.means,\n",
    "    stds=datamodule.stds,\n",
    "    ode_solver=\"midpoint\",\n",
    "    ode_steps=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    \"0\": r\"${p_T}_1$\",\n",
    "    \"1\": r\"$\\eta_1$\",\n",
    "    \"2\": r\"$\\phi_1$\",\n",
    "    \"3\": r\"$m_1$\",\n",
    "    \"4\": \"Particle Multiplicity 1\",\n",
    "    \"5\": r\"${p_T}_2$\",\n",
    "    \"6\": r\"$\\eta_2$\",\n",
    "    \"7\": r\"$\\phi_2$\",\n",
    "    \"8\": r\"$m_2$\",\n",
    "    \"9\": \"Particle Multiplicity 2\",\n",
    "}\n",
    "fig, axs = plt.subplots(2, 5, figsize=(25, 11))\n",
    "for index, ax in enumerate(axs.reshape(-1)):\n",
    "    x_min, x_max = min(\n",
    "        np.min(test_data_sr[:n_samples, index]), np.min(data_jet_feature[:n_samples, index])\n",
    "    ), max(np.max(test_data_sr[:n_samples, index]), np.max(data_jet_feature[:n_samples, index]))\n",
    "    if index == 4 or index == 9:\n",
    "        bin_width = 1\n",
    "        bins = range(int(x_min), int(x_max) + bin_width, bin_width)\n",
    "    else:\n",
    "        bins = 100\n",
    "    hist1 = ax.hist(\n",
    "        test_data_sr[:n_samples, index],\n",
    "        bins=bins,\n",
    "        label=\"train data\",\n",
    "        range=[x_min, x_max],\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    ax.hist(data_jet_feature[:n_samples, index], bins=hist1[1], label=\"generated\", histtype=\"step\")\n",
    "    ax.set_xlabel(f\"{label_map[str(index)]}\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    if index == 2 or index == 7:\n",
    "        ax.legend(frameon=False)\n",
    "        ax.set_ylim(1e-1, 1e6)\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Signal Region\", fontsize=30)\n",
    "fig.subplots_adjust(top=0.93)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle Feature Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_x = \"/lhco/lhco_x_jet.yaml\"\n",
    "experiment_y = \"/lhco/lhco_y_jet.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load everything from experiment config\n",
    "with hydra.initialize(version_base=None, config_path=\"../configs/\"):\n",
    "    cfg_x = hydra.compose(config_name=\"train.yaml\", overrides=[f\"experiment={experiment_x}\"])\n",
    "    # print(OmegaConf.to_yaml(cfg_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load everything from experiment config\n",
    "with hydra.initialize(version_base=None, config_path=\"../configs/\"):\n",
    "    cfg_y = hydra.compose(config_name=\"train.yaml\", overrides=[f\"experiment={experiment_y}\"])\n",
    "    # print(OmegaConf.to_yaml(cfg_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule_x = hydra.utils.instantiate(cfg_x.data)\n",
    "model_x = hydra.utils.instantiate(cfg_x.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule_y = hydra.utils.instantiate(cfg_y.data)\n",
    "model_y = hydra.utils.instantiate(cfg_y.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule_x.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule_y.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_x = (\n",
    "    \"/beegfs/desy/user/ewencedr/deep-learning/logs/lhco x jet mass new cut\"\n",
    "    \" interpolate/runs/2023-08-16_02-00-37/checkpoints/last-EMA.ckpt\"\n",
    ")\n",
    "model_x = model_x.load_from_checkpoint(ckpt_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_y = (\n",
    "    \"/beegfs/desy/user/ewencedr/deep-learning/logs/lhco y jet mass new cut\"\n",
    "    \" interpolate/runs/2023-08-16_03-49-00/checkpoints/last-EMA.ckpt\"\n",
    ")\n",
    "model_y = model_y.load_from_checkpoint(ckpt_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_x = 20000\n",
    "n_samples_y = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize conditioning variables\n",
    "cond_x = data_jet_feature[:, 0:4]\n",
    "normalized_cond_x = normalize_tensor(\n",
    "    torch.tensor(cond_x, dtype=torch.float32).clone(),\n",
    "    datamodule_x.cond_means,\n",
    "    datamodule_x.cond_stds,\n",
    "    datamodule_x.hparams.normalize_sigma,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize conditioning variables\n",
    "cond_y = data_jet_feature[:, 5:9]\n",
    "normalized_cond_y = normalize_tensor(\n",
    "    torch.tensor(cond_y, dtype=torch.float32).clone(),\n",
    "    datamodule_y.cond_means,\n",
    "    datamodule_y.cond_stds,\n",
    "    datamodule_y.hparams.normalize_sigma,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_x_ints = data_jet_feature[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_y_ints = data_jet_feature[:, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes_x = datamodule_x.tensor_test.shape[1]\n",
    "targets_x = np.rint(mask_x_ints).astype(int)\n",
    "mask_x = np.expand_dims(np.tril(np.ones((n_classes_x, n_classes_x)), k=-1)[targets_x], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes_y = datamodule_y.tensor_test.shape[1]\n",
    "targets_y = np.rint(mask_y_ints).astype(int)\n",
    "mask_y = np.expand_dims(np.tril(np.ones((n_classes_y, n_classes_y)), k=-1)[targets_y], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(normalized_cond_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(9999)\n",
    "data_x, generation_time_x = generate_data(\n",
    "    model_x,\n",
    "    num_jet_samples=n_samples_x,\n",
    "    batch_size=2048,\n",
    "    cond=normalized_cond_x[:n_samples_x],\n",
    "    variable_set_sizes=datamodule_x.hparams.variable_jet_sizes,\n",
    "    mask=torch.tensor(mask_x, dtype=torch.int64),\n",
    "    normalized_data=datamodule_x.hparams.normalize,\n",
    "    means=datamodule_x.means,\n",
    "    stds=datamodule_x.stds,\n",
    "    ode_solver=\"midpoint\",\n",
    "    ode_steps=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(9999)\n",
    "data_y, generation_time_y = generate_data(\n",
    "    model_y,\n",
    "    num_jet_samples=n_samples_y,\n",
    "    batch_size=2048,\n",
    "    cond=normalized_cond_y[:n_samples_y],\n",
    "    variable_set_sizes=datamodule_y.hparams.variable_jet_sizes,\n",
    "    mask=torch.tensor(mask_y, dtype=torch.int64),\n",
    "    normalized_data=datamodule_y.hparams.normalize,\n",
    "    means=datamodule_y.means,\n",
    "    stds=datamodule_y.stds,\n",
    "    ode_solver=\"midpoint\",\n",
    "    ode_steps=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_y\n",
    "background_data = np.array(datamodule_y.tensor_test_sr[: len(data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_dists = calculate_all_wasserstein_metrics(\n",
    "    background_data, data, num_eval_samples=50_000, num_batches=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "print(background_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_config = {\n",
    "    \"num_samples\": -1,\n",
    "    \"plot_jet_features\": True,\n",
    "    \"plot_w_dists\": False,\n",
    "    \"plot_efps\": True,\n",
    "    \"plot_selected_multiplicities\": False,\n",
    "    \"selected_multiplicities\": [10, 20, 30, 40, 50, 100],\n",
    "    \"selected_particles\": [1, 5, 20],\n",
    "    \"plottype\": \"sim_data\",\n",
    "    \"save_fig\": False,\n",
    "    \"variable_jet_sizes_plotting\": True,\n",
    "    \"bins\": 100,\n",
    "    \"close_fig\": False,\n",
    "}\n",
    "plot_prep_config = {\n",
    "    \"calculate_efps\" if key == \"plot_efps\" else key: value\n",
    "    for key, value in plot_config.items()\n",
    "    if key in [\"plot_efps\", \"selected_particles\", \"selected_multiplicities\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    jet_data,\n",
    "    efps_values,\n",
    "    pt_selected_particles,\n",
    "    pt_selected_multiplicities,\n",
    ") = prepare_data_for_plotting(\n",
    "    np.array([data]),\n",
    "    **plot_prep_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    jet_data_sim,\n",
    "    efps_sim,\n",
    "    pt_selected_particles_sim,\n",
    "    pt_selected_multiplicities_sim,\n",
    ") = prepare_data_for_plotting(\n",
    "    [background_data],\n",
    "    **plot_prep_config,\n",
    ")\n",
    "jet_data_sim, efps_sim, pt_selected_particles_sim = (\n",
    "    jet_data_sim[0],\n",
    "    efps_sim[0],\n",
    "    pt_selected_particles_sim[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_data(\n",
    "    particle_data=np.array([data]),\n",
    "    sim_data=background_data,\n",
    "    jet_data_sim=jet_data_sim,\n",
    "    jet_data=jet_data,\n",
    "    efps_sim=efps_sim,\n",
    "    efps_values=efps_values,\n",
    "    pt_selected_particles=pt_selected_particles,\n",
    "    pt_selected_multiplicities=pt_selected_multiplicities,\n",
    "    pt_selected_particles_sim=pt_selected_particles_sim,\n",
    "    pt_selected_multiplicities_sim=pt_selected_multiplicities_sim,\n",
    "    **plot_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to non-rel. Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cond_x.shape)\n",
    "print(data_x.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pllhome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
