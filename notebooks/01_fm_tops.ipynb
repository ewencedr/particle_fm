{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.models.zuko.utils import odeint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set env variable DATA_DIR again because of hydra\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"DATA_DIR\"] = os.environ.get(\"DATA_DIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"fm_tops.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load everything from experiment config\n",
    "with hydra.initialize(version_base=None, config_path=\"../configs/\"):\n",
    "    cfg = hydra.compose(config_name=\"train.yaml\", overrides=[f\"experiment={experiment}\"])\n",
    "    print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = hydra.utils.instantiate(cfg.data)\n",
    "model = hydra.utils.instantiate(cfg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_for_saving = \"nb_fm_tops30\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.array(datamodule.tensor_test)\n",
    "test_mask = np.array(datamodule.mask_test)\n",
    "means = np.array(datamodule.means)\n",
    "stds = np.array(datamodule.stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data.shape)\n",
    "print(test_mask.shape)\n",
    "print(means)\n",
    "print(stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(np.sum(test_mask, axis=-2), return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.callbacks.ema import EMA\n",
    "from src.callbacks.jetnet_eval import JetNetEvaluationCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    "    ModelSummary,\n",
    "    RichProgressBar,\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val/loss\",\n",
    "    mode=\"min\",\n",
    "    save_top_k=1,\n",
    "    save_last=True,\n",
    "    save_weights_only=True,\n",
    "    dirpath=f\"./logs/{model_name_for_saving}/checkpoints\",\n",
    ")\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val/loss\", mode=\"min\", patience=10, verbose=True, min_delta=0.0001\n",
    ")\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "model_summary = ModelSummary()\n",
    "rich_progress_bar = RichProgressBar()\n",
    "\n",
    "jetnet_eval_callback = JetNetEvaluationCallback(\n",
    "    every_n_epochs=3,\n",
    "    num_jet_samples=10000,\n",
    "    logger=2,\n",
    "    log_w_dists=False,\n",
    "    image_path=\"/beegfs/desy/user/ewencedr/deep-learning/logs/comet_logs\",\n",
    ")\n",
    "\n",
    "ema = EMA(\n",
    "    decay=0.9999,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([1, 2, 3]).unsqueeze(-1).repeat_interleave(3, dim=-1)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import CometLogger, CSVLogger, WandbLogger\n",
    "\n",
    "csv_logger = CSVLogger(f\"./logs/{model_name_for_saving}/csv_logs\")\n",
    "comet_logger = CometLogger(\n",
    "    api_key=os.environ.get(\"COMET_API_KEY\"),\n",
    "    workspace=os.environ.get(\"COMET_WORKSPACE\"),  # Optional\n",
    "    save_dir=f\"./logs/{model_name_for_saving}/comet_logs\",  # Optional\n",
    "    project_name=\"Flow Matching\",  # Optional\n",
    "    rest_api_key=os.environ.get(\"COMET_REST_API_KEY\"),  # Optional\n",
    "    experiment_key=os.environ.get(\"COMET_EXPERIMENT_KEY\"),  # Optional\n",
    "    experiment_name=model_name_for_saving,  # Optional\n",
    "    offline=False,\n",
    ")\n",
    "wandb_logger = WandbLogger(\n",
    "    project=\"Flow Matching\", name=model_name_for_saving, save_dir=f\"./logs/{model_name_for_saving}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=30,\n",
    "    callbacks=[checkpoint_callback, lr_monitor, model_summary, ema],\n",
    "    logger=[csv_logger, wandb_logger],\n",
    "    accelerator=\"gpu\",\n",
    ")\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "trainer.fit(\n",
    "    model=model,\n",
    "    datamodule=datamodule,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt = \"/beegfs/desy/user/ewencedr/deep-learning/logs/transformer/runs/2023-03-30_13-07-29/checkpoints/epoch_1861_loss_0.126.ckpt\"\n",
    "# ckpt = \"./logs/nb_fm_tops30/checkpoints/last-v17.ckpt\"  # mass conditioning\n",
    "# ckpt = \"/beegfs/desy/user/ewencedr/deep-learning/logs/SWD/runs/2023-04-18_14-51-12/checkpoints/epoch_1752_loss_0.02817.ckpt\"\n",
    "# ckpt = \"/beegfs/desy/user/ewencedr/deep-learning/logs/normalize t local 5000epochs/runs/2023-05-14_03-00-43/checkpoints/epoch_3503_loss_5.96382.ckpt\"\n",
    "ckpt = \"/beegfs/desy/user/ewencedr/deep-learning/logs/150 particles sigma 1e-6/runs/2023-05-26_18-47-53/checkpoints/epoch_9540_w1p_0.00500000.ckpt\"\n",
    "ckpt = \"/beegfs/desy/user/ewencedr/deep-learning/logs/fm_tops-150-1/runs/2023-06-01_15-35-44/checkpoints/last.ckpt\"\n",
    "model = model.load_from_checkpoint(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.components.utils import jet_masses\n",
    "\n",
    "print(test_data.shape)\n",
    "masses = jet_masses(torch.tensor(test_data)).unsqueeze(-1)\n",
    "print(masses.shape)\n",
    "print(masses[:100].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval().cuda()\n",
    "with torch.no_grad():\n",
    "    x_samples = model.sample(100, masses[:100]).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_samples.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.utils.plotting import apply_mpl_styles, create_and_plot_data, plot_single_jets\n",
    "\n",
    "apply_mpl_styles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(model))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, data, generation_times = create_and_plot_data(\n",
    "    np.array(test_data),\n",
    "    [model],\n",
    "    cond=None,\n",
    "    save_name=\"fm_tops_nb\",\n",
    "    labels=[\"FM\"],\n",
    "    mask=test_mask,\n",
    "    num_jet_samples=10000,\n",
    "    batch_size=1000,\n",
    "    variable_set_sizes=True,\n",
    "    normalized_data=[True, True],\n",
    "    means=means,\n",
    "    stds=stds,\n",
    "    save_folder=\"./logs/nb_plots/\",\n",
    "    plottype=\"sim_data\",\n",
    "    plot_jet_features=True,\n",
    "    plot_w_dists=True,\n",
    "    plot_selected_multiplicities=True,\n",
    "    selected_multiplicities=[1, 3, 5, 10, 20, 30],\n",
    "    ode_solver=\"midpoint\",\n",
    "    ode_steps=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.components import calculate_all_wasserstein_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[0].shape)\n",
    "print(test_mask.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particle_data = data[0]\n",
    "mask_data = (particle_data[..., 0] == 0).astype(int)\n",
    "mask_data = 1 - mask_data\n",
    "# print(mask_data)\n",
    "mask_data = np.expand_dims(mask_data, axis=-1)\n",
    "# print(np.count_nonzero(mask_data, axis=-2))\n",
    "# print(np.count_nonzero(test_data[:len(particle_data),:, :3], axis=-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(particle_data[0])\n",
    "print(particle_data[:, :, :3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros1 = ~(np.linalg.norm(particle_data[:, :, :3], axis=-1) == 0)\n",
    "print(zeros1)\n",
    "print(zeros1.shape)\n",
    "mask_data = ~(particle_data[..., 0] == 0)\n",
    "print(mask_data)\n",
    "print(mask_data.shape)\n",
    "print(np.count_nonzero((mask_data == zeros1).astype(int)))\n",
    "print(~zeros1 * mask_data)\n",
    "print(True * True)\n",
    "print(False * False)\n",
    "print(True * False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(int(10004 // 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particle_data = data[0]\n",
    "mask_data = (particle_data[..., 0] == 0).astype(int)\n",
    "# print(mask_data.shape)\n",
    "# print(test_mask[:len(particle_data),:,0].astype(bool))\n",
    "mask_data = np.expand_dims(mask_data, axis=-1)\n",
    "mask_data = 1 - mask_data\n",
    "print(mask_data.shape)\n",
    "print(mask_data)\n",
    "w_dists_1b = calculate_all_wasserstein_metrics(\n",
    "    test_data[: len(particle_data), :, :3],\n",
    "    particle_data,\n",
    "    test_mask[: len(particle_data)],\n",
    "    mask_data,\n",
    "    num_eval_samples=len(particle_data),\n",
    "    num_batches=1,\n",
    "    calculate_efps=True,\n",
    "    use_masks=True,\n",
    ")\n",
    "w_dists = calculate_all_wasserstein_metrics(\n",
    "    test_data[: len(particle_data), :, :3],\n",
    "    particle_data,\n",
    "    test_mask[: len(particle_data)],\n",
    "    mask_data,\n",
    "    num_eval_samples=int(len(particle_data) / 5),\n",
    "    num_batches=5,\n",
    "    calculate_efps=True,\n",
    "    use_masks=True,\n",
    ")\n",
    "print(w_dists_1b)\n",
    "print(w_dists)\n",
    "# 0.0029 using mask\n",
    "# 0.0004 using zero exclude without\n",
    "# 0.00018 without zero exclude"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_single_jets(test_data, save_folder=\"./logs/nb_plots/\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_single_jets(\n",
    "    data[0], save_folder=\"./logs/nb_plots/\", save_name=\"gen_jets\", color=\"#0271BB\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda()\n",
    "with torch.no_grad():\n",
    "    log_p = model.flows[0].log_prob(torch.tensor(test_data[:5]).float().cuda())\n",
    "print(log_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(test_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval().cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    x_samples = model.sample(100, mask=torch.tensor(test_mask)).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.repeat(test_mask[:100], 3, axis=-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_samples = x_samples * np.repeat(test_mask[:100], 3, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.count_nonzero(test_mask[0]))\n",
    "print(np.count_nonzero(x_samples[0, :, 0]))\n",
    "print(np.count_nonzero(masked_samples[0, :, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.components.utils import jet_masses\n",
    "\n",
    "print(f\"x_samples shape: {x_samples.shape}\")\n",
    "mass = jet_masses(torch.tensor(x_samples))\n",
    "print(f\"mass shape: {mass.shape}\")\n",
    "print(mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_single_jets(\n",
    "    masked_samples, save_folder=\"./logs/nb_plots/\", save_name=\"gen_jets\", color=\"#0271BB\"\n",
    ")\n",
    "fig = plot_single_jets(\n",
    "    test_data[: masked_samples.shape[0]],\n",
    "    save_folder=\"./logs/nb_plots/\",\n",
    "    save_name=\"gen_jets\",\n",
    "    color=\"r\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import energyflow as ef\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "\n",
    "def jet_masses(jets_ary):\n",
    "    jets_p4s = ef.p4s_from_ptyphims(jets_ary)\n",
    "    masses = ef.ms_from_p4s(jets_p4s.sum(axis=1))\n",
    "    return masses\n",
    "\n",
    "\n",
    "def jet_ys(jets_ary):\n",
    "    jets_p4s = ef.p4s_from_ptyphims(jets_ary)\n",
    "    ys = ef.ys_from_p4s(jets_p4s.sum(axis=1))\n",
    "    return ys\n",
    "\n",
    "\n",
    "def jet_etas(jets_ary):\n",
    "    jets_p4s = ef.p4s_from_ptyphims(jets_ary)\n",
    "    etas = ef.etas_from_p4s(jets_p4s.sum(axis=1))\n",
    "    return etas\n",
    "\n",
    "\n",
    "def jet_phis(jets_ary):\n",
    "    jets_p4s = ef.p4s_from_ptyphims(jets_ary)\n",
    "    phis = ef.phis_from_p4s(jets_p4s.sum(axis=1), phi_ref=0)\n",
    "    return phis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_samples.shape)\n",
    "# (np.concatenate(x_samples))[:, i_feat]\n",
    "# print((np.concatenate(x_samples))[:,0].shape)\n",
    "np.concatenate()\n",
    "print(np.reshape(x_samples, (-1, x_samples.shape[-1])).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(test_data)\n",
    "fig = plt.figure(figsize=(20, 4))\n",
    "gs = GridSpec(1, 4)\n",
    "\n",
    "#####\n",
    "\n",
    "ax = fig.add_subplot(gs[0])\n",
    "\n",
    "i_feat = 0\n",
    "\n",
    "bins = np.linspace(-0.5, 0.5, 50)\n",
    "ax.hist(\n",
    "    (np.concatenate(x_samples))[:, i_feat],\n",
    "    histtype=\"step\",\n",
    "    bins=bins,\n",
    "    density=True,\n",
    "    lw=2,\n",
    "    ls=\"--\",\n",
    "    alpha=0.7,\n",
    "    label=\"Gen\",\n",
    ")\n",
    "print(np.concatenate(x_samples).shape)\n",
    "eta = np.concatenate((np.array(x)))[:, i_feat]\n",
    "eta = eta[eta != 0.0]\n",
    "ax.hist(eta, histtype=\"step\", density=True, bins=bins, lw=2, alpha=0.7, label=\"Sim\")\n",
    "\n",
    "ax.set_xlabel(r\"$\\eta^\\mathrm{rel}$\")\n",
    "ax.get_yaxis().set_ticklabels([])\n",
    "ax.set_yscale(\"log\")\n",
    "ax.legend()\n",
    "\n",
    "#####\n",
    "\n",
    "ax = fig.add_subplot(gs[1])\n",
    "\n",
    "i_feat = 1\n",
    "\n",
    "bins = np.linspace(-0.5, 0.5, 50)\n",
    "ax.hist(\n",
    "    (np.concatenate(x_samples))[:, i_feat],\n",
    "    histtype=\"step\",\n",
    "    bins=bins,\n",
    "    density=True,\n",
    "    lw=2,\n",
    "    ls=\"--\",\n",
    "    alpha=0.7,\n",
    "    label=\"Gen\",\n",
    ")\n",
    "\n",
    "eta = (np.concatenate(np.array(x)))[:, i_feat]\n",
    "eta = eta[eta != 0.0]\n",
    "ax.hist(eta, histtype=\"step\", density=True, bins=bins, lw=2, alpha=0.7, label=\"Sim\")\n",
    "\n",
    "ax.set_xlabel(r\"$\\phi^\\mathrm{rel}$\")\n",
    "ax.get_yaxis().set_ticklabels([])\n",
    "ax.set_yscale(\"log\")\n",
    "ax.legend()\n",
    "\n",
    "#####\n",
    "\n",
    "ax = fig.add_subplot(gs[2])\n",
    "\n",
    "i_feat = 2\n",
    "\n",
    "bins = np.linspace(-0.1, 0.5, 100)\n",
    "ax.hist(\n",
    "    (np.concatenate(x_samples))[:, i_feat],\n",
    "    histtype=\"step\",\n",
    "    bins=bins,\n",
    "    density=True,\n",
    "    lw=2,\n",
    "    ls=\"--\",\n",
    "    alpha=0.7,\n",
    "    label=\"Gen\",\n",
    ")\n",
    "\n",
    "eta = np.concatenate((np.array(x)))[:, i_feat]\n",
    "eta = eta[eta != 0.0]\n",
    "ax.hist(eta, histtype=\"step\", density=True, bins=bins, lw=2, alpha=0.7, label=\"Sim\")\n",
    "\n",
    "ax.set_xlabel(r\"$p_\\mathrm{T}^\\mathrm{rel}$\")\n",
    "ax.get_yaxis().set_ticklabels([])\n",
    "ax.set_yscale(\"log\")\n",
    "ax.legend()\n",
    "\n",
    "#####\n",
    "\n",
    "ax = fig.add_subplot(gs[3])\n",
    "\n",
    "bins = np.linspace(0.0, 0.3, 100)\n",
    "\n",
    "jet_mass = jet_masses(\n",
    "    np.array([x_samples[:, :, 2], x_samples[:, :, 0], x_samples[:, :, 1]]).transpose(1, 2, 0)\n",
    ")\n",
    "ax.hist(jet_mass, histtype=\"step\", bins=bins, density=True, lw=2, ls=\"--\", alpha=0.7, label=\"Gen\")\n",
    "\n",
    "jet_mass = jet_masses(\n",
    "    np.array([x.numpy()[:, :, 2], x.numpy()[:, :, 0], x.numpy()[:, :, 1]]).transpose(1, 2, 0)\n",
    ")\n",
    "ax.hist(jet_mass, histtype=\"step\", bins=bins, density=True, lw=2, alpha=0.7, label=\"Sim\")\n",
    "\n",
    "ax.set_xlabel(r\"Jet mass\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pllhome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
