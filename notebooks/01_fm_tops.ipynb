{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set env variable DATA_DIR again because of hydra\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"DATA_DIR\"] = os.environ.get(\"DATA_DIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"fm_tops.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load everything from experiment config\n",
    "with hydra.initialize(version_base=None, config_path=\"../configs/\"):\n",
    "    cfg = hydra.compose(config_name=\"train.yaml\", overrides=[f\"experiment={experiment}\"])\n",
    "    print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = hydra.utils.instantiate(cfg.data)\n",
    "model = hydra.utils.instantiate(cfg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_for_saving = \"nb_fm_tops30\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.array(datamodule.tensor_test)\n",
    "test_mask = np.array(datamodule.mask_test)\n",
    "means = np.array(datamodule.means)\n",
    "stds = np.array(datamodule.stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data.shape)\n",
    "print(test_mask.shape)\n",
    "print(means)\n",
    "print(stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.callbacks.jetnet_eval import JetNetEvaluationCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    "    ModelSummary,\n",
    "    RichProgressBar,\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val/loss\",\n",
    "    mode=\"min\",\n",
    "    save_top_k=1,\n",
    "    save_last=True,\n",
    "    save_weights_only=True,\n",
    "    dirpath=f\"./logs/{model_name_for_saving}/checkpoints\",\n",
    ")\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val/loss\", mode=\"min\", patience=10, verbose=True, min_delta=0.0001\n",
    ")\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "model_summary = ModelSummary()\n",
    "rich_progress_bar = RichProgressBar()\n",
    "\n",
    "# jetnet_eval_callback = JetNetEvaluationCallback(every_n_epochs=3,test_particle_data=test_data,test_mask=test_mask,means=means,stds=stds,num_jet_samples=3000,w_dists_batches=2,selected_particles=[1, 2, 5],normalised_data=False)\n",
    "# jetnet_eval_callback = JetNetEvaluationCallback(every_n_epochs=3,datamodule=datamodule, num_jet_samples=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import CometLogger, CSVLogger, WandbLogger\n",
    "\n",
    "csv_logger = CSVLogger(f\"./logs/{model_name_for_saving}/csv_logs\")\n",
    "comet_logger = CometLogger(\n",
    "    api_key=os.environ.get(\"COMET_API_KEY\"),\n",
    "    workspace=os.environ.get(\"COMET_WORKSPACE\"),  # Optional\n",
    "    save_dir=f\"./logs/{model_name_for_saving}/comet_logs\",  # Optional\n",
    "    project_name=\"Flow Matching\",  # Optional\n",
    "    rest_api_key=os.environ.get(\"COMET_REST_API_KEY\"),  # Optional\n",
    "    experiment_key=os.environ.get(\"COMET_EXPERIMENT_KEY\"),  # Optional\n",
    "    experiment_name=model_name_for_saving,  # Optional\n",
    "    offline=False,\n",
    ")\n",
    "wandb_logger = WandbLogger(\n",
    "    project=\"Flow Matching\", name=model_name_for_saving, save_dir=f\"./logs/{model_name_for_saving}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=30,\n",
    "    callbacks=[checkpoint_callback, lr_monitor, model_summary],\n",
    "    logger=[csv_logger, wandb_logger],\n",
    "    accelerator=\"gpu\",\n",
    ")\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "trainer.fit(\n",
    "    model=model,\n",
    "    datamodule=datamodule,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt = \"/beegfs/desy/user/ewencedr/deep-learning/logs/epic2000/runs/2023-03-30_00-03-29/checkpoints/epoch_1127_loss_0.126.ckpt\"\n",
    "# model = model.load_from_checkpoint(ckpt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.utils.plotting import apply_mpl_styles, create_and_plot_data, plot_single_jets\n",
    "\n",
    "apply_mpl_styles()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, data, generation_times = create_and_plot_data(\n",
    "    np.array(test_data),\n",
    "    [model],\n",
    "    \"fm_tops_nb\",\n",
    "    labels=[\"FM\"],\n",
    "    mask=test_mask,\n",
    "    num_jet_samples=10000,\n",
    "    normalised_data=[False, False],\n",
    "    means=means,\n",
    "    stds=stds,\n",
    "    save_folder=\"./logs/nb_plots/\",\n",
    "    plottype=\"\",\n",
    "    plot_jet_features=False,\n",
    "    plot_w_dists=True,\n",
    "    plot_selected_multiplicities=False,\n",
    "    selected_multiplicities=[1, 3, 5, 10, 20, 30],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_single_jets(test_data, save_folder=\"./logs/nb_plots/\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_single_jets(\n",
    "    data[0], save_folder=\"./logs/nb_plots/\", save_name=\"gen_jets\", color=\"#0271BB\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda()\n",
    "with torch.no_grad():\n",
    "    log_p = model.flows[0].log_prob(torch.tensor(test_data[:5]).float().cuda())\n",
    "print(log_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pllhydra",
   "language": "python",
   "name": "pllhydra"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
