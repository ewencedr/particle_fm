{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Trainings on JetNet Dataset on single jettype"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import, data and checkpoint loading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set env variable DATA_DIR again because of hydra\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"DATA_DIR\"] = os.environ.get(\"DATA_DIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots and metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from particle_fm.data.components import calculate_all_wasserstein_metrics\n",
    "from particle_fm.utils.data_generation import generate_data\n",
    "from particle_fm.utils.plotting import (\n",
    "    apply_mpl_styles,\n",
    "    plot_data,\n",
    "    prepare_data_for_plotting,\n",
    ")\n",
    "\n",
    "apply_mpl_styles()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and datamodule from selected experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"experiment.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load everything from experiment config\n",
    "with hydra.initialize(version_base=None, config_path=\"../configs/\"):\n",
    "    cfg = hydra.compose(config_name=\"train.yaml\", overrides=[f\"experiment={experiment}\"])\n",
    "    # print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = hydra.utils.instantiate(cfg.data)\n",
    "model = hydra.utils.instantiate(cfg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.array(datamodule.tensor_test)\n",
    "test_mask = np.array(datamodule.mask_test)\n",
    "test_cond = np.array(datamodule.tensor_conditioning_test)\n",
    "val_data = np.array(datamodule.tensor_val)\n",
    "val_mask = np.array(datamodule.mask_val)\n",
    "val_cond = np.array(datamodule.tensor_conditioning_val)\n",
    "train_data = np.array(datamodule.tensor_train)\n",
    "train_mask = np.array(datamodule.mask_train)\n",
    "train_cond = np.array(datamodule.tensor_conditioning_train)\n",
    "means = np.array(datamodule.means)\n",
    "stds = np.array(datamodule.stds)\n",
    "means_cond = np.array(datamodule.cond_means)\n",
    "stds_cond = np.array(datamodule.cond_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data.shape)\n",
    "print(test_mask.shape)\n",
    "print(test_cond.shape)\n",
    "print(val_data.shape)\n",
    "print(val_mask.shape)\n",
    "print(val_cond.shape)\n",
    "print(train_data.shape)\n",
    "print(train_mask.shape)\n",
    "print(train_cond.shape)\n",
    "print(means)\n",
    "print(stds)\n",
    "print(means_cond)\n",
    "print(stds_cond)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add checkpoint path\n",
    "ckpt = \"XXX/checkpoints/last-EMA.ckpt\"\n",
    "model = model.load_from_checkpoint(ckpt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"test\"  # choose from \"test\", \"val\"\n",
    "num_samples = (\n",
    "    -1\n",
    ")  # negative values are interpreted as multiplications of len(dataset), e.g. -2 -> 2*len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == \"test\":\n",
    "    background_data = test_data\n",
    "    background_mask = test_mask\n",
    "    background_cond = test_cond\n",
    "elif dataset == \"val\":\n",
    "    background_data = val_data\n",
    "    background_mask = val_mask\n",
    "    background_cond = val_cond\n",
    "else:\n",
    "    raise ValueError(\"Choose from test and val\")\n",
    "print(background_data.shape)\n",
    "len_data = len(background_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_samples < 0:\n",
    "    factor = abs(num_samples)\n",
    "    num_samples = len(background_data) * factor\n",
    "    background_data = np.repeat(background_data, factor, axis=0)\n",
    "    background_mask = np.repeat(background_mask, factor, axis=0)\n",
    "    background_cond = np.repeat(background_cond, factor, axis=0)\n",
    "print(background_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(9999)\n",
    "data, generation_time = generate_data(\n",
    "    model,\n",
    "    num_jet_samples=len(background_data),\n",
    "    batch_size=1000,\n",
    "    cond=torch.tensor(background_cond),\n",
    "    variable_set_sizes=True,\n",
    "    mask=torch.tensor(background_mask),\n",
    "    normalized_data=True,\n",
    "    means=means,\n",
    "    stds=stds,\n",
    "    ode_solver=\"em\",\n",
    "    ode_steps=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Generation time: {generation_time:.2f}s\")\n",
    "print(f\"Generation time per jet: {generation_time / len(background_data):.5f}s\")\n",
    "print(data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save data in npy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/\".join(ckpt.split(\"/\")[:-2]) + \"/\"\n",
    "file_name = \"generated_data.npy\"\n",
    "full_path = path + file_name\n",
    "print(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(full_path, data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/\".join(ckpt.split(\"/\")[:-2]) + \"/\"\n",
    "# file_name = \"generated_data.npy\"\n",
    "file_name = \"final_generated_data.npy\"\n",
    "full_path = path + file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "# data = data[:len_data]\n",
    "print(data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wasserstein distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(background_data.shape)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_dists = calculate_all_wasserstein_metrics(\n",
    "    background_data, data, num_eval_samples=50_000, num_batches=40\n",
    ")\n",
    "\n",
    "print(f\"W-Dist m: {w_dists['w1m_mean']:4.3E} +- {w_dists['w1m_std']:4.3E}\")\n",
    "print(f\"W-Dist p: {w_dists['w1p_mean']:4.3E} +- {w_dists['w1p_std']:4.3E}\")\n",
    "print(f\"W-Dist efp: {w_dists['w1efp_mean']:4.3E} +- {w_dists['w1efp_std']:4.3E}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_config = {\n",
    "    \"num_samples\": -1,\n",
    "    \"plot_jet_features\": True,\n",
    "    \"plot_w_dists\": False,\n",
    "    \"plot_efps\": False,\n",
    "    \"plot_selected_multiplicities\": True,\n",
    "    \"selected_multiplicities\": [10, 20, 30, 40, 50, 100],\n",
    "    \"selected_particles\": [1, 3, 10],\n",
    "    \"plottype\": \"sim_data\",\n",
    "    \"save_fig\": False,\n",
    "    \"variable_jet_sizes_plotting\": True,\n",
    "    \"bins\": 100,\n",
    "    \"close_fig\": False,\n",
    "}\n",
    "plot_prep_config = {\n",
    "    \"calculate_efps\" if key == \"plot_efps\" else key: value\n",
    "    for key, value in plot_config.items()\n",
    "    if key in [\"plot_efps\", \"selected_particles\", \"selected_multiplicities\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    jet_data,\n",
    "    efps_values,\n",
    "    pt_selected_particles,\n",
    "    pt_selected_multiplicities,\n",
    ") = prepare_data_for_plotting(\n",
    "    np.array([data]),\n",
    "    **plot_prep_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    jet_data_sim,\n",
    "    efps_sim,\n",
    "    pt_selected_particles_sim,\n",
    "    pt_selected_multiplicities_sim,\n",
    ") = prepare_data_for_plotting(\n",
    "    [background_data],\n",
    "    **plot_prep_config,\n",
    ")\n",
    "jet_data_sim, efps_sim, pt_selected_particles_sim = (\n",
    "    jet_data_sim[0],\n",
    "    efps_sim[0],\n",
    "    pt_selected_particles_sim[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_data(\n",
    "    particle_data=np.array([data]),\n",
    "    sim_data=background_data,\n",
    "    jet_data_sim=jet_data_sim,\n",
    "    jet_data=jet_data,\n",
    "    efps_sim=efps_sim,\n",
    "    efps_values=efps_values,\n",
    "    pt_selected_particles=pt_selected_particles,\n",
    "    pt_selected_multiplicities=pt_selected_multiplicities,\n",
    "    pt_selected_particles_sim=pt_selected_particles_sim,\n",
    "    pt_selected_multiplicities_sim=pt_selected_multiplicities_sim,\n",
    "    **plot_config,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truth value wasserstein distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_dists = calculate_all_wasserstein_metrics(\n",
    "    background_data, train_data, num_eval_samples=50_000, num_batches=40\n",
    ")\n",
    "\n",
    "print(f\"W-Dist m: {w_dists['w1m_mean']:4.3E} +- {w_dists['w1m_std']:4.3E}\")\n",
    "print(f\"W-Dist p: {w_dists['w1p_mean']:4.3E} +- {w_dists['w1p_std']:4.3E}\")\n",
    "print(f\"W-Dist efp: {w_dists['w1efp_mean']:4.3E} +- {w_dists['w1efp_std']:4.3E}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jet substructure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create and save substructure data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "from particle_fm.data.components.metrics import wasserstein_distance_batched\n",
    "from particle_fm.utils.jet_substructure import dump_hlvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/\".join(ckpt.split(\"/\")[:-2]) + \"/\"\n",
    "file_name = \"substructure\"\n",
    "full_path = path + file_name\n",
    "print(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_hlvs(data, full_path, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JetNet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path for jetnet substructure\n",
    "path_jetnet = f\"XXX/jetnet_substructure/{datamodule.hparams.jet_type[0]}-{datamodule.hparams.num_particles}_substructure\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_hlvs(background_data, path_jetnet, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load and compare generated data with JetNet data (w-dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load substructure for model generated data\n",
    "keys = []\n",
    "data_substructure = []\n",
    "with h5py.File(full_path + \".h5\", \"r\") as f:\n",
    "    print(f.keys())\n",
    "    tau21 = np.array(f[\"tau21\"])\n",
    "    tau32 = np.array(f[\"tau32\"])\n",
    "    d2 = np.array(f[\"d2\"])\n",
    "    for key in f.keys():\n",
    "        keys.append(key)\n",
    "        data_substructure.append(np.array(f[key]))\n",
    "data_substructure = np.array(data_substructure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load substructure for JetNet data\n",
    "data_substructure_jetnet = []\n",
    "with h5py.File(path_jetnet + \".h5\", \"r\") as f:\n",
    "    tau21_jetnet = np.array(f[\"tau21\"])\n",
    "    tau32_jetnet = np.array(f[\"tau32\"])\n",
    "    d2_jetnet = np.array(f[\"d2\"])\n",
    "    for key in f.keys():\n",
    "        data_substructure_jetnet.append(np.array(f[key]))\n",
    "data_substructure_jetnet = np.array(data_substructure_jetnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_dist_tau21_mean, w_dist_tau21_std = wasserstein_distance_batched(\n",
    "    tau21_jetnet, tau21, num_eval_samples=50_000, num_batches=40\n",
    ")\n",
    "w_dist_tau32_mean, w_dist_tau32_std = wasserstein_distance_batched(\n",
    "    tau32_jetnet, tau32, num_eval_samples=50_000, num_batches=40\n",
    ")\n",
    "w_dist_d2_mean, w_dist_d2_std = wasserstein_distance_batched(\n",
    "    d2_jetnet, d2, num_eval_samples=50_000, num_batches=40\n",
    ")\n",
    "print(f\"W-Dist tau21: {w_dist_tau21_mean:4.3E} +- {w_dist_tau21_std:4.3E}\")\n",
    "print(f\"W-Dist tau32: {w_dist_tau32_mean:4.3E} +- {w_dist_tau32_std:4.3E}\")\n",
    "print(f\"W-Dist d2: {w_dist_d2_mean:4.3E} +- {w_dist_d2_std:4.3E}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = \"XXX\"\n",
    "dump_hlvs(train_data, path_train, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = \"XXX\"\n",
    "dump_hlvs(test_data, path_test, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load substructure for model generated data\n",
    "keys = []\n",
    "data_substructure = []\n",
    "with h5py.File(path_train + \".h5\", \"r\") as f:\n",
    "    print(f.keys())\n",
    "    tau21 = np.array(f[\"tau21\"])\n",
    "    tau32 = np.array(f[\"tau32\"])\n",
    "    d2 = np.array(f[\"d2\"])\n",
    "    for key in f.keys():\n",
    "        keys.append(key)\n",
    "        data_substructure.append(np.array(f[key]))\n",
    "data_substructure = np.array(data_substructure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load substructure for JetNet data\n",
    "data_substructure_jetnet = []\n",
    "with h5py.File(path_test + \".h5\", \"r\") as f:\n",
    "    tau21_jetnet = np.array(f[\"tau21\"])\n",
    "    tau32_jetnet = np.array(f[\"tau32\"])\n",
    "    d2_jetnet = np.array(f[\"d2\"])\n",
    "    for key in f.keys():\n",
    "        data_substructure_jetnet.append(np.array(f[key]))\n",
    "data_substructure_jetnet = np.array(data_substructure_jetnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tau21_jetnet.shape)\n",
    "print(tau21.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_dist_tau21_mean, w_dist_tau21_std = wasserstein_distance_batched(\n",
    "    tau21_jetnet, tau21, num_eval_samples=50_000, num_batches=40\n",
    ")\n",
    "w_dist_tau32_mean, w_dist_tau32_std = wasserstein_distance_batched(\n",
    "    tau32_jetnet, tau32, num_eval_samples=50_000, num_batches=40\n",
    ")\n",
    "w_dist_d2_mean, w_dist_d2_std = wasserstein_distance_batched(\n",
    "    d2_jetnet, d2, num_eval_samples=50_000, num_batches=40\n",
    ")\n",
    "print(f\"W-Dist tau21: {w_dist_tau21_mean:4.3E} +- {w_dist_tau21_std:4.3E}\")\n",
    "print(f\"W-Dist tau32: {w_dist_tau32_mean:4.3E} +- {w_dist_tau32_std:4.3E}\")\n",
    "print(f\"W-Dist d2: {w_dist_d2_mean:4.3E} +- {w_dist_d2_std:4.3E}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pllhome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
