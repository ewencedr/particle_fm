{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set env variable DATA_DIR again because of hydra\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"DATA_DIR\"] = os.environ.get(\"DATA_DIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here belongs the name of the experiment that you want to run\n",
    "experiment = \"experiment.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load everything from experiment config\n",
    "with hydra.initialize(version_base=None, config_path=\"../configs/\"):\n",
    "    cfg = hydra.compose(config_name=\"train.yaml\", overrides=[f\"experiment={experiment}\"])\n",
    "    # print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = hydra.utils.instantiate(cfg.data)\n",
    "model = hydra.utils.instantiate(cfg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_for_saving = \"nb_fm_tops30\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.array(datamodule.tensor_test)\n",
    "test_mask = np.array(datamodule.mask_test)\n",
    "test_cond = np.array(datamodule.tensor_conditioning_test)\n",
    "val_data = np.array(datamodule.tensor_val)\n",
    "val_mask = np.array(datamodule.mask_val)\n",
    "val_cond = np.array(datamodule.tensor_conditioning_val)\n",
    "train_data = np.array(datamodule.tensor_train)\n",
    "train_mask = np.array(datamodule.mask_train)\n",
    "train_cond = np.array(datamodule.tensor_conditioning_train)\n",
    "means = np.array(datamodule.means)\n",
    "stds = np.array(datamodule.stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data.shape)\n",
    "print(test_mask.shape)\n",
    "print(test_cond.shape)\n",
    "print(val_data.shape)\n",
    "print(val_mask.shape)\n",
    "print(val_cond.shape)\n",
    "print(train_data.shape)\n",
    "print(train_mask.shape)\n",
    "print(train_cond.shape)\n",
    "print(means)\n",
    "print(stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(np.sum(test_mask, axis=-2), return_counts=True)\n",
    "# print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from particle_fm.callbacks.ema import EMA\n",
    "from particle_fm.callbacks.jetnet_eval import JetNetEvaluationCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    "    ModelSummary,\n",
    "    RichProgressBar,\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val/loss\",\n",
    "    mode=\"min\",\n",
    "    save_top_k=1,\n",
    "    save_last=True,\n",
    "    save_weights_only=True,\n",
    "    dirpath=f\"./logs/{model_name_for_saving}/checkpoints\",\n",
    ")\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val/loss\", mode=\"min\", patience=10, verbose=True, min_delta=0.0001\n",
    ")\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "model_summary = ModelSummary()\n",
    "rich_progress_bar = RichProgressBar()\n",
    "\n",
    "# jetnet_eval_callback = JetNetEvaluationCallback(\n",
    "#    every_n_epochs=3,\n",
    "#    num_jet_samples=10000,\n",
    "#    logger=2,\n",
    "#    log_w_dists=False,\n",
    "#    image_path=\"/beegfs/desy/user/ewencedr/deep-learning/logs/comet_logs\",\n",
    "# )\n",
    "\n",
    "ema = EMA(\n",
    "    decay=0.9999,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import CometLogger, CSVLogger, WandbLogger\n",
    "\n",
    "csv_logger = CSVLogger(f\"./logs/{model_name_for_saving}/csv_logs\")\n",
    "comet_logger = CometLogger(\n",
    "    api_key=os.environ.get(\"COMET_API_KEY\"),\n",
    "    workspace=os.environ.get(\"COMET_WORKSPACE\"),  # Optional\n",
    "    save_dir=f\"./logs/{model_name_for_saving}/comet_logs\",  # Optional\n",
    "    project_name=\"Flow Matching\",  # Optional\n",
    "    rest_api_key=os.environ.get(\"COMET_REST_API_KEY\"),  # Optional\n",
    "    experiment_key=os.environ.get(\"COMET_EXPERIMENT_KEY\"),  # Optional\n",
    "    experiment_name=model_name_for_saving,  # Optional\n",
    "    offline=False,\n",
    ")\n",
    "wandb_logger = WandbLogger(\n",
    "    project=\"Flow Matching\", name=model_name_for_saving, save_dir=f\"./logs/{model_name_for_saving}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    callbacks=[checkpoint_callback, lr_monitor, model_summary, ema],\n",
    "    logger=[csv_logger, wandb_logger],\n",
    "    accelerator=\"gpu\",\n",
    ")\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "trainer.fit(\n",
    "    model=model,\n",
    "    datamodule=datamodule,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pllhome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
