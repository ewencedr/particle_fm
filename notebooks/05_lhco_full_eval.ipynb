{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LHCO Cathode Generation Pipeline\n",
    "After the particle level models and the jet feature models have been trained, the final step is to run the whole generation pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "import energyflow as ef\n",
    "import h5py\n",
    "import hydra\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "from sklearn.neighbors import KernelDensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots and metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from particle_fm.data.components import (\n",
    "    calculate_all_wasserstein_metrics,\n",
    "    inverse_normalize_tensor,\n",
    "    normalize_tensor,\n",
    ")\n",
    "from particle_fm.utils.data_generation import generate_data\n",
    "from particle_fm.utils.plotting import (\n",
    "    apply_mpl_styles,\n",
    "    plot_data,\n",
    "    prepare_data_for_plotting,\n",
    ")\n",
    "\n",
    "apply_mpl_styles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set env variable DATA_DIR again because of hydra\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"DATA_DIR\"] = os.environ.get(\"DATA_DIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.environ.get(\"DATA_DIR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate mjj samples\n",
    "We fit a KDE to the mjj distribution of the signal and background samples. We then sample from the KDE to generate new mjj samples in the signal region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 200_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"{data_folder}/lhco/final_data/processed_data_background_rel.h5\"\n",
    "with h5py.File(path, \"r\") as f:\n",
    "    jets = f[\"jet_data\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p4_jets = ef.p4s_from_ptyphims(jets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_p4 = p4_jets[:, 0] + p4_jets[:, 1]\n",
    "mjj = ef.ms_from_p4s(sum_p4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_to_keep = ((mjj < 3300) & (mjj > 2300)) | ((mjj > 3700) & (mjj < 5000))\n",
    "args_to_keep_sr = (mjj > 3300) & (mjj < 3700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mjj_sb = mjj[args_to_keep]\n",
    "mjj_sr = mjj[args_to_keep_sr]\n",
    "args_to_keep_sb_sr = args_to_keep | args_to_keep_sr\n",
    "mjj_sb_sr = mjj[args_to_keep_sb_sr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = plt.hist(\n",
    "    mjj, bins=np.arange(1e3, 9.5e3, 0.1e3), histtype=\"stepfilled\", label=\"mjj\", alpha=0.5\n",
    ")\n",
    "plt.hist(mjj_sb, bins=hist[1], histtype=\"step\", label=\"mjj SB\")\n",
    "plt.hist(mjj_sr, bins=hist[1], histtype=\"step\", label=\"mjj SR\")\n",
    "\n",
    "plt.legend(frameon=False)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = plt.hist(\n",
    "    mjj, bins=np.arange(1e3, 9.5e3, 0.1e3), histtype=\"stepfilled\", label=\"mjj\", alpha=0.5\n",
    ")\n",
    "plt.hist(mjj_sb_sr, bins=hist[1], histtype=\"step\", label=\"mjj SB SR\")\n",
    "\n",
    "plt.legend()\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit KDE on SR and SB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_model_sb_sr = KernelDensity(kernel=\"gaussian\", bandwidth=0.001)\n",
    "kde_model_sb_sr.fit(mjj_sb_sr.reshape(-1, 1))\n",
    "\n",
    "samples_sb_sr = kde_model_sb_sr.sample(n_samples * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = plt.hist(\n",
    "    mjj_sb_sr,\n",
    "    bins=np.arange(1e3, 9.5e3, 0.05e3),\n",
    "    histtype=\"stepfilled\",\n",
    "    label=\"Truth\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.hist(samples_sb_sr[: len(mjj_sb_sr)], bins=hist[1], histtype=\"step\", label=\"KDE samples\")\n",
    "plt.xlabel(\"mjj [GeV]\")\n",
    "plt.ylim(1e-1, 1e5)\n",
    "plt.legend(frameon=False)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### only take SR and SB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_to_keep_sr_samples = (samples_sb_sr > 3300) & (samples_sb_sr < 3700)\n",
    "args_to_keep_sb_samples = ((samples_sb_sr < 3300) & (samples_sb_sr > 2300)) | (\n",
    "    (samples_sb_sr > 3700) & (samples_sb_sr < 5000)\n",
    ")\n",
    "mjj_samples_sr = samples_sb_sr[args_to_keep_sr_samples]\n",
    "mjj_samples_sb = samples_sb_sr[args_to_keep_sb_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mjj_samples_sr = mjj_samples_sr[:n_samples]\n",
    "mjj_samples_sb = mjj_samples_sb[:n_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mjj = f\"{data_folder}/lhco/generated/mjj_data.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mjj_sb = f\"{data_folder}/lhco/generated/mjj_data_sb.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with h5py.File(path_mjj, \"w\") as f:\n",
    "#    f.create_dataset(\"mjj\", data=mjj_samples_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with h5py.File(path_mjj_sb, \"w\") as f:\n",
    "#    f.create_dataset(\"mjj\", data=mjj_samples_sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(path_mjj, \"r\") as f:\n",
    "    mjj_samples_sr = f[\"mjj\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(path_mjj_sb, \"r\") as f:\n",
    "    mjj_samples_sb = f[\"mjj\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = plt.hist(\n",
    "    mjj_sr,\n",
    "    bins=np.arange(1e3, 9.5e3, 0.1e3),\n",
    "    histtype=\"stepfilled\",\n",
    "    label=\"Truth\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.hist(mjj_samples_sr[: len(mjj_sr)], bins=hist[1], histtype=\"step\", label=\"KDE samples\")\n",
    "plt.ylim(1e-1, 1e5)\n",
    "plt.xlabel(\"mjj [GeV]\")\n",
    "plt.legend(frameon=False)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = plt.hist(\n",
    "    mjj_sb[: len(mjj_samples_sb)],\n",
    "    bins=np.arange(1e3, 9.5e3, 0.1e3),\n",
    "    histtype=\"stepfilled\",\n",
    "    label=\"Truth\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.hist(mjj_samples_sb, bins=hist[1], histtype=\"step\", label=\"KDE samples\")\n",
    "plt.ylim(1e-1, 1e5)\n",
    "plt.xlabel(\"mjj [GeV]\")\n",
    "plt.legend(frameon=False)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate from Jet Feature Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"/lhco/lhco_jet_features.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load everything from experiment config\n",
    "with hydra.initialize(version_base=None, config_path=\"../configs/\"):\n",
    "    # cfg = hydra.compose(config_name=\"train.yaml\")\n",
    "    cfg = hydra.compose(config_name=\"train.yaml\", overrides=[f\"experiment={experiment}\"])\n",
    "    print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = hydra.utils.instantiate(cfg.data)\n",
    "model = hydra.utils.instantiate(cfg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_sr = np.array(datamodule.tensor_test_sr)\n",
    "test_cond_sr = np.array(datamodule.tensor_conditioning_test_sr)\n",
    "val_data_sr = np.array(datamodule.tensor_val_sr)\n",
    "val_cond_sr = np.array(datamodule.tensor_conditioning_val_sr)\n",
    "train_data_sr = np.array(datamodule.tensor_train_sr)\n",
    "train_cond_sr = np.array(datamodule.tensor_conditioning_train_sr)\n",
    "means = np.array(datamodule.means)\n",
    "stds = np.array(datamodule.stds)\n",
    "means_cond = np.array(datamodule.cond_means)\n",
    "stds_cond = np.array(datamodule.cond_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_sb = np.array(datamodule.tensor_test)\n",
    "test_cond_sb = np.array(datamodule.tensor_conditioning_test)\n",
    "val_data_sb = np.array(datamodule.tensor_val)\n",
    "val_cond_sb = np.array(datamodule.tensor_conditioning_val)\n",
    "train_data_sb = np.array(datamodule.tensor_train)\n",
    "train_cond_sb = np.array(datamodule.tensor_conditioning_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert checkpoint path here\n",
    "ckpt = \".../last-EMA.ckpt\"\n",
    "model = model.load_from_checkpoint(ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize conditioning variables\n",
    "normalized_cond = normalize_tensor(\n",
    "    torch.tensor(mjj_samples_sr.copy(), dtype=torch.float).clone().unsqueeze(-1),\n",
    "    means_cond,\n",
    "    stds_cond,\n",
    "    datamodule.hparams.normalize_sigma,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize conditioning variables\n",
    "normalized_cond_sb = normalize_tensor(\n",
    "    torch.tensor(mjj_samples_sb.copy(), dtype=torch.float).clone().unsqueeze(-1),\n",
    "    means_cond,\n",
    "    stds_cond,\n",
    "    datamodule.hparams.normalize_sigma,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(9999)\n",
    "data_jet_feature_temp, generation_time = generate_data(\n",
    "    model,\n",
    "    num_jet_samples=n_samples,\n",
    "    batch_size=2048,\n",
    "    cond=normalized_cond[:n_samples],\n",
    "    normalized_data=datamodule.hparams.normalize,\n",
    "    normalize_sigma=datamodule.hparams.normalize_sigma,\n",
    "    means=datamodule.means,\n",
    "    stds=datamodule.stds,\n",
    "    ode_solver=\"midpoint\",\n",
    "    ode_steps=250,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(9999)\n",
    "data_jet_feature_temp_sb, generation_time = generate_data(\n",
    "    model,\n",
    "    num_jet_samples=n_samples,\n",
    "    batch_size=2048,\n",
    "    cond=normalized_cond_sb[:n_samples],\n",
    "    normalized_data=datamodule.hparams.normalize,\n",
    "    means=datamodule.means,\n",
    "    stds=datamodule.stds,\n",
    "    ode_solver=\"midpoint\",\n",
    "    ode_steps=250,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift phi values to [-pi, pi]\n",
    "data_jet_feature_temp[:, 2][data_jet_feature_temp[:, 2] > np.pi] -= 2 * np.pi\n",
    "data_jet_feature_temp[:, 2][data_jet_feature_temp[:, 2] < -np.pi] += 2 * np.pi\n",
    "data_jet_feature_temp[:, 7][data_jet_feature_temp[:, 7] > np.pi] -= 2 * np.pi\n",
    "data_jet_feature_temp[:, 7][data_jet_feature_temp[:, 7] < -np.pi] += 2 * np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift phi values to [-pi, pi]\n",
    "data_jet_feature_temp_sb[:, 2][data_jet_feature_temp_sb[:, 2] > np.pi] -= 2 * np.pi\n",
    "data_jet_feature_temp_sb[:, 2][data_jet_feature_temp_sb[:, 2] < -np.pi] += 2 * np.pi\n",
    "data_jet_feature_temp_sb[:, 7][data_jet_feature_temp_sb[:, 7] > np.pi] -= 2 * np.pi\n",
    "data_jet_feature_temp_sb[:, 7][data_jet_feature_temp_sb[:, 7] < -np.pi] += 2 * np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip particle multiplicity\n",
    "data_jet_feature_temp[:, 4][data_jet_feature_temp[:, 4] < 1] = 1\n",
    "data_jet_feature_temp[:, 4][data_jet_feature_temp[:, 4] > 279] = 279\n",
    "data_jet_feature_temp[:, 9][data_jet_feature_temp[:, 9] < 1] = 1\n",
    "data_jet_feature_temp[:, 9][data_jet_feature_temp[:, 9] > 279] = 279\n",
    "data_jet_feature = data_jet_feature_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip particle multiplicity\n",
    "data_jet_feature_temp_sb[:, 4][data_jet_feature_temp_sb[:, 4] < 1] = 1\n",
    "data_jet_feature_temp_sb[:, 4][data_jet_feature_temp_sb[:, 4] > 279] = 279\n",
    "data_jet_feature_temp_sb[:, 9][data_jet_feature_temp_sb[:, 9] < 1] = 1\n",
    "data_jet_feature_temp_sb[:, 9][data_jet_feature_temp_sb[:, 9] > 279] = 279\n",
    "data_jet_feature_sb = data_jet_feature_temp_sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mask from particle multiplicity\n",
    "n_classes_x = 279\n",
    "mask_x_ints = data_jet_feature[:, 4]\n",
    "targets_x = np.rint(mask_x_ints).astype(int)\n",
    "mask_x = np.expand_dims(np.tril(np.ones((n_classes_x, n_classes_x)), k=-1)[targets_x], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mask from particle multiplicity sideband\n",
    "n_classes_x_sb = 279\n",
    "mask_x_ints_sb = data_jet_feature_sb[:, 4]\n",
    "targets_x_sb = np.rint(mask_x_ints_sb).astype(int)\n",
    "mask_x_sb = np.expand_dims(\n",
    "    np.tril(np.ones((n_classes_x_sb, n_classes_x_sb)), k=-1)[targets_x_sb], axis=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mask from particle multiplicity jet 2\n",
    "n_classes_y = 279\n",
    "mask_y_ints = data_jet_feature[:, 9]\n",
    "targets_y = np.rint(mask_y_ints).astype(int)\n",
    "mask_y = np.expand_dims(np.tril(np.ones((n_classes_y, n_classes_y)), k=-1)[targets_y], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mask from particle multiplicity sideband jet 2\n",
    "n_classes_y_sb = 279\n",
    "mask_y_ints_sb = data_jet_feature_sb[:, 9]\n",
    "targets_y_sb = np.rint(mask_y_ints_sb).astype(int)\n",
    "mask_y_sb = np.expand_dims(\n",
    "    np.tril(np.ones((n_classes_y_sb, n_classes_y_sb)), k=-1)[targets_y_sb], axis=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_jet_feature_temp[:, 4] = np.rint(data_jet_feature_temp[:, 4])\n",
    "data_jet_feature_temp[:, 9] = np.rint(data_jet_feature_temp[:, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_jet_feature_temp_sb[:, 4] = np.rint(data_jet_feature_temp_sb[:, 4])\n",
    "data_jet_feature_temp_sb[:, 9] = np.rint(data_jet_feature_temp_sb[:, 9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_jet_features_full = f\"{data_folder}/lhco/generated/jet_features_full.h5\"\n",
    "# with h5py.File(path_jet_features_full, \"w\") as f:\n",
    "#    f.create_dataset(\"jet_features_x\", data=data_jet_feature[..., :5])\n",
    "#    f.create_dataset(\"jet_features_y\", data=data_jet_feature[..., 5:])\n",
    "#    f.create_dataset(\"mask_x\", data=mask_x)\n",
    "#    f.create_dataset(\"mask_y\", data=mask_y)\n",
    "#    f.create_dataset(\"mjj\", data=mjj_samples_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_jet_features_full_sb = f\"{data_folder}/lhco/generated/jet_features_full_sb.h5\"\n",
    "# with h5py.File(path_jet_features_full_sb, \"w\") as f:\n",
    "#    f.create_dataset(\"jet_features_x\", data=data_jet_feature_sb[..., :5])\n",
    "#    f.create_dataset(\"jet_features_y\", data=data_jet_feature_sb[..., 5:])\n",
    "#    f.create_dataset(\"mask_x\", data=mask_x_sb)\n",
    "#    f.create_dataset(\"mask_y\", data=mask_y_sb)\n",
    "#    f.create_dataset(\"mjj\", data=mjj_samples_sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(path_jet_features_full, \"r\") as f:\n",
    "    data_jet_feature = np.concatenate([f[\"jet_features_x\"][:], f[\"jet_features_y\"][:]], axis=-1)\n",
    "    mask_x = f[\"mask_x\"][:]\n",
    "    mask_y = f[\"mask_y\"][:]\n",
    "    mjj_samples_sr2 = f[\"mjj\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(path_jet_features_full_sb, \"r\") as f:\n",
    "    data_jet_feature_sb = np.concatenate([f[\"jet_features_x\"][:], f[\"jet_features_y\"][:]], axis=-1)\n",
    "    mask_x_sb = f[\"mask_x\"][:]\n",
    "    mask_y_sb = f[\"mask_y\"][:]\n",
    "    mjj_samples_sr2_sb = f[\"mjj\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples = min(n_samples, len(test_data_sr))\n",
    "label_map = {\n",
    "    \"0\": r\"${p_T}_1$\",\n",
    "    \"1\": r\"$\\eta_1$\",\n",
    "    \"2\": r\"$\\phi_1$\",\n",
    "    \"3\": r\"$m_1$\",\n",
    "    \"4\": \"Particle Multiplicity 1\",\n",
    "    \"5\": r\"${p_T}_2$\",\n",
    "    \"6\": r\"$\\eta_2$\",\n",
    "    \"7\": r\"$\\phi_2$\",\n",
    "    \"8\": r\"$m_2$\",\n",
    "    \"9\": \"Particle Multiplicity 2\",\n",
    "}\n",
    "fig, axs = plt.subplots(2, 5, figsize=(25, 11))\n",
    "for index, ax in enumerate(axs.reshape(-1)):\n",
    "    x_min, x_max = min(\n",
    "        np.min(test_data_sr[:plot_samples, index]), np.min(data_jet_feature[:plot_samples, index])\n",
    "    ), max(\n",
    "        np.max(test_data_sr[:plot_samples, index]), np.max(data_jet_feature[:plot_samples, index])\n",
    "    )\n",
    "    if index == 4 or index == 9:\n",
    "        bin_width = 1\n",
    "        bins = range(int(x_min), int(x_max) + bin_width, bin_width)\n",
    "    else:\n",
    "        bins = 100\n",
    "    hist1 = ax.hist(\n",
    "        test_data_sr[:plot_samples, index],\n",
    "        bins=bins,\n",
    "        label=\"Sim. data\",\n",
    "        range=[x_min, x_max],\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    ax.hist(\n",
    "        data_jet_feature[:plot_samples, index], bins=hist1[1], label=\"Gen. data\", histtype=\"step\"\n",
    "    )\n",
    "    ax.set_xlabel(f\"{label_map[str(index)]}\")\n",
    "    if index == 1 or index == 2 or index == 4 or index == 6 or index == 7 or index == 9:\n",
    "        ax.set_yscale(\"log\")\n",
    "    if index == 2 or index == 7:\n",
    "        ax.legend(frameon=False)\n",
    "        ax.set_ylim(1e-1, 1e6)\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Signal Region\", fontsize=30)\n",
    "fig.subplots_adjust(top=0.93)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples = min(n_samples, len(test_data_sb))\n",
    "label_map = {\n",
    "    \"0\": r\"${p_T}_1$\",\n",
    "    \"1\": r\"$\\eta_1$\",\n",
    "    \"2\": r\"$\\phi_1$\",\n",
    "    \"3\": r\"$m_1$\",\n",
    "    \"4\": \"Particle Multiplicity 1\",\n",
    "    \"5\": r\"${p_T}_2$\",\n",
    "    \"6\": r\"$\\eta_2$\",\n",
    "    \"7\": r\"$\\phi_2$\",\n",
    "    \"8\": r\"$m_2$\",\n",
    "    \"9\": \"Particle Multiplicity 2\",\n",
    "}\n",
    "fig, axs = plt.subplots(2, 5, figsize=(25, 11))\n",
    "for index, ax in enumerate(axs.reshape(-1)):\n",
    "    x_min, x_max = min(\n",
    "        np.min(test_data_sb[:plot_samples, index]),\n",
    "        np.min(data_jet_feature_sb[:plot_samples, index]),\n",
    "    ), max(\n",
    "        np.max(test_data_sb[:plot_samples, index]),\n",
    "        np.max(data_jet_feature_sb[:plot_samples, index]),\n",
    "    )\n",
    "    if index == 4 or index == 9:\n",
    "        bin_width = 1\n",
    "        bins = range(int(x_min), int(x_max) + bin_width, bin_width)\n",
    "    else:\n",
    "        bins = 100\n",
    "    hist1 = ax.hist(\n",
    "        test_data_sb[:plot_samples, index],\n",
    "        bins=bins,\n",
    "        label=\"Sim. data\",\n",
    "        range=[x_min, x_max],\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    ax.hist(\n",
    "        data_jet_feature_sb[:plot_samples, index],\n",
    "        bins=hist1[1],\n",
    "        label=\"Gen. data\",\n",
    "        histtype=\"step\",\n",
    "    )\n",
    "    ax.set_xlabel(f\"{label_map[str(index)]}\")\n",
    "    if index == 1 or index == 2 or index == 4 or index == 6 or index == 7 or index == 9:\n",
    "        ax.set_yscale(\"log\")\n",
    "    if index == 2 or index == 7:\n",
    "        ax.legend(frameon=False)\n",
    "        ax.set_ylim(1e-1, 1e6)\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Sideband\", fontsize=30)\n",
    "fig.subplots_adjust(top=0.93)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle Feature Model\n",
    "Generating from the Particle Feature Model takes some time. Therefore a separate script in the `scripts` folder is provided to generate the data. Use the following command to generate the data and provide the file that was created by this notebook as `--cond` argument:\n",
    "\n",
    "```shell\n",
    "python scripts/generate_data_lhco.py --save_file <filename for generated data> --folder <folder where the model was saved> --cond <path to conditioning> --sr <\"True\" for SR, \"False\" for SB>\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pllhome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
