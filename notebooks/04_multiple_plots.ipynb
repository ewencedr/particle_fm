{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set env variable DATA_DIR again because of hydra\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"DATA_DIR\"] = os.environ.get(\"DATA_DIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots and metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.data.components import calculate_all_wasserstein_metrics\n",
    "from src.utils.data_generation import generate_data\n",
    "from src.utils.plotting import apply_mpl_styles, create_and_plot_data, plot_single_jets\n",
    "\n",
    "apply_mpl_styles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment1 = \"plot1.yaml\"\n",
    "experiment2 = \"plot2.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load everything from experiment config\n",
    "with hydra.initialize(version_base=None, config_path=\"../configs/\"):\n",
    "    cfg1 = hydra.compose(config_name=\"train.yaml\", overrides=[f\"experiment={experiment1}\"])\n",
    "    # print(OmegaConf.to_yaml(cfg1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load everything from experiment config\n",
    "with hydra.initialize(version_base=None, config_path=\"../configs/\"):\n",
    "    cfg2 = hydra.compose(config_name=\"train.yaml\", overrides=[f\"experiment={experiment2}\"])\n",
    "    # print(OmegaConf.to_yaml(cfg1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule1 = hydra.utils.instantiate(cfg1.data)\n",
    "datamodule2 = hydra.utils.instantiate(cfg2.data)\n",
    "model1 = hydra.utils.instantiate(cfg1.model)\n",
    "model2 = hydra.utils.instantiate(cfg2.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_for_saving = \"nb_fm_tops30\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule1.setup()\n",
    "datamodule2.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data1 = np.array(datamodule1.tensor_test)\n",
    "test_mask1 = np.array(datamodule1.mask_test)\n",
    "test_cond1 = np.array(datamodule1.tensor_conditioning_test)\n",
    "val_data1 = np.array(datamodule1.tensor_val)\n",
    "val_mask1 = np.array(datamodule1.mask_val)\n",
    "val_cond1 = np.array(datamodule1.tensor_conditioning_val)\n",
    "train_data1 = np.array(datamodule1.tensor_train)\n",
    "train_mask1 = np.array(datamodule1.mask_train)\n",
    "train_cond1 = np.array(datamodule1.tensor_conditioning_train)\n",
    "means1 = np.array(datamodule1.means)\n",
    "stds1 = np.array(datamodule1.stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data1.shape)\n",
    "print(test_mask1.shape)\n",
    "print(test_cond1.shape)\n",
    "print(val_data1.shape)\n",
    "print(val_mask1.shape)\n",
    "print(val_cond1.shape)\n",
    "print(train_data1.shape)\n",
    "print(train_mask1.shape)\n",
    "print(train_cond1.shape)\n",
    "print(means1)\n",
    "print(stds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data2 = np.array(datamodule2.tensor_test)\n",
    "test_mask2 = np.array(datamodule2.mask_test)\n",
    "test_cond2 = np.array(datamodule2.tensor_conditioning_test)\n",
    "val_data2 = np.array(datamodule2.tensor_val)\n",
    "val_mask2 = np.array(datamodule2.mask_val)\n",
    "val_cond2 = np.array(datamodule2.tensor_conditioning_val)\n",
    "train_data2 = np.array(datamodule2.tensor_train)\n",
    "train_mask2 = np.array(datamodule2.mask_train)\n",
    "train_cond2 = np.array(datamodule2.tensor_conditioning_train)\n",
    "means2 = np.array(datamodule2.means)\n",
    "stds2 = np.array(datamodule2.stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt1 = \"/beegfs/desy/user/ewencedr/deep-learning/logs/150 alljets nocond onlymetrics/runs/2023-06-14_18-51-51/checkpoints/epoch_6983_w1m_0.00038674-EMA.ckpt\"\n",
    "ckpt2 = \"/beegfs/desy/user/ewencedr/deep-learning/logs/150 alljets condmasspt onlymetrics/runs/2023-06-15_16-28-35/checkpoints/epoch_4986_w1m_0.00014095-EMA.ckpt\"\n",
    "model1 = model1.load_from_checkpoint(ckpt1)\n",
    "model2 = model2.load_from_checkpoint(ckpt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_type = \"t\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = test_mask1\n",
    "data1 = test_data1\n",
    "cond1 = test_cond1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only data, mask and cond for the specified jet type\n",
    "# also for training data because it is compared to test data later\n",
    "index_jettype1 = np.squeeze(np.argwhere(np.array(datamodule1.jet_types) == jet_type))\n",
    "\n",
    "indice_jettype1 = np.squeeze(np.argwhere(cond1[:, index_jettype1] == 1))\n",
    "indice_jettype_train1 = np.squeeze(np.argwhere(train_cond1[:, index_jettype1] == 1))\n",
    "\n",
    "mask_jettype1 = mask1[indice_jettype1]\n",
    "data_jettype1 = data1[indice_jettype1]\n",
    "cond_jettype1 = cond1[indice_jettype1]\n",
    "train_mask_jettype1 = train_mask1[indice_jettype_train1]\n",
    "train_data_jettype1 = train_data1[indice_jettype_train1]\n",
    "train_cond_jettype1 = train_cond1[indice_jettype_train1]\n",
    "\n",
    "print(mask_jettype1.shape)\n",
    "print(data_jettype1.shape)\n",
    "print(cond_jettype1.shape)\n",
    "print(train_mask_jettype1.shape)\n",
    "print(train_data_jettype1.shape)\n",
    "print(train_cond_jettype1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask2 = test_mask2\n",
    "data2 = test_data2\n",
    "cond2 = test_cond2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only data, mask and cond for the specified jet type\n",
    "# also for training data because it is compared to test data later\n",
    "index_jettype2 = np.squeeze(np.argwhere(np.array(datamodule2.jet_types) == jet_type))\n",
    "\n",
    "indice_jettype2 = np.squeeze(np.argwhere(cond2[:, index_jettype2] == 1))\n",
    "indice_jettype_train2 = np.squeeze(np.argwhere(train_cond2[:, index_jettype2] == 1))\n",
    "\n",
    "mask_jettype2 = mask2[indice_jettype2]\n",
    "data_jettype2 = data2[indice_jettype2]\n",
    "cond_jettype2 = cond2[indice_jettype2]\n",
    "train_mask_jettype1 = train_mask1[indice_jettype_train1]\n",
    "train_data_jettype1 = train_data1[indice_jettype_train1]\n",
    "train_cond_jettype1 = train_cond1[indice_jettype_train1]\n",
    "\n",
    "print(mask_jettype1.shape)\n",
    "print(data_jettype1.shape)\n",
    "print(cond_jettype1.shape)\n",
    "print(train_mask_jettype1.shape)\n",
    "print(train_data_jettype1.shape)\n",
    "print(train_cond_jettype1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, data, generation_times = create_and_plot_data(\n",
    "#    np.array(data_jettype),\n",
    "#    [model1, model2],\n",
    "#    cond=[torch.tensor(cond_jettype), torch.tensor(cond_jettype)],\n",
    "#    save_name=\"fm_tops_nb\",\n",
    "#    labels=[\"FM\", \"2\"],\n",
    "#    mask=mask_jettype,\n",
    "#    num_jet_samples=len(data_jettype),\n",
    "#    batch_size=1000,\n",
    "#    variable_set_sizes=True,\n",
    "#    normalized_data=[True, True],\n",
    "#    means=means,\n",
    "#    stds=stds,\n",
    "#    save_folder=\"./logs/nb_plots/\",\n",
    "#    plottype=\"sim_data\",\n",
    "#    plot_jet_features=True,\n",
    "#    plot_w_dists=False,\n",
    "#    plot_selected_multiplicities=False,\n",
    "#    selected_multiplicities=[1, 3, 5, 10, 20, 30],\n",
    "#    ode_solver=\"midpoint\",\n",
    "#    ode_steps=100,\n",
    "#    bins=100,\n",
    "#    mass_linear=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = np.load(\n",
    "    \"/beegfs/desy/user/ewencedr/deep-learning/logs/150 alljets nocond onlymetrics/runs/2023-06-14_18-51-51/gen_data_t.npy\"\n",
    ")\n",
    "data2 = np.load(\n",
    "    \"/beegfs/desy/user/ewencedr/deep-learning/logs/150 alljets condmasspt onlymetrics/runs/2023-06-15_16-28-35/gen_data_t.npy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data1.shape)\n",
    "print(data2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.plotting import plot_data, prepare_data_for_plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    jet_data,\n",
    "    efps_values,\n",
    "    pt_selected_particles,\n",
    "    pt_selected_multiplicities,\n",
    ") = prepare_data_for_plotting(np.array([data1, data2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    jet_data_sim,\n",
    "    efps_sim,\n",
    "    pt_selected_particles_sim,\n",
    "    pt_selected_multiplicities_sim,\n",
    ") = prepare_data_for_plotting([data_jettype1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pt_selected_particles_sim.shape)\n",
    "print(pt_selected_particles.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array([data1, data2]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jet_data.shape)\n",
    "print(data_jettype1.shape)\n",
    "print(mask_jettype1.shape)\n",
    "sim_data = np.concatenate([data_jettype2, mask_jettype2], axis=-1)\n",
    "print(sim_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_data(\n",
    "    particle_data=np.array([data1, data2]),\n",
    "    sim_data=sim_data,\n",
    "    jet_data_sim=jet_data_sim[0],\n",
    "    jet_data=jet_data,\n",
    "    efps_sim=efps_sim[0],\n",
    "    efps_values=efps_values,\n",
    "    labels=[\"all\", \"all cond\"],\n",
    "    sim_data_label=\"JetNet\",\n",
    "    plot_jet_features=True,\n",
    "    plot_w_dists=False,\n",
    "    plot_efps=False,\n",
    "    plot_selected_multiplicities=False,\n",
    "    selected_multiplicities=[20, 30, 40],\n",
    "    selected_particles=[1, 3, 10],\n",
    "    pt_selected_particles=pt_selected_particles,\n",
    "    pt_selected_multiplicities=pt_selected_multiplicities,\n",
    "    pt_selected_particles_sim=pt_selected_particles_sim[0],\n",
    "    pt_selected_multiplicities_sim=pt_selected_multiplicities_sim,\n",
    "    plottype=\"sim_data\",\n",
    "    save_fig=False,\n",
    "    variable_jet_sizes_plotting=True,\n",
    "    bins=100,\n",
    "    close_fig=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pllhome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
