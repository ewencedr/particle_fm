{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import hydra\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set env variable DATA_DIR again because of hydra\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"DATA_DIR\"] = os.environ.get(\"DATA_DIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots and metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.data.components import calculate_all_wasserstein_metrics\n",
    "from src.utils.data_generation import generate_data\n",
    "from src.utils.plotting import apply_mpl_styles, create_and_plot_data, plot_single_jets\n",
    "\n",
    "apply_mpl_styles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment1 = \"fm_tops150.yaml\"\n",
    "experiment2 = \"fm_tops150_cond.yaml\"\n",
    "experiment3 = \"diffusion_tops150_cond.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load everything from experiment config\n",
    "with hydra.initialize(version_base=None, config_path=\"../configs/\"):\n",
    "    cfg1 = hydra.compose(config_name=\"train.yaml\", overrides=[f\"experiment={experiment1}\"])\n",
    "    # print(OmegaConf.to_yaml(cfg1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load everything from experiment config\n",
    "with hydra.initialize(version_base=None, config_path=\"../configs/\"):\n",
    "    cfg2 = hydra.compose(config_name=\"train.yaml\", overrides=[f\"experiment={experiment2}\"])\n",
    "    # print(OmegaConf.to_yaml(cfg1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule1 = hydra.utils.instantiate(cfg1.data)\n",
    "datamodule2 = hydra.utils.instantiate(cfg2.data)\n",
    "model1 = hydra.utils.instantiate(cfg1.model)\n",
    "model2 = hydra.utils.instantiate(cfg2.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_for_saving = \"nb_fm_tops30\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule1.setup()\n",
    "datamodule2.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data1 = np.array(datamodule1.tensor_test)\n",
    "test_mask1 = np.array(datamodule1.mask_test)\n",
    "test_cond1 = np.array(datamodule1.tensor_conditioning_test)\n",
    "val_data1 = np.array(datamodule1.tensor_val)\n",
    "val_mask1 = np.array(datamodule1.mask_val)\n",
    "val_cond1 = np.array(datamodule1.tensor_conditioning_val)\n",
    "train_data1 = np.array(datamodule1.tensor_train)\n",
    "train_mask1 = np.array(datamodule1.mask_train)\n",
    "train_cond1 = np.array(datamodule1.tensor_conditioning_train)\n",
    "means1 = np.array(datamodule1.means)\n",
    "stds1 = np.array(datamodule1.stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data1.shape)\n",
    "print(test_mask1.shape)\n",
    "print(test_cond1.shape)\n",
    "print(val_data1.shape)\n",
    "print(val_mask1.shape)\n",
    "print(val_cond1.shape)\n",
    "print(train_data1.shape)\n",
    "print(train_mask1.shape)\n",
    "print(train_cond1.shape)\n",
    "print(means1)\n",
    "print(stds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data2 = np.array(datamodule2.tensor_test)\n",
    "test_mask2 = np.array(datamodule2.mask_test)\n",
    "test_cond2 = np.array(datamodule2.tensor_conditioning_test)\n",
    "val_data2 = np.array(datamodule2.tensor_val)\n",
    "val_mask2 = np.array(datamodule2.mask_val)\n",
    "val_cond2 = np.array(datamodule2.tensor_conditioning_val)\n",
    "train_data2 = np.array(datamodule2.tensor_train)\n",
    "train_mask2 = np.array(datamodule2.mask_train)\n",
    "train_cond2 = np.array(datamodule2.tensor_conditioning_train)\n",
    "means2 = np.array(datamodule2.means)\n",
    "stds2 = np.array(datamodule2.stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt1 = \"/beegfs/desy/user/ewencedr/deep-learning/logs/fm_tops150_cond/runs/2023-07-11_03-07-10/checkpoints/last-EMA.ckpt\"\n",
    "ckpt2 = \"/beegfs/desy/user/ewencedr/deep-learning/logs/diffusion_tops150_cond/runs/2023-07-11_03-11-13/checkpoints/last-EMA.ckpt\"\n",
    "model1 = model1.load_from_checkpoint(ckpt1)\n",
    "model2 = model2.load_from_checkpoint(ckpt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_type = \"t\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = test_mask1\n",
    "data1 = test_data1\n",
    "cond1 = test_cond1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only data, mask and cond for the specified jet type\n",
    "# also for training data because it is compared to test data later\n",
    "index_jettype1 = np.squeeze(np.argwhere(np.array(datamodule1.jet_types) == jet_type))\n",
    "\n",
    "indice_jettype1 = np.squeeze(np.argwhere(cond1[:, index_jettype1] == 1))\n",
    "indice_jettype_train1 = np.squeeze(np.argwhere(train_cond1[:, index_jettype1] == 1))\n",
    "\n",
    "mask_jettype1 = mask1[indice_jettype1]\n",
    "data_jettype1 = data1[indice_jettype1]\n",
    "cond_jettype1 = cond1[indice_jettype1]\n",
    "train_mask_jettype1 = train_mask1[indice_jettype_train1]\n",
    "train_data_jettype1 = train_data1[indice_jettype_train1]\n",
    "train_cond_jettype1 = train_cond1[indice_jettype_train1]\n",
    "\n",
    "print(mask_jettype1.shape)\n",
    "print(data_jettype1.shape)\n",
    "print(cond_jettype1.shape)\n",
    "print(train_mask_jettype1.shape)\n",
    "print(train_data_jettype1.shape)\n",
    "print(train_cond_jettype1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask2 = test_mask2\n",
    "data2 = test_data2\n",
    "cond2 = test_cond2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only data, mask and cond for the specified jet type\n",
    "# also for training data because it is compared to test data later\n",
    "index_jettype2 = np.squeeze(np.argwhere(np.array(datamodule2.jet_types) == jet_type))\n",
    "\n",
    "indice_jettype2 = np.squeeze(np.argwhere(cond2[:, index_jettype2] == 1))\n",
    "indice_jettype_train2 = np.squeeze(np.argwhere(train_cond2[:, index_jettype2] == 1))\n",
    "\n",
    "mask_jettype2 = mask2[indice_jettype2]\n",
    "data_jettype2 = data2[indice_jettype2]\n",
    "cond_jettype2 = cond2[indice_jettype2]\n",
    "train_mask_jettype1 = train_mask1[indice_jettype_train1]\n",
    "train_data_jettype1 = train_data1[indice_jettype_train1]\n",
    "train_cond_jettype1 = train_cond1[indice_jettype_train1]\n",
    "\n",
    "print(mask_jettype1.shape)\n",
    "print(data_jettype1.shape)\n",
    "print(cond_jettype1.shape)\n",
    "print(train_mask_jettype1.shape)\n",
    "print(train_data_jettype1.shape)\n",
    "print(train_cond_jettype1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, data, generation_times = create_and_plot_data(\n",
    "#    np.array(data_jettype),\n",
    "#    [model1, model2],\n",
    "#    cond=[torch.tensor(cond_jettype), torch.tensor(cond_jettype)],\n",
    "#    save_name=\"fm_tops_nb\",\n",
    "#    labels=[\"FM\", \"2\"],\n",
    "#    mask=mask_jettype,\n",
    "#    num_jet_samples=len(data_jettype),\n",
    "#    batch_size=1000,\n",
    "#    variable_set_sizes=True,\n",
    "#    normalized_data=[True, True],\n",
    "#    means=means,\n",
    "#    stds=stds,\n",
    "#    save_folder=\"./logs/nb_plots/\",\n",
    "#    plottype=\"sim_data\",\n",
    "#    plot_jet_features=True,\n",
    "#    plot_w_dists=False,\n",
    "#    plot_selected_multiplicities=False,\n",
    "#    selected_multiplicities=[1, 3, 5, 10, 20, 30],\n",
    "#    ode_solver=\"midpoint\",\n",
    "#    ode_steps=100,\n",
    "#    bins=100,\n",
    "#    mass_linear=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = np.load(\n",
    "    \"/beegfs/desy/user/ewencedr/deep-learning/logs/fm_tops150/runs/2023-07-11_03-06-15/final_generated_data_mp200nfe.npy\"\n",
    ")\n",
    "data2 = np.load(\n",
    "    \"/beegfs/desy/user/ewencedr/deep-learning/logs/fm_tops150_cond/runs/2023-07-11_03-07-10/final_generated_data_mp200nfe.npy\"\n",
    ")\n",
    "data3 = np.load(\n",
    "    \"/beegfs/desy/user/ewencedr/deep-learning/logs/diffusion_tops150_cond/runs/2023-07-11_03-11-13/final_generated_data_mp200nfe.npy\"\n",
    ")\n",
    "\n",
    "# data1 = np.load(\"/beegfs/desy/user/ewencedr/deep-learning/logs/fm_tops30/runs/2023-07-12_00-57-10/final_generated_data_mp200nfe.npy\")\n",
    "# data2 = np.load(\"/beegfs/desy/user/ewencedr/deep-learning/logs/fm_tops30_cond/runs/2023-07-11_03-03-48/final_generated_data_mp200nfe.npy\")\n",
    "# data3 = np.load(\"/beegfs/desy/user/ewencedr/deep-learning/logs/diffusion_tops30_cond/runs/2023-07-11_03-12-22/final_generated_data_mp200nfe.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data1[: len(test_data1)]\n",
    "data2 = data2[: len(test_data1)]\n",
    "data3 = data3[: len(test_data1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data1.shape)\n",
    "print(data2.shape)\n",
    "print(data3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.plotting import plot_data, prepare_data_for_plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_config = {\n",
    "    \"num_samples\": -1,\n",
    "    \"plot_jet_features\": False,\n",
    "    \"plot_w_dists\": False,\n",
    "    \"plot_efps\": True,\n",
    "    \"plot_selected_multiplicities\": False,\n",
    "    \"selected_multiplicities\": [10, 20, 30, 40, 50, 100],\n",
    "    \"selected_particles\": [1, 3, 10],\n",
    "    \"plottype\": \"sim_data\",\n",
    "    \"save_fig\": False,\n",
    "    \"variable_jet_sizes_plotting\": True,\n",
    "    \"bins\": 100,\n",
    "    \"close_fig\": False,\n",
    "    \"labels\": [\"FM\", \"FM cond\", \"Jedi cond\"],\n",
    "}\n",
    "plot_prep_config = {\n",
    "    \"calculate_efps\" if key == \"plot_efps\" else key: value\n",
    "    for key, value in plot_config.items()\n",
    "    if key in [\"plot_efps\", \"selected_particles\", \"selected_multiplicities\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    jet_data,\n",
    "    efps_values,\n",
    "    pt_selected_particles,\n",
    "    pt_selected_multiplicities,\n",
    ") = prepare_data_for_plotting(\n",
    "    np.array([data1, data2, data3]),\n",
    "    **plot_prep_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(efps_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    jet_data_sim,\n",
    "    efps_sim,\n",
    "    pt_selected_particles_sim,\n",
    "    pt_selected_multiplicities_sim,\n",
    ") = prepare_data_for_plotting(\n",
    "    [test_data1],\n",
    "    **plot_prep_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(jet_data.shape)\n",
    "# print(data_jettype1.shape)\n",
    "# print(mask_jettype1.shape)\n",
    "# sim_data = np.concatenate([test_data1, test_mask1], axis=-1)\n",
    "# print(sim_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data = test_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from cycler import cycler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpl.rcParams[\"axes.prop_cycle\"] = cycler(\n",
    "#    color=[\n",
    "#        \"#B6BFC3\",\n",
    "#        \"#0271BB\",\n",
    "#        \"#E2001A\",\n",
    "#    ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_data_sim, efps_sim, pt_selected_particles_sim = (\n",
    "    jet_data_sim[0],\n",
    "    efps_sim[0],\n",
    "    pt_selected_particles_sim[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_data(\n",
    "    particle_data=np.array([data1, data2, data3]),\n",
    "    sim_data=sim_data,\n",
    "    jet_data_sim=jet_data_sim,\n",
    "    jet_data=jet_data,\n",
    "    efps_sim=efps_sim,\n",
    "    efps_values=efps_values,\n",
    "    pt_selected_particles=pt_selected_particles,\n",
    "    pt_selected_multiplicities=pt_selected_multiplicities,\n",
    "    pt_selected_particles_sim=pt_selected_particles_sim,\n",
    "    pt_selected_multiplicities_sim=pt_selected_multiplicities_sim,\n",
    "    **plot_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Substructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_sub = \"/beegfs/desy/user/ewencedr/deep-learning/logs/fm_tops150/runs/2023-07-11_03-06-15/substructure_jetnet_mp200nfe\"\n",
    "# b_sub = \"/beegfs/desy/user/ewencedr/deep-learning/logs/fm_tops30/runs/2023-07-12_00-57-10/substructure_jetnet_mp200nfe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "substr1 = \"/beegfs/desy/user/ewencedr/deep-learning/logs/fm_tops150/runs/2023-07-11_03-06-15/substructure_mp200nfe\"\n",
    "substr2 = \"/beegfs/desy/user/ewencedr/deep-learning/logs/fm_tops150_cond/runs/2023-07-11_03-07-10/substructure_mp200nfe\"\n",
    "substr3 = \"/beegfs/desy/user/ewencedr/deep-learning/logs/diffusion_tops150_cond/runs/2023-07-11_03-11-13/substructure_mp200nfe\"\n",
    "# substr1 = \"/beegfs/desy/user/ewencedr/deep-learning/logs/fm_tops30/runs/2023-07-12_00-57-10/substructure_mp200nfe\"\n",
    "# substr2 = \"/beegfs/desy/user/ewencedr/deep-learning/logs/fm_tops30_cond/runs/2023-07-11_03-03-48/substructure_mp200nfe\"\n",
    "# substr3 = \"/beegfs/desy/user/ewencedr/deep-learning/logs/diffusion_tops30_cond/runs/2023-07-11_03-12-22/substructure_mp200nfe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load substructure for model generated data\n",
    "data_substructure_b = []\n",
    "with h5py.File(b_sub + \".h5\", \"r\") as f:\n",
    "    tau21_b = np.array(f[\"tau21\"])\n",
    "    tau32_b = np.array(f[\"tau32\"])\n",
    "    d2_b = np.array(f[\"d2\"])\n",
    "    for key in f.keys():\n",
    "        data_substructure_b.append(np.array(f[key]))\n",
    "data_substructure_b = np.array(data_substructure_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load substructure for model generated data\n",
    "data_substructure_1 = []\n",
    "with h5py.File(substr1 + \".h5\", \"r\") as f:\n",
    "    tau21_1 = np.array(f[\"tau21\"])[: len(tau21_b)]\n",
    "    tau32_1 = np.array(f[\"tau32\"])[: len(tau21_b)]\n",
    "    d2_1 = np.array(f[\"d2\"])[: len(tau21_b)]\n",
    "    for key in f.keys():\n",
    "        data_substructure_1.append(np.array(f[key]))\n",
    "data_substructure_1 = np.array(data_substructure_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load substructure for model generated data\n",
    "data_substructure_2 = []\n",
    "with h5py.File(substr2 + \".h5\", \"r\") as f:\n",
    "    tau21_2 = np.array(f[\"tau21\"])[: len(tau21_b)]\n",
    "    tau32_2 = np.array(f[\"tau32\"])[: len(tau21_b)]\n",
    "    d2_2 = np.array(f[\"d2\"])[: len(tau21_b)]\n",
    "    for key in f.keys():\n",
    "        data_substructure_2.append(np.array(f[key]))\n",
    "data_substructure_2 = np.array(data_substructure_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load substructure for model generated data\n",
    "data_substructure_3 = []\n",
    "with h5py.File(substr3 + \".h5\", \"r\") as f:\n",
    "    tau21_3 = np.array(f[\"tau21\"])[: len(tau21_b)]\n",
    "    tau32_3 = np.array(f[\"tau32\"])[: len(tau21_b)]\n",
    "    d2_3 = np.array(f[\"d2\"])[: len(tau21_b)]\n",
    "    for key in f.keys():\n",
    "        data_substructure_3.append(np.array(f[key]))\n",
    "data_substructure_3 = np.array(data_substructure_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "bins = 100\n",
    "histb = ax1.hist(tau21_b, bins=bins, label=\"Sim data\", histtype=\"stepfilled\", alpha=0.5)\n",
    "hist1 = ax1.hist(tau21_1, bins=histb[1], label=\"FM\", histtype=\"step\")\n",
    "hist2 = ax1.hist(tau21_2, bins=histb[1], label=\"FM cond\", histtype=\"step\")\n",
    "hist3 = ax1.hist(tau21_3, bins=histb[1], label=\"Jedi cond\", histtype=\"step\")\n",
    "ax1.set_title(r\"$\\tau_{21}$\")\n",
    "# ax1.legend(loc=\"best\")\n",
    "\n",
    "histb_t32 = ax2.hist(tau32_b, bins=bins, label=\"Sim data\", histtype=\"stepfilled\", alpha=0.5)\n",
    "hist1_t32 = ax2.hist(tau32_1, bins=histb_t32[1], label=\"FM\", histtype=\"step\")\n",
    "hist2_t32 = ax2.hist(tau32_2, bins=histb_t32[1], label=\"FM cond\", histtype=\"step\")\n",
    "hist3_t32 = ax2.hist(tau32_3, bins=histb_t32[1], label=\"Jedi cond\", histtype=\"step\")\n",
    "ax2.set_title(r\"$\\tau_{32}$\")\n",
    "# ax2.legend(loc=\"best\")\n",
    "ax2.legend(loc=\"best\", prop={\"size\": 14}, frameon=True)\n",
    "\n",
    "histb_d = ax3.hist(d2_b, bins=bins, label=\"Sim data\", histtype=\"stepfilled\", alpha=0.5)\n",
    "hist1_d = ax3.hist(d2_1, bins=histb_d[1], label=\"FM\", histtype=\"step\")\n",
    "hist2_d = ax3.hist(d2_2, bins=histb_d[1], label=\"FM cond\", histtype=\"step\")\n",
    "hist3_d = ax3.hist(d2_3, bins=histb_d[1], label=\"Jedi cond\", histtype=\"step\")\n",
    "ax3.set_title(r\"$d_2$\")\n",
    "# ax3.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save file as h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load conditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../data/conditioning.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(filepath, \"r\") as f:\n",
    "    print(f.keys())\n",
    "    types = f[\"type\"][:]\n",
    "    mass = f[\"mass\"][:]\n",
    "    pt = f[\"pt\"][:]\n",
    "    num_particles = f[\"num_particles\"][:]\n",
    "    gen_ctxt = f[\"gen_ctxt\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\n",
    "    \"/beegfs/desy/user/ewencedr/deep-learning/logs/fm_tops150_cond/runs/2023-07-11_03-07-10/final_generated_data_mp200nfe.npy\"\n",
    ")\n",
    "# data = np.load(\"/beegfs/desy/user/ewencedr/deep-learning/logs/fm_tops30_cond/runs/2023-07-11_03-03-48/final_generated_data_mp200nfe.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[:, :, 2] = data.copy()[:, :, 2] * pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[:10, :5, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pt[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data2[:10, :5, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data[:, :, 2].flatten(), bins=100, label=\"FM\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data2[:, :, 2].flatten(), bins=100, label=\"FM\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_write = \"/beegfs/desy/user/ewencedr/deep-learning/final_data/fm_tops150_cond.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(filepath_write, \"w\") as f:\n",
    "    f.create_dataset(\"etaphipt\", data=data)\n",
    "    f.create_dataset(\"etaphiptfrac\", data=data2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pllhome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
