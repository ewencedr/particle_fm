{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set env variable DATA_DIR again because of hydra\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"DATA_DIR\"] = os.environ.get(\"DATA_DIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"fm_tops.yaml\"\n",
    "experiment_jedi = \"epic_jedi.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load everything from experiment config\n",
    "torch.manual_seed(123)\n",
    "with hydra.initialize(version_base=None, config_path=\"../configs/\"):\n",
    "    cfg = hydra.compose(config_name=\"train.yaml\", overrides=[f\"experiment={experiment}\"])\n",
    "    # print(OmegaConf.to_yaml(cfg))\n",
    "torch.manual_seed(torch.seed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load everything from experiment config\n",
    "torch.manual_seed(123)\n",
    "with hydra.initialize(version_base=None, config_path=\"../configs/\"):\n",
    "    cfg_jedi = hydra.compose(config_name=\"train.yaml\", overrides=[f\"experiment={experiment_jedi}\"])\n",
    "    # print(OmegaConf.to_yaml(cfg_jedi))\n",
    "torch.manual_seed(torch.seed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "datamodule = hydra.utils.instantiate(cfg.data)\n",
    "datamodule.setup()\n",
    "torch.manual_seed(torch.seed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "datamodule_jedi = hydra.utils.instantiate(cfg_jedi.data)\n",
    "datamodule_jedi.setup(stage=\"fit\")\n",
    "torch.manual_seed(torch.seed())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the data shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.array(datamodule.tensor_test)\n",
    "test_mask = np.array(datamodule.mask_test)\n",
    "test_cond = np.array(datamodule.tensor_conditioning_test)\n",
    "val_data = np.array(datamodule.tensor_val)\n",
    "val_mask = np.array(datamodule.mask_val)\n",
    "val_cond = np.array(datamodule.tensor_conditioning_val)\n",
    "train_data = np.array(datamodule.tensor_train)\n",
    "train_mask = np.array(datamodule.mask_train)\n",
    "train_cond = np.array(datamodule.tensor_conditioning_train)\n",
    "means = np.array(datamodule.means)\n",
    "stds = np.array(datamodule.stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test_data.shape\", test_data.shape)\n",
    "print(\"val_data.shape\", val_data.shape)\n",
    "print(\"train_data.shape\", train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datamodule.hparams.normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_jedi = []\n",
    "torch.manual_seed(123)\n",
    "\n",
    "for i in datamodule_jedi.train_dataloader():\n",
    "    # print(i[0].shape)\n",
    "    data_jedi.append(i[0].numpy())\n",
    "data_jedi = np.array(data_jedi)\n",
    "data_jedi = np.reshape(\n",
    "    data_jedi, (data_jedi.shape[0] * data_jedi.shape[1], data_jedi.shape[2], data_jedi.shape[3])\n",
    ")\n",
    "print(\"data_jedi.shape\", data_jedi.shape)\n",
    "torch.manual_seed(torch.seed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "torch.manual_seed(123)\n",
    "for i in datamodule.train_dataloader():\n",
    "    #\n",
    "    data.append(i[0].numpy())\n",
    "data = np.array(data)\n",
    "\n",
    "data = np.reshape(data, (data.shape[0] * data.shape[1], data.shape[2], data.shape[3]))\n",
    "print(\"data.shape\", data.shape)\n",
    "torch.manual_seed(torch.seed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_jedi[:10, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[:10, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "print(data_jedi.shape)\n",
    "print((data - data_jedi).shape)\n",
    "diff = data - data_jedi\n",
    "print(diff[:10, 0])\n",
    "print(np.allclose(data, data_jedi, rtol=1e-05, atol=1e-08, equal_nan=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = plt.hist(data[:, :, 2].flatten(), histtype=\"stepfilled\")\n",
    "plt.hist(data_jedi[:, :, 2].flatten(), histtype=\"step\", bins=hist[1])\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array9 = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "test_mask9 = torch.tensor([0, 0, 0, 0, 1, 1, 1, 1, 1], dtype=torch.bool)\n",
    "print(type(test_array9))\n",
    "print(test_mask9)\n",
    "print(test_array9[test_mask9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_mask = torch.tensor(test_mask)\n",
    "print(test_mask.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_mask.shape)\n",
    "print(test_data.shape)\n",
    "# print(test_mask[:2])\n",
    "# print(test_mask[:2]==1)\n",
    "# test_mask = torch.tensor(test_mask.clone(), dtype=torch.bool)\n",
    "# test_data = torch.tensor(test_data.clone())\n",
    "test_data = test_data.clone()\n",
    "test_mask = test_mask.clone() == 1\n",
    "print(test_mask[:2])\n",
    "# tm = np.squeeze(np.array(test_mask == 1))\n",
    "# tm = test_mask.repeat_interleave(3, dim=-1)\n",
    "tm = test_mask.squeeze()\n",
    "# tm =np.repeat(tm, 3, axis=-1)\n",
    "# print(tm.shape)\n",
    "mean_ar = []\n",
    "print(test_data.shape)\n",
    "# for i in range(3):\n",
    "#    t2 = test_data[:, :, i]\n",
    "#    t23 = t2[tm]\n",
    "#    print(t23.shape)\n",
    "#    mean = np.mean(t23)\n",
    "#    mean_ar.append(mean)\n",
    "#\n",
    "# print(np.array(mean_ar).shape)\n",
    "means = torch.tensor([[0.0, 0.0, 0.0]])\n",
    "print(means.shape)\n",
    "tt = test_data[tm]\n",
    "print(tt.shape)\n",
    "means, var = torch.var_mean(tt, dim=0, keepdim=True)\n",
    "print(means.shape)\n",
    "print(var.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetnet.datasets import JetNet\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to one hot encode the jet type and leave the rest of the features as is\n",
    "def OneHotEncodeType(x: np.ndarray):\n",
    "    enc = OneHotEncoder(categories=[[0, 1]])\n",
    "    type_encoded = enc.fit_transform(x[..., 0].reshape(-1, 1)).toarray()\n",
    "    other_features = x[..., 1:].reshape(-1, 3)\n",
    "    return np.concatenate((type_encoded, other_features), axis=-1).reshape(*x.shape[:-1], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_args = {\n",
    "    # \"jet_type\": [\"g\", \"q\", \"t\", \"w\", \"z\"],  # gluon and top quark jets\n",
    "    \"jet_type\": [\"g\", \"t\"],  # gluon and top quark jets\n",
    "    \"data_dir\": \"/beegfs/desy/user/ewencedr/data/jetnet/\",\n",
    "    # these are the default particle features, written here to be explicit\n",
    "    \"particle_features\": [\"etarel\", \"phirel\", \"ptrel\", \"mask\"],\n",
    "    \"num_particles\": 150,  # we retain only the 10 highest pT particles for this demo\n",
    "    \"jet_features\": [\"type\", \"pt\", \"eta\", \"mass\"],\n",
    "    # we don't want to normalise the 'mask' feature so we set that to False\n",
    "    # \"particle_normalisation\": FeaturewiseLinear(\n",
    "    #    normal=True, normalise_features=[True, True, True, False]\n",
    "    # ),\n",
    "    # pass our function as a transform to be applied to the jet features\n",
    "    \"jet_transform\": OneHotEncodeType,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jets_train = JetNet(**data_args, split=\"train\")\n",
    "jets_valid = JetNet(**data_args, split=\"valid\")\n",
    "jets = JetNet(**data_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jets_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particle_features, jet_features = jets_train[0]\n",
    "print(f\"Particle features ({data_args['particle_features']}):\\n\\t{particle_features}\")\n",
    "print(f\"\\nJet features ({data_args['jet_features']}):\\n\\t{jet_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_args_np = {\n",
    "    \"jet_type\": [\"g\", \"q\", \"t\", \"z\"],  # gluon and top quark jets\n",
    "    # \"jet_type\": [\"z\"],  # gluon and top quark jets\n",
    "    \"data_dir\": \"/beegfs/desy/user/ewencedr/data/jetnet/\",\n",
    "    # these are the default particle features, written here to be explicit\n",
    "    \"particle_features\": [\"etarel\", \"phirel\", \"ptrel\", \"mask\"],\n",
    "    \"num_particles\": 150,  # we retain only the 10 highest pT particles for this demo\n",
    "    \"jet_features\": [\"type\", \"pt\", \"eta\", \"mass\"],\n",
    "    # we don't want to normalise the 'mask' feature so we set that to False\n",
    "    # \"particle_normalisation\": FeaturewiseLinear(\n",
    "    #    normal=True, normalise_features=[True, True, True, False]\n",
    "    # ),\n",
    "    # pass our function as a transform to be applied to the jet features\n",
    "    # \"jet_transform\": OneHotEncodeType,\n",
    "    \"split\": \"all\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particle_data_np, jet_data_np = JetNet.getData(**data_args_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(particle_data_np.shape)\n",
    "print(jet_data_np[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gluon: 0\n",
    "# quark: 1\n",
    "# top: 2\n",
    "# w: 3\n",
    "# z: 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dict = {\"g\": 0, \"q\": 1, \"t\": 2, \"w\": 3, \"z\": 4}\n",
    "categories = []\n",
    "for type in data_args_np[\"jet_type\"]:\n",
    "    categories.append(type_dict[type])\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OneHotEncodeTypeNp(x: np.ndarray, categories: list = [[0, 1, 2, 3, 4]]):\n",
    "    \"\"\"One hot encode the jet type and leave the rest of the features as is\n",
    "        Note: The one_hot encoded value is based on the position in the categories list not the value itself,\n",
    "        e.g. categories: [0,3] results in the two one_hot encoded values [1,0] and [0,1]\n",
    "\n",
    "    Args:\n",
    "        x (np.ndarray): jet data with shape (num_jets, num_features) that contains the jet type in the first column\n",
    "        categories (list, optional): List with values in x that should be one hot encoded. Defaults to [[0, 1, 2, 3, 4]].\n",
    "\n",
    "    Returns:\n",
    "        np.array: one_hot_encoded jet data (num_jets, num_features) with feature length len(categories) + 3 (pt, eta, mass)\n",
    "    \"\"\"\n",
    "    enc = OneHotEncoder(categories=categories)\n",
    "    type_encoded = enc.fit_transform(x[..., 0].reshape(-1, 1)).toarray()\n",
    "    other_features = x[..., 1:].reshape(-1, 3)\n",
    "    return np.concatenate((type_encoded, other_features), axis=-1).reshape(*x.shape[:-1], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_data_one_hot = OneHotEncodeTypeNp(jet_data_np, categories=[categories])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jet_data_one_hot.shape)\n",
    "print(jet_data_one_hot[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditioning_type = True\n",
    "conditioning_pt = False\n",
    "conditioning_eta = False\n",
    "conditioning_mass = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_len = len(categories)\n",
    "print(one_hot_len)\n",
    "keep_col = []\n",
    "if conditioning_type:\n",
    "    keep_col.append(np.arange(one_hot_len))\n",
    "if conditioning_pt:\n",
    "    keep_col.append(np.arange(one_hot_len, one_hot_len + 1))\n",
    "if conditioning_eta:\n",
    "    keep_col.append(np.arange(one_hot_len + 1, one_hot_len + 2))\n",
    "if conditioning_mass:\n",
    "    keep_col.append(np.arange(one_hot_len + 2, one_hot_len + 3))\n",
    "keep_col = np.concatenate(keep_col)\n",
    "print(keep_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what happens if no conditioning is used?\n",
    "jet_data_final = jet_data_one_hot[..., keep_col]\n",
    "print(jet_data_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jet_data_one_hot.shape)\n",
    "print(jet_data_one_hot[:, [0, 1, 2, 5]].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array = np.array([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
    "test_array = np.repeat(test_array, 10, axis=0)\n",
    "print(test_array.shape)\n",
    "print(test_array)\n",
    "print(test_array[:, [0, 1, 2, 5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(datamodule.tensor_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color: str = (\"#E2001A\",)\n",
    "mask_data = np.ma.masked_where(\n",
    "    data[:, :, 0] == 0,\n",
    "    data[:, :, 0],\n",
    ")\n",
    "mask = np.expand_dims(mask_data, axis=-1)\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "gs = GridSpec(1, 1)\n",
    "ax = fig.add_subplot(gs[0])\n",
    "# idx = np.random.randint(len(data))\n",
    "for idx in tqdm(range(1000)):\n",
    "    x_plot = data[idx, :, :2]  # .cpu()\n",
    "    s_plot = np.abs(data[idx, :, 2])  # .cpu())\n",
    "    s_plot[mask[idx, :, 0] < 0.0] = 0.0\n",
    "\n",
    "    ax.scatter(*x_plot.T, s=50 * s_plot, color=color, alpha=0.5)\n",
    "\n",
    "ax.set_xlabel(r\"$\\eta$\")\n",
    "ax.set_ylabel(r\"$\\phi$\")\n",
    "\n",
    "ax.set_xlim(-0.3, 0.3)\n",
    "ax.set_ylim(-0.3, 0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_jets(\n",
    "    data: np.ndarray,\n",
    "    color: str = \"#E2001A\",\n",
    "    save_folder: str = \"logs/\",\n",
    "    save_name: str = \"sim_jets\",\n",
    ") -> plt.figure:\n",
    "    \"\"\"Create a plot with 16 randomly selected jets from the data.\n",
    "\n",
    "    Args:\n",
    "        data (_type_): Data to plot.\n",
    "        color (str, optional): Color of plotted point cloud. Defaults to \"#E2001A\".\n",
    "        save_folder (str, optional): Path to folder where the plot is saved. Defaults to \"logs/\".\n",
    "        save_name (str, optional): File_name for saving the plot. Defaults to \"sim_jets\".\n",
    "    \"\"\"\n",
    "    mask_data = np.ma.masked_where(\n",
    "        data[:, :, 0] == 0,\n",
    "        data[:, :, 0],\n",
    "    )\n",
    "    mask = np.expand_dims(mask_data, axis=-1)\n",
    "    fig = plt.figure(figsize=(16, 16))\n",
    "    gs = GridSpec(4, 4)\n",
    "\n",
    "    for i in tqdm(range(16)):\n",
    "        ax = fig.add_subplot(gs[i])\n",
    "\n",
    "        idx = np.random.randint(len(data))\n",
    "        x_plot = data[idx, :, :2]  # .cpu()\n",
    "        s_plot = np.abs(data[idx, :, 2])  # .cpu())\n",
    "        s_plot[mask[idx, :, 0] < 0.0] = 0.0\n",
    "\n",
    "        ax.scatter(*x_plot.T, s=5000 * s_plot, color=color, alpha=0.5)\n",
    "\n",
    "        ax.set_xlabel(r\"$\\eta$\")\n",
    "        ax.set_ylabel(r\"$\\phi$\")\n",
    "\n",
    "        ax.set_xlim(-0.3, 0.3)\n",
    "        ax.set_ylim(-0.3, 0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(f\"{save_folder}{save_name}.png\", bbox_inches=\"tight\")\n",
    "    return fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Sliced Wasserstein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swd(data: torch.Tensor, preds: torch.Tensor, n_proj: int = 1024) -> torch.Tensor:\n",
    "    \"\"\"Sliced Wassersteini Distance\n",
    "    Compute the Wasserstein distance between two point clouds.\n",
    "    Inspired by https://github.com/apple/ml-cvpr2019-swd/blob/master/swd.py#L45\n",
    "\n",
    "    Args:\n",
    "        data (torch.Tensor) [batch, n_points, feats]: Ground truth.\n",
    "        preds (torch.Tensor) [batch, n_points, feats]: Predictions.\n",
    "        n_proj (int, optional): number of random 1d projections. Defaults to 1024.\n",
    "\n",
    "    Returns:\n",
    "        wdist (torch.Tensor) [1]: Wasserstein distance\n",
    "    \"\"\"\n",
    "\n",
    "    b, p, f = data.shape  # [batch,points,feats]\n",
    "    data, preds = data.float(), preds.float()\n",
    "    proj = torch.randn(f, n_proj, device=data.device)  # [feats, l]\n",
    "    print(f\"proj: {proj.shape}\")\n",
    "    proj *= torch.rsqrt(torch.sum(torch.square(proj), 0, keepdim=True))\n",
    "    print(f\"proj: {proj.shape}\")\n",
    "    proj = proj.view(1, f, n_proj).expand(b, -1, -1)  # first add dim, then expand to batch dim\n",
    "    print(f\"proj: {proj.shape}\")\n",
    "    p1 = torch.matmul(data, proj)  # shape: [batch, n_points, l]\n",
    "    print(f\"p1: {p1.shape}\")\n",
    "    p2 = torch.matmul(preds, proj)  # shape: [batch, n_points, l]\n",
    "    print(f\"p2: {p2.shape}\")\n",
    "    p1, _ = torch.sort(p1, 1, descending=True)  # point wise sorting\n",
    "    print(f\"p1: {p1.shape}\")\n",
    "    p2, _ = torch.sort(p2, 1, descending=True)\n",
    "    print(f\"p2: {p2.shape}\")\n",
    "    wdist = torch.mean(torch.square(p1 - p2))  # MSE\n",
    "    return wdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1 = torch.tensor(data)\n",
    "tensor2 = torch.tensor(data) + 0.1\n",
    "print(tensor1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swd_ = swd(tensor1, tensor2)\n",
    "print(swd_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_test = torch.rand(2, 5)\n",
    "mask_test[mask_test > 0.5] = 1\n",
    "mask_test = mask_test == 1\n",
    "print(mask_test)\n",
    "mask_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor = torch.rand(2, 5, 3)\n",
    "print(test_tensor)\n",
    "print(test_tensor.shape)\n",
    "print(mask_test.shape)\n",
    "masked_test = test_tensor[mask_test]\n",
    "print(masked_test.shape)\n",
    "print(masked_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mskd = test_tensor * mask_test\n",
    "print(mskd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mskd.mean())\n",
    "print(mskd.sum() / mask_test.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pllhome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
