_target_: src.models.flow_matching_module.SetFlowMatchingLitModule

optimizer:
  _target_: torch.optim.AdamW
  _partial_: true
  lr: 0.001
  weight_decay: 0.00005

scheduler:
  _target_: src.schedulers.lr_scheduler.CosineWarmupScheduler
  _partial_: true
  warmup: 1000
  max_iters: 10000

model: "droid_fullcrossattention"
net_config:
  node_embd_config:
    act_h: lrlu
    nrm: layer
  ctxt_embd_config:
    outp_dim: 64
    act_h: lrlu
    nrm: layer
  cae_config:
    model_dim: 128
    num_layers: 8
    mha_config:
      num_heads: 16
      init_zeros: True
      do_layer_norm: True
    dense_config:
      hddn_dim: 256
      act_h: lrlu
      nrm: layer
      output_init_zeros: True
  outp_embd_config:
    act_h: lrlu
    nrm: layer
    output_init_zeros: True

t_emb: cosine
frequencies: 16
#t_global_cat: True
#t_local_cat: True
add_time_to_input: True

loss_type: 'FM-OT'
diff_config:
  max_sr: 0.999
  min_sr: 0.02
criterion: 'mse'
sigma: 1e-4

use_normaliser: False
normaliser_config:
  max_n: 2000
