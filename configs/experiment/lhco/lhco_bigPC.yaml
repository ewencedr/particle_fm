# @package _global_

# to execute this experiment run:
# python train.py experiment=fm_tops

defaults:
  - override /data: lhco.yaml
  - override /model: flow_matching.yaml
  - override /callbacks: /lhco/lhco_bruteforce.yaml
  - override /trainer: ddp.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters



tags: ["flow_matching", "LHCO", "bigPC"]

seed: 12345

trainer:
  min_epochs: 100
  max_epochs: 1500
  gradient_clip_val: 0.5
  layers: 8
  latent: 256
  hidden_dim: 256

model:
  num_particles: 558
  global_cond_dim: 10 # needs to be calculated when using conditioning
  local_cond_dim: 10
  scheduler:
    warmup: ${trainer.min_epochs}
    max_iters: ${trainer.max_epochs}

data:
  batch_size: 128
  normalize: True
  conditioning: True
  relative_coords: False
  jet_type: "all_one_pc"
  num_particles: ${model.num_particles}
  use_all_data: False
  shuffle_data: False
  val_fraction: 0.05
  test_fraction: 0.35
  file_suffix_processed_data: "_masssorted"
  log_pt: True
  pt_standardization: False
  multiplicity_conditioning: True

callbacks:
  ema:
    decay: 0.999
    apply_ema_every_n_steps: 1
    start_step: 0
    save_ema_weights_in_callback_state: True
    evaluate_ema_weights_instead: True

  lhco_bruteforce_eval:
    every_n_epochs: 300 # evaluate every n epochs
    num_jet_samples: -1 # jet samples to generate
    model_name: "lhco_flow_matching"
    log_epoch_zero: True
    data_type: "val"
    w_dist_config:
      num_eval_samples: 10_000
      num_batches: 40
      calculate_efps: False
    generation_config:
      batch_size: 2048
      ode_solver: "midpoint"
      ode_steps: 50
      verbose: False
    plot_config:
      plot_efps: False
      plottype: ""

  #early_stopping:
  #  monitor: "val/loss"
  #  patience: 2000
  #  mode: "min"

task_name: "lhco_flow_matching"

logger:
  wandb:
    tags: ${tags}
    project: "LHCO"
    group: "lhco_flow_matching"
    name: ${task_name}
  comet:
    project_name: "LHCO"
    experiment_name: ${task_name}
