# @package _global_

# to execute this experiment run:
# python train.py experiment=fm_tops

defaults:
  - override /data: /calo_challenge/calo_challenge.yaml
  - override /model: flow_matching_mdma.yaml
  - override /callbacks: /calo_challenge/calo_challenge.yaml
  - override /trainer: gpu.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters



tags: ["flow_matching", "CaloChallenge", "cond", "MDMA"]

seed: 12345

trainer:
  min_epochs: 1000
  max_epochs: 10000
  gradient_clip_val: 0.5

model:
  features: 4
  num_particles: 150

callbacks:
  ema:
    decay: 0.999
    apply_ema_every_n_steps: 1
    start_step: 0
    save_ema_weights_in_callback_state: True
    evaluate_ema_weights_instead: True

  calo_challenge_eval:
    every_n_epochs: 2
    num_jet_samples: -1
    data_type: "val"
    use_ema: ${callbacks.ema.evaluate_ema_weights_instead}
    generation_config:
      ode_solver: "midpoint"
      verbose: True
      ode_steps: 100
    w_dist_config:
      num_batches: 40
    plot_config:
      plot_w_dists: False
      plot_jet_features: True

  #early_stopping:
  #  monitor: "val/loss"
  #  patience: 2000
  #  mode: "min"

task_name: "CaloChallenge-${model.num_particles}-MDMA"

logger:
  wandb:
    tags: ${tags}
    group: "CaloChallenge"
    name: ${task_name}
  comet:
    experiment_name: ${task_name}
